{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"00 Misc: python-dotenv, ToDo\"\n",
    "lightbox: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "number-offset: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "![image.png](../background_photos/libs_00_patrvac_amper.jpg)\n",
    "’Ñ’°÷Ä’£’°÷Ä’µ’°’∂ ÷É’∏’≤’∏÷Å, [’¨’∏÷Ç’Ω’°’∂’Ø’°÷Ä’´ ’∞’≤’∏÷Ç’¥’®](https://unsplash.com/photos/F8vy6hUmfbk), ’Ä’•’≤’´’∂’°’Ø’ù [Sanasar Tovmasyan](https://unsplash.com/@santovmasyan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<a href=\"ToDo\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> (ToDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìå ’Ü’Ø’°÷Ä’°’£’´÷Ä\n",
    "\n",
    "[üìö ‘±’¥’¢’∏’≤’ª’°’Ø’°’∂ ’∂’µ’∏÷Ç’©’®](00_misc_libraries.ipynb)\n",
    "\n",
    "#### üì∫ ’è’•’Ω’°’∂’µ’∏÷Ç’©’•÷Ä\n",
    "\n",
    "- [’è’•’Ω’°’∂’µ’∏÷Ç’©’®](https://youtu.be/tqR3DhSkNlQ)\n",
    "- [‘±’∂’£’¨’•÷Ä’•’∂’∏’æ ’¨’°’æ ’æ’´’§’•’∏](https://www.youtube.com/watch?v=c42T5wKSztQ)\n",
    "#### üè° ’è’∂’°’µ’´’∂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìö ’Ü’µ’∏÷Ç’©’®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-dotenv\n",
    "\n",
    "- [’è’•’Ω’°’∂’µ’∏÷Ç’©’®](https://youtu.be/tqR3DhSkNlQ)\n",
    "- [‘±’∂’£’¨’•÷Ä’•’∂’∏’æ ’¨’°’æ ’æ’´’§’•’∏](https://www.youtube.com/watch?v=c42T5wKSztQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.18 environment at: C:\\Users\\hayk_\\.conda\\envs\\lectures\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 576ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 124ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "’ä’•’ø÷Ñ ’° ’Ω’°÷Ä÷Ñ’•’∂÷Ñ `.env` ’°’∂’∏÷Ç’∂’∏’æ ÷Ü’°’µ’¨, ’∏÷Ä’ø’•’≤ ’Ø’∫’°’∞’•’∂÷Ñ ’¥’•÷Ä ’£’°’≤’ø’∂’´ ’ø’æ’µ’°’¨’∂’•÷Ä’®, ÷Ö÷Ä’´’∂’°’Ø’ù\n",
    "\n",
    "```\n",
    "PASSWORD=hnkdahav\n",
    "SECRET_KEY=1234567890abcdef\n",
    "```\n",
    "\n",
    "**’Ü’∑’∏÷Ç’¥÷â**\n",
    "’é’´’§’•’∏’µ’´ ’¥’•’ª ’¥’∏’º’°’∂’∏÷Ç’¥ ’•’¥ ’°’Ω’•’¨’ù `load_dotenv`-’® default-’∏’æ ’°  ’£’∂’∏÷Ç’¥ `.env` ÷Ü’°’µ’¨’® ’Ø’°÷Ä’§’∏÷Ç’¥÷â ‘µ’©’• ’∏÷Ç’¶’•’∂÷Ñ ’∏÷Ç÷Ä’´’∑ ÷Ü’°’µ’¨ ’Ø’°÷Ä’§’°’¨, ’∫’•’ø÷Ñ ’° ’∞’°’Ω÷Å’•’∂ ’∏÷Ä’∫’•’Ω ’°÷Ä’£’∏÷Ç’¥’•’∂’ø ÷É’∏’≠’°’∂÷Å’•’∂÷Ñ÷â"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hndkahav'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"PASSWORD\")  # Access the environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234567890abcdef'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"SECRET_KEY\")  # Access the environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÇÔ∏è Pathlib - Modern Path Handling\n",
    "\n",
    "`pathlib` is a modern, object-oriented approach to handling filesystem paths in Python. It provides a clean, intuitive interface that works across different operating systems.\n",
    "\n",
    "## Why use Pathlib over os.path?\n",
    "\n",
    "- **Object-oriented**: Paths are objects with methods\n",
    "- **Cross-platform**: Works on Windows, macOS, and Linux\n",
    "- **Readable**: More intuitive syntax\n",
    "- **Powerful**: Rich set of methods for path operations\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Path manipulation and navigation\n",
    "- File system operations\n",
    "- Pattern matching with glob\n",
    "- Path validation and properties\n",
    "- Cross-platform compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Path Creation ===\n",
      "Current directory: c:\\Users\\hayk_\\OneDrive\\Desktop\\01_python_math_ml_course\\python_libs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Basic Path Creation\n",
    "print(\"=== Basic Path Creation ===\")\n",
    "# Current working directory\n",
    "current_dir = Path.cwd()\n",
    "print(f\"Current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 1: documents\\projects\\myproject\n",
      "Path 2: \\usr\\local\\bin\n"
     ]
    }
   ],
   "source": [
    "# Creating paths from strings\n",
    "path1 = Path(\"documents/projects/myproject\")\n",
    "path2 = Path(r\"\\usr\\local\\bin\")\n",
    "print(f\"Path 1: {path1}\")\n",
    "print(f\"Path 2: {path2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('/usr/local/bin')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 3: documents\\projects\\myproject\\file.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = Path(\"documents\")\n",
    "# os.path.join(\"docs\", ..)\n",
    "# Path from multiple parts (magic, polymorphism)\n",
    "path3 = docs / \"projects\" / \"myproject\" / \"file.txt\" \n",
    "print(f\"Path 3: {path3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path as string: documents\\projects\\myproject\\file.txt\n"
     ]
    }
   ],
   "source": [
    "# Converting between Path and string\n",
    "path_str = str(path3)\n",
    "print(f\"Path as string: {path_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Path Properties ===\n",
      "Full path: documents\\projects\\myproject\\data.csv\n",
      "Name: example_path.name = 'data.csv'\n",
      "Stem: example_path.stem = 'data'\n",
      "Suffix: example_path.suffix = '.csv'\n",
      "Suffixes: example_path.suffixes = ['.csv']\n",
      "Parent: example_path.parent = WindowsPath('documents/projects/myproject')\n",
      "Parents: list(example_path.parents) = [WindowsPath('documents/projects/myproject'), WindowsPath('documents/projects'), WindowsPath('documents'), WindowsPath('.')]\n",
      "Parts: ('documents', 'projects', 'myproject', 'data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Path Properties\n",
    "print(\"=== Path Properties ===\")\n",
    "example_path = Path(\"documents/projects/myproject/data.csv\")\n",
    "print(f\"Full path: {example_path}\")\n",
    "print(f\"Name: {example_path.name = }\")           # data.csv\n",
    "print(f\"Stem: {example_path.stem = }\")           # data\n",
    "print(f\"Suffix: {example_path.suffix = }\")       # .csv\n",
    "print(f\"Suffixes: {example_path.suffixes = }\")   # ['.csv']\n",
    "print(f\"Parent: {example_path.parent = }\")       # documents/projects/myproject\n",
    "print(f\"Parents: {list(example_path.parents) = }\")  # All parent directories\n",
    "print(f\"Parts: {example_path.parts = }\")         # ('documents', 'projects', 'myproject', 'data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path Joining and Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Path Manipulation ===\n",
      "Joined path: documents\\projects\\myproject\n",
      "Resolved path: C:\\Users\\hayk_\\OneDrive\\Desktop\\01_python_math_ml_course\\python_libs\\documents\\projects\\myproject\n",
      "Is absolute? True\n",
      "Is absolute? False\n"
     ]
    }
   ],
   "source": [
    "# Path Joining and Resolution\n",
    "print(\"=== Path Manipulation ===\")\n",
    "\n",
    "# Joining paths\n",
    "base_path = Path(\"documents\")\n",
    "project_path = base_path / \"projects\" / \"myproject\"\n",
    "print(f\"Joined path: {project_path}\")\n",
    "\n",
    "# Resolving paths (absolute path)\n",
    "resolved_path = project_path.resolve()\n",
    "print(f\"Resolved path: {resolved_path}\")\n",
    "\n",
    "# Check if path is absolute or relative\n",
    "rel_path = Path(\"documents/file.txt\")\n",
    "print(f\"Is absolute? {resolved_path.is_absolute()}\")  # True\n",
    "print(f\"Is absolute? {rel_path.is_absolute()}\")  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Path Modification ===\n",
      "Original: report.txt\n",
      "PDF version: report.pdf\n",
      "JSON version: report.json\n"
     ]
    }
   ],
   "source": [
    "# Path Modification\n",
    "print(\"=== Path Modification ===\")\n",
    "\n",
    "# Changing file extensions\n",
    "data_file = Path(\"report.txt\")\n",
    "pdf_file = data_file.with_suffix(\".pdf\")\n",
    "json_file = data_file.with_suffix(\".json\")\n",
    "print(f\"Original: {data_file}\")\n",
    "print(f\"PDF version: {pdf_file}\")\n",
    "print(f\"JSON version: {json_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path: documents\\old_name.txt\n",
      "New path: documents\\new_name.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Changing filename but keeping directory\n",
    "old_path = Path(\"documents/old_name.txt\")\n",
    "new_path = old_path.with_name(\"new_name.txt\")\n",
    "print(f\"Old path: {old_path}\")\n",
    "print(f\"New path: {new_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Path Checking Methods ===\n",
      "Testing path: C:\\Users\\hayk_\\OneDrive\\Desktop\\01_python_math_ml_course\\python_libs\n",
      "Exists: True\n",
      "Is directory: True\n",
      "Is file: False\n"
     ]
    }
   ],
   "source": [
    "# Path Checking Methods\n",
    "print(\"=== Path Checking Methods ===\")\n",
    "# Note: These will work with actual files/directories\n",
    "test_path = Path(\".\")\n",
    "print(f\"Testing path: {test_path.resolve()}\")\n",
    "print(f\"Exists: {test_path.exists()}\")\n",
    "print(f\"Is directory: {test_path.is_dir()}\")\n",
    "print(f\"Is file: {test_path.is_file()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== File Operations ===\n",
      "Created file: temp_demo.txt\n",
      "File content:\n",
      "Hello, World!\n",
      "This is a test file.\n"
     ]
    }
   ],
   "source": [
    "# File Reading and Writing\n",
    "print(\"=== File Operations ===\")\n",
    "\n",
    "# Create a temporary file for demonstration\n",
    "temp_file = Path(\"temp_demo.txt\")\n",
    "\n",
    "# Writing to a file\n",
    "temp_file.write_text(\"Hello, World!\\nThis is a test file.\")\n",
    "print(f\"Created file: {temp_file}\")\n",
    "\n",
    "# # Reading from a file\n",
    "content = temp_file.read_text()\n",
    "print(f\"File content:\\n{content}\")\n",
    "\n",
    "# Clean up the temp file\n",
    "temp_file.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== File Statistics ===\n",
      "File size: 29 bytes\n",
      "Modified time: 1755106330.0550132\n"
     ]
    }
   ],
   "source": [
    "# File Statistics\n",
    "print(\"=== File Statistics ===\")\n",
    "\n",
    "# Create a temporary file to get stats\n",
    "temp_file = Path(\"temp_stats.txt\")\n",
    "temp_file.write_text(\"Sample content for statistics\")\n",
    "\n",
    "if temp_file.exists():\n",
    "    stat = temp_file.stat()\n",
    "    print(f\"File size: {stat.st_size} bytes\")\n",
    "    print(f\"Modified time: {stat.st_mtime}\")\n",
    "\n",
    "# Clean up\n",
    "temp_file.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Directory Operations ===\n",
      "Created directory: test_directory\n",
      "Created nested directories: parent\\child\\grandchild\n"
     ]
    }
   ],
   "source": [
    "# Directory Operations\n",
    "print(\"=== Directory Operations ===\")\n",
    "\n",
    "# Create directories\n",
    "test_dir = Path(\"test_directory\")\n",
    "test_dir.mkdir(exist_ok=True)  # exist_ok prevents error if directory exists\n",
    "print(f\"Created directory: {test_dir}\")\n",
    "\n",
    "# Create nested directories\n",
    "nested_dir = Path(\"parent/child/grandchild\")\n",
    "nested_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Created nested directories: {nested_dir}\")\n",
    "\n",
    "# # List directory contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory contains 30 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('00_misc_libraries.ipynb'),\n",
       " WindowsPath('00_template.ipynb'),\n",
       " WindowsPath('01_openai_api_timestamp_generator.ipynb'),\n",
       " WindowsPath('02_numpy.ipynb'),\n",
       " WindowsPath('03_pandas_1.ipynb'),\n",
       " WindowsPath('04_pandas_2.ipynb'),\n",
       " WindowsPath('05_noble_people_analysis.ipynb'),\n",
       " WindowsPath('06_data_viz.ipynb'),\n",
       " WindowsPath('07_kargin_project.ipynb'),\n",
       " WindowsPath('08_logging__clis.ipynb'),\n",
       " WindowsPath('09_testing__debugging.ipynb'),\n",
       " WindowsPath('10_scraping__parallelization.ipynb'),\n",
       " WindowsPath('11_ysu_scraping.ipynb'),\n",
       " WindowsPath('12_sql.ipynb'),\n",
       " WindowsPath('13_pydantic.ipynb'),\n",
       " WindowsPath('assets'),\n",
       " WindowsPath('bg_photos.ipynb'),\n",
       " WindowsPath('clis'),\n",
       " WindowsPath('dbs'),\n",
       " WindowsPath('kargin_api.py'),\n",
       " WindowsPath('manimm.py'),\n",
       " WindowsPath('parent'),\n",
       " WindowsPath('README_kargin_api.md'),\n",
       " WindowsPath('requirements_kargin_api.txt'),\n",
       " WindowsPath('scraping'),\n",
       " WindowsPath('testing'),\n",
       " WindowsPath('test_directory'),\n",
       " WindowsPath('test_kargin_api.py'),\n",
       " WindowsPath('unittest'),\n",
       " WindowsPath('__pycache__')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_contents = list(Path(\".\").iterdir())\n",
    "print(f\"Current directory contains {len(current_contents)} items\")\n",
    "current_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up test directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean up\n",
    "if test_dir.exists():\n",
    "    test_dir.rmdir()  # Remove empty directory\n",
    "print(\"Cleaned up test directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Glob Patterns ===\n",
      "Python files in current directory: 3\n",
      "  - kargin_api.py\n",
      "  - manimm.py\n",
      "  - test_kargin_api.py\n",
      "Total files recursively: 439\n"
     ]
    }
   ],
   "source": [
    "# Basic Glob Patterns\n",
    "print(\"=== Basic Glob Patterns ===\")\n",
    "\n",
    "# Current directory\n",
    "current_dir = Path(\".\")\n",
    "\n",
    "# Find all Python files\n",
    "python_files = list(current_dir.glob(\"*.py\"))\n",
    "print(f\"Python files in current directory: {len(python_files)}\")\n",
    "for py_file in python_files[:3]:  # Show first 3\n",
    "    print(f\"  - {py_file}\")\n",
    "\n",
    "# Find all files recursively\n",
    "all_files = list(current_dir.rglob(\"*\")) # recursive glob\n",
    "print(f\"Total files recursively: {len(all_files)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter notebooks: 11\n",
      "  - 00_misc_libraries.ipynb\n",
      "  - 00_template.ipynb\n",
      "  - 01_openai_api_timestamp_generator.ipynb\n",
      "  - 02_numpy.ipynb\n",
      "  - 03_pandas_1.ipynb\n",
      "  - 04_pandas_2.ipynb\n",
      "  - 05_noble_people_analysis.ipynb\n",
      "  - 06_data_viz.ipynb\n",
      "  - 07_kargin_project.ipynb\n",
      "  - 08_logging__clis.ipynb\n",
      "  - 09_testing__debugging.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Find specific patterns\n",
    "notebook_files = list(current_dir.rglob(\"0*.ipynb\"))\n",
    "print(f\"Jupyter notebooks: {len(notebook_files)}\")\n",
    "for nb in notebook_files:  # Show all\n",
    "    print(f\"  - {nb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Advanced Pathlib Features ===\n",
      "Relative path: myapp\\src\\main.py\n"
     ]
    }
   ],
   "source": [
    "# Advanced Pathlib Features\n",
    "print(\"=== Advanced Pathlib Features ===\")\n",
    "\n",
    "# Relative path calculation\n",
    "base = Path(\"/home/user/projects\")\n",
    "target = Path(\"/home/user/projects/myapp/src/main.py\")\n",
    "try:\n",
    "    relative = target.relative_to(base)\n",
    "    print(f\"Relative path: {relative}\")\n",
    "except ValueError:\n",
    "    print(\"Cannot calculate relative path - paths don't share common base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathlib vs os.path Comparison\n",
    "print(\"=== Pathlib vs os.path Comparison ===\")\n",
    "\n",
    "import os\n",
    "\n",
    "filepath = \"documents/projects/myproject/data.csv\"\n",
    "\n",
    "print(\"Task: Get filename from path\")\n",
    "print(f\"os.path:  {os.path.basename(filepath)}\")\n",
    "print(f\"pathlib:  {Path(filepath).name}\")\n",
    "\n",
    "print(\"\\nTask: Get file extension\")\n",
    "print(f\"os.path:  {os.path.splitext(filepath)[1]}\")\n",
    "print(f\"pathlib:  {Path(filepath).suffix}\")\n",
    "\n",
    "print(\"\\nTask: Get parent directory\")\n",
    "print(f\"os.path:  {os.path.dirname(filepath)}\")\n",
    "print(f\"pathlib:  {Path(filepath).parent}\")\n",
    "\n",
    "print(\"\\nTask: Join paths\")\n",
    "print(f\"os.path:  {os.path.join('documents', 'projects', 'file.txt')}\")\n",
    "print(f\"pathlib:  {Path('documents') / 'projects' / 'file.txt'}\")\n",
    "\n",
    "print(\"\\nTask: Check if file exists\")\n",
    "print(f\"os.path:  {os.path.exists(filepath)}\")\n",
    "print(f\"pathlib:  {Path(filepath).exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical Example: File Organization\n",
    "print(\"=== Practical Example: File Organization ===\")\n",
    "\n",
    "def organize_files_by_extension(directory):\n",
    "    \"\"\"Organize files in a directory by their extensions\"\"\"\n",
    "    source_dir = Path(directory)\n",
    "    \n",
    "    if not source_dir.exists():\n",
    "        print(f\"Directory {directory} does not exist\")\n",
    "        return\n",
    "    \n",
    "    # Get all files (not directories)\n",
    "    files = [f for f in source_dir.iterdir() if f.is_file()]\n",
    "    \n",
    "    # Group by extension\n",
    "    extensions = {}\n",
    "    for file in files:\n",
    "        ext = file.suffix.lower() or 'no_extension'\n",
    "        if ext not in extensions:\n",
    "            extensions[ext] = []\n",
    "        extensions[ext].append(file)\n",
    "    \n",
    "    print(f\"Files in {directory}:\")\n",
    "    for ext, file_list in extensions.items():\n",
    "        print(f\"  {ext}: {len(file_list)} files\")\n",
    "        for file in file_list[:3]:  # Show first 3\n",
    "            print(f\"    - {file.name}\")\n",
    "\n",
    "# Example usage\n",
    "organize_files_by_extension(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Practical Example: Find Large Files ===\n",
      "Files larger than 1MB: 10\n",
      "  - 03_pandas_1.ipynb: 20.88 MB\n",
      "  - 04_pandas_2.ipynb: 3.86 MB\n",
      "  - 06_data_viz.ipynb: 4.41 MB\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: Find Large Files\n",
    "print(\"=== Practical Example: Find Large Files ===\")\n",
    "\n",
    "def find_large_files(directory, size_mb=10):\n",
    "    \"\"\"Find files larger than specified size\"\"\"\n",
    "    dir_path = Path(directory)\n",
    "    large_files = []\n",
    "    \n",
    "    for file in dir_path.rglob(\"*\"):\n",
    "        if file.is_file():\n",
    "            try:\n",
    "                size_mb_actual = file.stat().st_size / (1024 * 1024)\n",
    "                if size_mb_actual > size_mb:\n",
    "                    large_files.append((file, size_mb_actual))\n",
    "            except (OSError, PermissionError):\n",
    "                continue\n",
    "    \n",
    "    return large_files\n",
    "    \n",
    "# Find files larger than 1MB in current directory\n",
    "large_files = find_large_files(\".\", 1)\n",
    "print(f\"Files larger than 1MB: {len(large_files)}\")\n",
    "for file, size in large_files[:3]:\n",
    "    print(f\"  - {file.name}: {size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git , 50 mb limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üç¶ iceCream - Never Use Print for Debugging Again\n",
    "\n",
    "\n",
    "https://github.com/gruns/icecream\n",
    "\n",
    "`icecream` is a powerful debugging library that makes print debugging sweet and simple. It's a more convenient and informative alternative to Python's print() function.\n",
    "\n",
    "## Why use iceCream?\n",
    "\n",
    "- **Automatic variable names**: Shows variable names alongside their values\n",
    "- **Source code context**: Shows the exact line that called ic()\n",
    "- **Rich formatting**: Beautiful output formatting\n",
    "- **Function inspection**: Shows function calls and returns\n",
    "- **Configurable**: Customize output format and behavior\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install icecream\n",
    "```\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Zero-configuration debugging\n",
    "- Automatic variable name detection\n",
    "- Function call tracing\n",
    "- Customizable output formatting\n",
    "- Context-aware debugging\n",
    "- Works with any data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting icecream\n",
      "  Downloading icecream-2.1.5-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: colorama>=0.3.9 in c:\\users\\hayk_\\.conda\\envs\\sl\\lib\\site-packages (from icecream) (0.4.6)\n",
      "Requirement already satisfied: pygments>=2.2.0 in c:\\users\\hayk_\\.conda\\envs\\sl\\lib\\site-packages (from icecream) (2.19.1)\n",
      "Requirement already satisfied: executing>=2.1.0 in c:\\users\\hayk_\\.conda\\envs\\sl\\lib\\site-packages (from icecream) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in c:\\users\\hayk_\\.conda\\envs\\sl\\lib\\site-packages (from icecream) (3.0.0)\n",
      "Downloading icecream-2.1.5-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: icecream\n",
      "Successfully installed icecream-2.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=JMW6u_AFVKY\n",
    "https://www.youtube.com/watch?v=-33IXM8gC4g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| name: 'Alice'\n",
      "ic| age: 30\n",
      "ic| name: 'Alice', age: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic iceCream Examples ===\n",
      "name = Alice\n",
      "name = 'Alice'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Alice', 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Variable Debugging\n",
    "print(\"=== Basic iceCream Examples ===\")\n",
    "\n",
    "# Simple variable debugging\n",
    "name = \"Alice\"\n",
    "age = 30\n",
    "ic(name)      # name: 'Alice'\n",
    "ic(age)       # Shows: ic| age: 30\n",
    "\n",
    "\n",
    "print(f\"name = {name}\")\n",
    "print(f\"{name = }\")\n",
    "\n",
    "# Multiple variables at once\n",
    "ic(name, age) # Shows both variables with names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(numbers): 5\n",
      "ic| sum(numbers): 15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ic| numbers[0]: 1\n",
      "ic| data[\"users\"][0]: 'Alice'\n",
      "ic| len(data[\"users\"]): 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expressions\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "ic(len(numbers))           # ic| len(numbers): 5\n",
    "ic(sum(numbers))           # ic| sum(numbers): 15\n",
    "ic(numbers[0])             # ic| numbers[0]: 1\n",
    "\n",
    "# Complex expressions\n",
    "data = {\"users\": [\"Alice\", \"Bob\", \"Charlie\"]}\n",
    "ic(data[\"users\"][0])       # ic| data[\"users\"][0]: 'Alice'\n",
    "ic(len(data[\"users\"]))     # ic| len(data[\"users\"]): 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| users: [{'age': 30, 'city': 'New York', 'name': 'Alice'},\n",
      "            {'age': 25, 'city': 'London"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "', 'name': 'Bob'},\n",
      "            {'age': 35, 'city': 'Tokyo', 'name': 'Charlie'}]\n",
      "ic| users[0]: {'age':"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Structure Debugging ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30, 'city': 'New York', 'name': 'Alice'}\n",
      "ic| [user[\"name\"] for user in users]: ['Alice', 'Bob', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "# Data Structure Debugging\n",
    "print(\"=== Data Structure Debugging ===\")\n",
    "\n",
    "# Lists and dictionaries\n",
    "users = [\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"},\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"city\": \"London\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Tokyo\"}\n",
    "]\n",
    "\n",
    "ic(users)\n",
    "ic(users[0])\n",
    "ic([user[\"name\"] for user in users])\n",
    "\n",
    "# Complex data structures\n",
    "nested_data = {\n",
    "    \"project\": \"ML Pipeline\",\n",
    "    \"stages\": {\n",
    "        \"data_preprocessing\": {\"status\": \"complete\", \"time\": 45},\n",
    "        \"training\": {\"status\": \"in_progress\", \"time\": 120},\n",
    "        \"evaluation\": {\"status\": \"pending\", \"time\": None}\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| nested_data: {'project': 'ML Pipeline',\n",
      "                  'stages': {'data_preprocessing': {'status': 'complete', 'time': 45},\n",
      "                             'evaluation': {'status': 'pending', 'time': None},\n",
      "                             'training': {'status': 'in_progress', 'time': 120}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nested_data = {'project': 'ML Pipeline', 'stages': {'data_preprocessing': {'status': 'complete', 'time': 45}, 'training': {'status': 'in_progress', 'time': 120}, 'evaluation': {'status': 'pending', 'time': None}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ic(nested_data)\n",
    "# ic(nested_data[\"stages\"][\"training\"][\"status\"])\n",
    "\n",
    "\n",
    "print(f\"{nested_data = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.includeContext = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 3036100448.py:2 in <module>- a: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3 \n",
    "ic(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG | 2746202514.py:3 in <module>- a: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic.configureOutput(prefix='DEBUG | ')\n",
    "\n",
    "ic(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö° Numba - High-Performance Python Computing\n",
    "\n",
    "`Numba` is a just-in-time (JIT) compiler for Python that translates Python functions to optimized machine code at runtime. It can dramatically speed up numerical computations with minimal code changes.\n",
    "\n",
    "## Why use Numba?\n",
    "\n",
    "- **Massive speedups**: 10-1000x faster for numerical code\n",
    "- **Easy to use**: Just add a decorator to your functions\n",
    "- **NumPy integration**: Excellent support for NumPy arrays\n",
    "- **No C knowledge required**: Write Python, get C-like performance\n",
    "- **GPU acceleration**: CUDA support for parallel computing\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Just-in-time compilation\n",
    "- Automatic parallelization\n",
    "- GPU acceleration (CUDA)\n",
    "- NumPy universal function creation\n",
    "- Support for Python and NumPy functions\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install numba\n",
    "# For CUDA support:\n",
    "# conda install numba cudatoolkit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.61.2-cp310-cp310-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba)\n",
      "  Using cached llvmlite-0.44.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.24 in c:\\users\\hayk_\\.conda\\envs\\sl\\lib\\site-packages (from numba) (2.2.6)\n",
      "Downloading numba-0.61.2-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.3/2.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached llvmlite-0.44.0-cp310-cp310-win_amd64.whl (30.3 MB)\n",
      "Installing collected packages: llvmlite, numba\n",
      "\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   ---------------------------------------- 0/2 [llvmlite]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   -------------------- ------------------- 1/2 [numba]\n",
      "   ---------------------------------------- 2/2 [numba]\n",
      "\n",
      "Successfully installed llvmlite-0.44.0 numba-0.61.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Numba JIT Compilation\n",
    "import time\n",
    "import numpy as np\n",
    "from numba import jit, njit\n",
    "\n",
    "# Example 1: Simple mathematical function\n",
    "def python_sum_of_squares(n):\n",
    "    \"\"\"Regular Python function\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "@jit\n",
    "def numba_sum_of_squares(n):\n",
    "    \"\"\"Numba-compiled function\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing sum of squares for n=1,000,000\n",
      "Computing sum of squares for n=1,000,000,000,000\n",
      "Python result: 333,332,833,333,500,000\n",
      "Numba result:  -8,993,179,702,706,251,776\n",
      "Python time:   0.211253 seconds\n",
      "Numba time:    0.001999378204345703 seconds\n",
      "Speedup:       105.66x faster with Numba!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare performance\n",
    "n_python = 1_000_000\n",
    "print(f\"Computing sum of squares for n={n_python:,}\")\n",
    "\n",
    "\n",
    "n_numba = 1_000_000_000_000\n",
    "print(f\"Computing sum of squares for n={n_numba:,}\")\n",
    "\n",
    "# Time Python version\n",
    "start = time.time()\n",
    "python_result = python_sum_of_squares(n_python)\n",
    "python_time = time.time() - start\n",
    "\n",
    "# Time Numba version (includes compilation time on first run)\n",
    "start = time.time()\n",
    "numba_result = numba_sum_of_squares(n_numba)\n",
    "numba_time = time.time() - start\n",
    "\n",
    "print(f\"Python result: {python_result:,}\")\n",
    "print(f\"Numba result:  {numba_result:,}\")\n",
    "print(f\"Python time:   {python_time:.6f} seconds\")\n",
    "print(f\"Numba time:    {numba_time} seconds\")\n",
    "\n",
    "speedup = python_time / numba_time\n",
    "print(f\"Speedup:       {speedup:.2f}x faster with Numba!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Numba JIT Compilation Works\n",
    "\n",
    "**Just-In-Time (JIT) Compilation** is a technique where code is compiled at runtime rather than ahead of time. Here's how Numba works:\n",
    "\n",
    "### üîÑ The Compilation Process\n",
    "\n",
    "1. **First Call**: When you first call a `@jit` decorated function:\n",
    "   - Numba analyzes the function and input types\n",
    "   - Generates optimized machine code specific to those types\n",
    "   - Caches the compiled version\n",
    "   - Executes the compiled code\n",
    "\n",
    "2. **Subsequent Calls**: For later calls with the same types:\n",
    "   - Uses the cached compiled version\n",
    "   - No compilation overhead\n",
    "   - Maximum performance\n",
    "\n",
    "### üéØ Type Specialization\n",
    "\n",
    "Numba creates specialized versions of functions for different input types:\n",
    "\n",
    "```python\n",
    "@jit\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "# First call with integers - compiles version for int64\n",
    "result1 = add_numbers(5, 3)\n",
    "\n",
    "# First call with floats - compiles version for float64  \n",
    "result2 = add_numbers(5.0, 3.0)\n",
    "\n",
    "# Second call with integers - uses cached int64 version\n",
    "result3 = add_numbers(10, 7)\n",
    "```\n",
    "\n",
    "### ‚ö° Why It's Fast\n",
    "\n",
    "- **No Python overhead**: Compiled code runs at machine speed\n",
    "- **Type specialization**: Optimized for specific data types\n",
    "- **LLVM backend**: Uses industry-standard optimization\n",
    "- **Vectorization**: Automatic use of CPU SIMD instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Numba Compilation Modes ===\n",
      "Testing compilation modes:\n",
      "Input array size: 1,000,000\n",
      "Lazy compiled (@jit): 1849.00 (time: 0.119028s)\n",
      "No-Python (@njit): 1849.00 (time: 0.087462s)\n",
      "Explicit no-Python: 1849.00 (time: 0.101513s)\n",
      "\n",
      "Testing parallel processing:\n",
      "Parallel function completed in 0.576533 seconds\n",
      "Result shape: (100000,)\n",
      "Sample results: [0.51835051 0.46277311 0.07698531 1.4442374  1.19414022]\n"
     ]
    }
   ],
   "source": [
    "# Different Numba Compilation Modes\n",
    "print(\"=== Numba Compilation Modes ===\")\n",
    "\n",
    "from numba import jit, njit, prange\n",
    "\n",
    "# Mode 1: @jit - Lazy compilation\n",
    "@jit\n",
    "def lazy_compiled_function(x):\n",
    "    \"\"\"Compiled when first called\"\"\"\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "# Mode 2: @njit - No-Python mode (faster)\n",
    "@njit\n",
    "def nopython_function(x):\n",
    "    \"\"\"Compiled in no-Python mode for maximum speed\"\"\"\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "# Mode 3: @jit(nopython=True) - Explicit no-Python mode\n",
    "@jit(nopython=True)\n",
    "def explicit_nopython(x):\n",
    "    \"\"\"Explicitly compiled in no-Python mode\"\"\"\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "# Mode 4: Parallel processing\n",
    "@njit(parallel=True)\n",
    "def parallel_function(arr):\n",
    "    \"\"\"Parallel processing with prange\"\"\"\n",
    "    result = np.zeros_like(arr)\n",
    "    for i in prange(len(arr)):  # prange enables parallel execution\n",
    "        result[i] = arr[i] ** 2 + np.sin(arr[i])\n",
    "    return result\n",
    "\n",
    "# Test different modes\n",
    "test_array = np.random.random(1_000_000)\n",
    "test_value = 42.0\n",
    "\n",
    "print(\"Testing compilation modes:\")\n",
    "print(f\"Input array size: {len(test_array):,}\")\n",
    "\n",
    "# Test scalar functions\n",
    "modes = [\n",
    "    (\"Lazy compiled (@jit)\", lazy_compiled_function),\n",
    "    (\"No-Python (@njit)\", nopython_function),\n",
    "    (\"Explicit no-Python\", explicit_nopython)\n",
    "]\n",
    "\n",
    "for name, func in modes:\n",
    "    start = time.time()\n",
    "    result = func(test_value)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"{name}: {result:.2f} (time: {elapsed:.6f}s)\")\n",
    "\n",
    "# Test parallel function\n",
    "print(f\"\\nTesting parallel processing:\")\n",
    "start = time.time()\n",
    "parallel_result = parallel_function(test_array[:100_000])  # Use smaller array for demo\n",
    "parallel_time = time.time() - start\n",
    "print(f\"Parallel function completed in {parallel_time:.6f} seconds\")\n",
    "print(f\"Result shape: {parallel_result.shape}\")\n",
    "print(f\"Sample results: {parallel_result[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Numba Compilation Modes\n",
    "\n",
    "Numba offers different compilation modes, each with specific characteristics and use cases:\n",
    "\n",
    "### 1. `@jit` - Object Mode (Default)\n",
    "\n",
    "```python\n",
    "@jit\n",
    "def my_function(x):\n",
    "    return x ** 2\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- **Fallback capability**: If Numba can't compile part of the code, it falls back to Python\n",
    "- **Mixed execution**: Some parts run compiled, others in Python interpreter\n",
    "- **More forgiving**: Works with more Python features\n",
    "- **Moderate speedup**: Usually 2-10x faster than pure Python\n",
    "\n",
    "**When to use**: When you're not sure if your code is fully Numba-compatible\n",
    "\n",
    "### 2. `@njit` - No-Python Mode\n",
    "\n",
    "```python\n",
    "@njit  # Equivalent to @jit(nopython=True)\n",
    "def my_function(x):\n",
    "    return x ** 2\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- **Pure compilation**: Entire function must be compilable to machine code\n",
    "- **No Python interpreter**: No fallback to Python\n",
    "- **Maximum performance**: 10-1000x faster than pure Python\n",
    "- **Strict requirements**: Only supports Numba-compatible operations\n",
    "\n",
    "**When to use**: For numerical computations where you want maximum performance\n",
    "\n",
    "### 3. `@jit(nopython=True)` - Explicit No-Python Mode\n",
    "\n",
    "```python\n",
    "@jit(nopython=True)\n",
    "def my_function(x):\n",
    "    return x ** 2\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- **Identical to @njit**: Same behavior as `@njit`\n",
    "- **More explicit**: Makes the no-Python requirement clear\n",
    "- **Error handling**: Fails with clear error if Python fallback would be needed\n",
    "\n",
    "**When to use**: When you want to be explicit about no-Python mode requirements\n",
    "\n",
    "### 4. Parallel Compilation\n",
    "\n",
    "```python\n",
    "@njit(parallel=True)\n",
    "def parallel_function(arr):\n",
    "    for i in prange(len(arr)):  # prange enables parallelization\n",
    "        arr[i] = arr[i] ** 2\n",
    "    return arr\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "- **Multi-core execution**: Uses multiple CPU cores automatically\n",
    "- **Requires prange**: Use `prange` instead of `range` for parallel loops\n",
    "- **Additional speedup**: 2-8x additional speedup on multi-core systems\n",
    "- **Independent iterations**: Loop iterations must be independent\n",
    "\n",
    "### ‚öñÔ∏è Comparison Summary\n",
    "\n",
    "| Mode | Speed | Compatibility | Error Handling | Use Case |\n",
    "|------|-------|---------------|----------------|----------|\n",
    "| `@jit` | Moderate (2-10x) | High | Fallback to Python | Testing/Development |\n",
    "| `@njit` | Maximum (10-1000x) | Limited | Compilation error | Production numerical code |\n",
    "| `@jit(nopython=True)` | Maximum (10-1000x) | Limited | Compilation error | Explicit no-Python |\n",
    "| `@njit(parallel=True)` | Maximum + Multi-core | Limited | Compilation error | Parallelizable algorithms |\n",
    "\n",
    "### üéØ Which Mode to Choose?\n",
    "\n",
    "1. **Start with `@jit`** for development and testing\n",
    "2. **Switch to `@njit`** once your code works and you want maximum performance\n",
    "3. **Use `@njit(parallel=True)`** for loops with independent iterations\n",
    "4. **Use explicit `@jit(nopython=True)`** when you want to be clear about requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing with Numba\n",
    "\n",
    "Numba can automatically parallelize certain types of loops across multiple CPU cores, providing additional speedup on multi-core systems.\n",
    "\n",
    "### üîÑ How Parallel Processing Works\n",
    "\n",
    "When you use `@njit(parallel=True)`, Numba:\n",
    "\n",
    "1. **Analyzes the loop**: Checks if iterations are independent\n",
    "2. **Splits the work**: Divides loop iterations across available CPU cores\n",
    "3. **Executes in parallel**: Runs iterations simultaneously on different cores\n",
    "4. **Combines results**: Merges the results back together\n",
    "\n",
    "### üìä `prange` vs `range`\n",
    "\n",
    "```python\n",
    "# Sequential execution\n",
    "@njit\n",
    "def sequential_sum(arr):\n",
    "    total = 0\n",
    "    for i in range(len(arr)):  # Sequential loop\n",
    "        total += arr[i] ** 2\n",
    "    return total\n",
    "\n",
    "# Parallel execution  \n",
    "@njit(parallel=True)\n",
    "def parallel_sum(arr):\n",
    "    total = 0\n",
    "    for i in prange(len(arr)):  # Parallel loop\n",
    "        total += arr[i] ** 2\n",
    "    return total\n",
    "```\n",
    "\n",
    "**Key Differences:**\n",
    "- `range`: Executes iterations sequentially (one after another)\n",
    "- `prange`: Executes iterations in parallel (simultaneously across cores)\n",
    "- `prange` requires `parallel=True` in the decorator\n",
    "\n",
    "### ‚úÖ Requirements for Parallelization\n",
    "\n",
    "For a loop to be parallelizable with `prange`:\n",
    "\n",
    "1. **Independent iterations**: Each iteration must not depend on previous iterations\n",
    "2. **No shared mutable state**: Iterations shouldn't modify shared variables unsafely\n",
    "3. **Reduction operations**: Operations like sum, max, min are automatically handled\n",
    "\n",
    "### ‚ùå What Doesn't Work with Parallelization\n",
    "\n",
    "```python\n",
    "# ‚ùå This won't parallelize correctly (each iteration depends on previous)\n",
    "@njit(parallel=True)\n",
    "def bad_parallel_example(arr):\n",
    "    for i in prange(1, len(arr)):\n",
    "        arr[i] = arr[i] + arr[i-1]  # Depends on previous iteration\n",
    "    return arr\n",
    "\n",
    "# ‚úÖ This parallelizes well (independent iterations)\n",
    "@njit(parallel=True)\n",
    "def good_parallel_example(arr):\n",
    "    for i in prange(len(arr)):\n",
    "        arr[i] = arr[i] ** 2 + 5  # Each iteration is independent\n",
    "    return arr\n",
    "```\n",
    "\n",
    "### üéØ Automatic Reduction Operations\n",
    "\n",
    "Numba automatically handles common reduction patterns:\n",
    "\n",
    "```python\n",
    "@njit(parallel=True)\n",
    "def parallel_reductions(arr):\n",
    "    # These are automatically parallelized\n",
    "    total_sum = 0\n",
    "    maximum = arr[0]\n",
    "    minimum = arr[0]\n",
    "    \n",
    "    for i in prange(len(arr)):\n",
    "        total_sum += arr[i]      # Automatic parallel sum\n",
    "        if arr[i] > maximum:\n",
    "            maximum = arr[i]      # Automatic parallel max\n",
    "        if arr[i] < minimum:\n",
    "            minimum = arr[i]      # Automatic parallel min\n",
    "    \n",
    "    return total_sum, maximum, minimum\n",
    "```\n",
    "\n",
    "### üîß Performance Considerations\n",
    "\n",
    "- **Array size matters**: Parallel overhead means small arrays might be slower\n",
    "- **Number of cores**: Speedup is limited by available CPU cores\n",
    "- **Memory bandwidth**: Very simple operations might be memory-bound\n",
    "- **Load balancing**: Numba automatically distributes work evenly\n",
    "\n",
    "### üìà Expected Speedups\n",
    "\n",
    "- **Typical range**: 2-8x speedup on quad-core to 8-core systems\n",
    "- **Best case**: Close to linear scaling with number of cores\n",
    "- **Worst case**: No speedup (or slower) for very simple operations or small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Monte Carlo Pi Estimation ===\n",
      "Estimating œÄ with 1,000,000 samples\n",
      "True value of œÄ: 3.141593\n",
      "\n",
      "Results:\n",
      "Python estimate:    3.140804 (error: 0.000789) - 1.6733s\n",
      "Numba estimate:     3.141368 (error: 0.000225) - 0.2625s\n",
      "Parallel estimate:  3.143076 (error: 0.001483) - 0.7440s\n",
      "\n",
      "Speedups:\n",
      "Numba speedup:    6.37x\n",
      "Parallel speedup: 2.25x\n"
     ]
    }
   ],
   "source": [
    "NUMBA_AVAILABLE = True\n",
    "\n",
    "# Practical Example: Monte Carlo Pi Estimation\n",
    "print(\"=== Monte Carlo Pi Estimation ===\")\n",
    "\n",
    "# Regular Python implementation\n",
    "def python_monte_carlo_pi(n_samples):\n",
    "    \"\"\"Estimate œÄ using Monte Carlo method - Python version\"\"\"\n",
    "    inside_circle = 0\n",
    "    for i in range(n_samples):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        if x*x + y*y <= 1.0:\n",
    "            inside_circle += 1\n",
    "    return 4.0 * inside_circle / n_samples\n",
    "\n",
    "# Numba-optimized implementation\n",
    "@njit\n",
    "def numba_monte_carlo_pi(n_samples):\n",
    "    \"\"\"Estimate œÄ using Monte Carlo method - Numba version\"\"\"\n",
    "    inside_circle = 0\n",
    "    for i in range(n_samples):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        if x*x + y*y <= 1.0:\n",
    "            inside_circle += 1\n",
    "    return 4.0 * inside_circle / n_samples\n",
    "\n",
    "# Parallel version\n",
    "if NUMBA_AVAILABLE:\n",
    "    @njit(parallel=True)\n",
    "    def parallel_monte_carlo_pi(n_samples):\n",
    "        \"\"\"Parallel Monte Carlo œÄ estimation\"\"\"\n",
    "        inside_circle = 0\n",
    "        for i in prange(n_samples):\n",
    "            x = np.random.random()\n",
    "            y = np.random.random()\n",
    "            if x*x + y*y <= 1.0:\n",
    "                inside_circle += 1\n",
    "        return 4.0 * inside_circle / n_samples\n",
    "else:\n",
    "    def parallel_monte_carlo_pi(n_samples):\n",
    "        return numba_monte_carlo_pi(n_samples)\n",
    "\n",
    "# Compare implementations\n",
    "n_samples = 1_000_000\n",
    "print(f\"Estimating œÄ with {n_samples:,} samples\")\n",
    "print(f\"True value of œÄ: {np.pi:.6f}\")\n",
    "\n",
    "# Python version\n",
    "start = time.time()\n",
    "python_pi = python_monte_carlo_pi(n_samples)\n",
    "python_mc_time = time.time() - start\n",
    "\n",
    "# Numba version\n",
    "start = time.time()\n",
    "numba_pi = numba_monte_carlo_pi(n_samples)\n",
    "numba_mc_time = time.time() - start\n",
    "\n",
    "# Parallel version\n",
    "start = time.time()\n",
    "parallel_pi = parallel_monte_carlo_pi(n_samples)\n",
    "parallel_mc_time = time.time() - start\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Python estimate:    {python_pi:.6f} (error: {abs(python_pi - np.pi):.6f}) - {python_mc_time:.4f}s\")\n",
    "print(f\"Numba estimate:     {numba_pi:.6f} (error: {abs(numba_pi - np.pi):.6f}) - {numba_mc_time:.4f}s\")\n",
    "print(f\"Parallel estimate:  {parallel_pi:.6f} (error: {abs(parallel_pi - np.pi):.6f}) - {parallel_mc_time:.4f}s\")\n",
    "\n",
    "if NUMBA_AVAILABLE and python_mc_time > 0:\n",
    "    numba_speedup = python_mc_time / numba_mc_time\n",
    "    parallel_speedup = python_mc_time / parallel_mc_time\n",
    "    print(f\"\\nSpeedups:\")\n",
    "    print(f\"Numba speedup:    {numba_speedup:.2f}x\")\n",
    "    print(f\"Parallel speedup: {parallel_speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation Overhead and When to Use Numba\n",
    "\n",
    "Understanding compilation overhead is crucial for effectively using Numba in your applications.\n",
    "\n",
    "### ‚è±Ô∏è Compilation Overhead\n",
    "\n",
    "**What is it?**\n",
    "- Time spent analyzing and compiling your function on the first call\n",
    "- Can range from milliseconds to several seconds depending on function complexity\n",
    "- Only happens once per function per set of input types\n",
    "\n",
    "**Example Timeline:**\n",
    "```\n",
    "First call:     [Compilation: 100ms] + [Execution: 1ms] = 101ms total\n",
    "Second call:    [Execution: 1ms] = 1ms total  \n",
    "Third call:     [Execution: 1ms] = 1ms total\n",
    "...\n",
    "```\n",
    "\n",
    "### üéØ Break-Even Analysis\n",
    "\n",
    "**When is Numba worth it?**\n",
    "\n",
    "Consider a function that:\n",
    "- Takes 100ms compilation time\n",
    "- Pure Python version takes 10ms per call\n",
    "- Numba version takes 0.1ms per call\n",
    "\n",
    "```\n",
    "Break-even calculation:\n",
    "Compilation time / (Python time - Numba time) = Number of calls to break even\n",
    "100ms / (10ms - 0.1ms) = 100ms / 9.9ms ‚âà 10 calls\n",
    "```\n",
    "\n",
    "After 10 calls, you start saving time!\n",
    "\n",
    "### üìä Use Case Categories\n",
    "\n",
    "#### ‚úÖ **Excellent for Numba:**\n",
    "- **Computational kernels**: Functions called many times\n",
    "- **Long-running computations**: Functions that take significant time\n",
    "- **Numerical algorithms**: Mathematical computations with loops\n",
    "- **Batch processing**: Processing large datasets\n",
    "\n",
    "```python\n",
    "# Perfect for Numba - called thousands of times\n",
    "@njit\n",
    "def distance_calculation(points1, points2):\n",
    "    distances = np.zeros(len(points1))\n",
    "    for i in range(len(points1)):\n",
    "        dx = points1[i][0] - points2[i][0]\n",
    "        dy = points1[i][1] - points2[i][1]\n",
    "        distances[i] = np.sqrt(dx*dx + dy*dy)\n",
    "    return distances\n",
    "```\n",
    "\n",
    "#### ‚ö†Ô∏è **Consider Carefully:**\n",
    "- **One-time computations**: Functions called only once\n",
    "- **Simple operations**: Already fast operations\n",
    "- **I/O bound code**: File reading, network operations\n",
    "- **String processing**: Text manipulation\n",
    "\n",
    "#### ‚ùå **Not Good for Numba:**\n",
    "- **Complex Python features**: Classes, decorators, generators\n",
    "- **External library calls**: Most non-NumPy libraries\n",
    "- **Exception-heavy code**: Frequent error handling\n",
    "\n",
    "### üöÄ Strategies for Optimization\n",
    "\n",
    "#### 1. **Eager Compilation**\n",
    "Pre-compile functions to avoid first-call overhead:\n",
    "\n",
    "```python\n",
    "from numba import njit\n",
    "import numba as nb\n",
    "\n",
    "# Specify exact types to pre-compile\n",
    "@njit('float64(float64[:])')  # Pre-compiled for float64 arrays\n",
    "def optimized_function(arr):\n",
    "    return np.sum(arr ** 2)\n",
    "\n",
    "# Alternative: Compile immediately\n",
    "@njit\n",
    "def another_function(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Force compilation\n",
    "another_function(1.0)  # Compile now\n",
    "```\n",
    "\n",
    "#### 2. **Warm-up Calls**\n",
    "Make a dummy call during initialization:\n",
    "\n",
    "```python\n",
    "@njit\n",
    "def my_algorithm(data):\n",
    "    # Complex algorithm here\n",
    "    return result\n",
    "\n",
    "# Warm-up during app startup\n",
    "dummy_data = np.array([1.0, 2.0, 3.0])\n",
    "my_algorithm(dummy_data)  # Compile now, not during critical path\n",
    "```\n",
    "\n",
    "#### 3. **Profile First**\n",
    "Always measure before optimizing:\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "def profile_function(func, *args, runs=100):\n",
    "    # Warm-up\n",
    "    func(*args)\n",
    "    \n",
    "    # Time multiple runs\n",
    "    start = time.time()\n",
    "    for _ in range(runs):\n",
    "        result = func(*args)\n",
    "    end = time.time()\n",
    "    \n",
    "    return (end - start) / runs, result\n",
    "\n",
    "python_time, _ = profile_function(python_version, data)\n",
    "numba_time, _ = profile_function(numba_version, data)\n",
    "print(f\"Speedup: {python_time / numba_time:.2f}x\")\n",
    "```\n",
    "\n",
    "### üéØ Decision Framework\n",
    "\n",
    "**Use Numba when:**\n",
    "1. ‚úÖ Function is called multiple times (>10-100 times)\n",
    "2. ‚úÖ Function contains numerical computations\n",
    "3. ‚úÖ Function has loops or array operations\n",
    "4. ‚úÖ Current performance is a bottleneck\n",
    "\n",
    "**Don't use Numba when:**\n",
    "1. ‚ùå Function is called only once\n",
    "2. ‚ùå Function is already fast enough\n",
    "3. ‚ùå Function uses unsupported Python features\n",
    "4. ‚ùå Development time outweighs performance gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Algorithm: Solving Differential Equations\n",
    "print(\"=== Solving Differential Equations with Numba ===\")\n",
    "\n",
    "# Example: Simple harmonic oscillator dy/dt = -k*y\n",
    "# Analytical solution: y(t) = y0 * cos(sqrt(k)*t)\n",
    "\n",
    "def python_euler_method(y0, k, dt, n_steps):\n",
    "    \"\"\"Euler method for solving dy/dt = -k*y - Python version\"\"\"\n",
    "    y = np.zeros(n_steps)\n",
    "    y[0] = y0\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        y[i] = y[i-1] + dt * (-k * y[i-1])\n",
    "    \n",
    "    return y\n",
    "\n",
    "@njit\n",
    "def numba_euler_method(y0, k, dt, n_steps):\n",
    "    \"\"\"Euler method for solving dy/dt = -k*y - Numba version\"\"\"\n",
    "    y = np.zeros(n_steps)\n",
    "    y[0] = y0\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        y[i] = y[i-1] + dt * (-k * y[i-1])\n",
    "    \n",
    "    return y\n",
    "\n",
    "@njit\n",
    "def numba_runge_kutta_4(y0, k, dt, n_steps):\n",
    "    \"\"\"4th-order Runge-Kutta method - Numba optimized\"\"\"\n",
    "    y = np.zeros(n_steps)\n",
    "    y[0] = y0\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        y_curr = y[i-1]\n",
    "        \n",
    "        k1 = dt * (-k * y_curr)\n",
    "        k2 = dt * (-k * (y_curr + k1/2))\n",
    "        k3 = dt * (-k * (y_curr + k2/2))\n",
    "        k4 = dt * (-k * (y_curr + k3))\n",
    "        \n",
    "        y[i] = y_curr + (k1 + 2*k2 + 2*k3 + k4) / 6\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Setup problem parameters\n",
    "y0 = 1.0      # Initial condition\n",
    "k = 1.0       # Spring constant\n",
    "dt = 0.01     # Time step\n",
    "n_steps = 10000\n",
    "t_final = (n_steps - 1) * dt\n",
    "\n",
    "print(f\"Solving dy/dt = -k*y with y(0) = {y0}, k = {k}\")\n",
    "print(f\"Time steps: {n_steps}, dt = {dt}, final time = {t_final}\")\n",
    "\n",
    "# Compare methods and timing\n",
    "start = time.time()\n",
    "python_solution = python_euler_method(y0, k, dt, n_steps)\n",
    "python_ode_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "numba_euler = numba_euler_method(y0, k, dt, n_steps)\n",
    "numba_euler_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "numba_rk4 = numba_runge_kutta_4(y0, k, dt, n_steps)\n",
    "numba_rk4_time = time.time() - start\n",
    "\n",
    "# Analytical solution for comparison\n",
    "t = np.linspace(0, t_final, n_steps)\n",
    "analytical = y0 * np.cos(np.sqrt(k) * t)\n",
    "\n",
    "print(f\"\\nTiming results:\")\n",
    "print(f\"Python Euler:     {python_ode_time:.6f} seconds\")\n",
    "print(f\"Numba Euler:      {numba_euler_time:.6f} seconds\")\n",
    "print(f\"Numba RK4:        {numba_rk4_time:.6f} seconds\")\n",
    "\n",
    "if NUMBA_AVAILABLE and python_ode_time > 0:\n",
    "    euler_speedup = python_ode_time / numba_euler_time\n",
    "    print(f\"Euler speedup:    {euler_speedup:.2f}x\")\n",
    "\n",
    "# Check accuracy at final time\n",
    "final_analytical = analytical[-1]\n",
    "final_python = python_solution[-1]\n",
    "final_numba_euler = numba_euler[-1]\n",
    "final_numba_rk4 = numba_rk4[-1]\n",
    "\n",
    "print(f\"\\nAccuracy at t = {t_final}:\")\n",
    "print(f\"Analytical:       {final_analytical:.6f}\")\n",
    "print(f\"Python Euler:     {final_python:.6f} (error: {abs(final_python - final_analytical):.6f})\")\n",
    "print(f\"Numba Euler:      {final_numba_euler:.6f} (error: {abs(final_numba_euler - final_analytical):.6f})\")\n",
    "print(f\"Numba RK4:        {final_numba_rk4:.6f} (error: {abs(final_numba_rk4 - final_analytical):.6f})\")\n",
    "\n",
    "print(f\"\\nRK4 is {abs(final_numba_euler - final_analytical) / abs(final_numba_rk4 - final_analytical):.1f}x more accurate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba Supported vs Unsupported Features\n",
    "\n",
    "Understanding what Numba can and cannot compile is essential for writing efficient Numba code.\n",
    "\n",
    "### ‚úÖ **Fully Supported Features**\n",
    "\n",
    "#### **Basic Python:**\n",
    "- Arithmetic operations (`+`, `-`, `*`, `/`, `**`, `//`, `%`)\n",
    "- Comparison operations (`==`, `!=`, `<`, `>`, `<=`, `>=`)\n",
    "- Boolean operations (`and`, `or`, `not`)\n",
    "- Control flow (`if`, `for`, `while`, `break`, `continue`)\n",
    "- Basic functions (`len`, `range`, `enumerate`, `zip`)\n",
    "\n",
    "#### **NumPy Support:**\n",
    "- All basic NumPy array operations\n",
    "- Mathematical functions (`np.sin`, `np.cos`, `np.sqrt`, `np.exp`, etc.)\n",
    "- Array creation (`np.zeros`, `np.ones`, `np.empty`, `np.arange`)\n",
    "- Array indexing and slicing\n",
    "- Broadcasting operations\n",
    "- Reductions (`np.sum`, `np.mean`, `np.max`, `np.min`)\n",
    "\n",
    "```python\n",
    "@njit\n",
    "def supported_operations(arr1, arr2):\n",
    "    # All of these work perfectly with Numba\n",
    "    result = np.zeros_like(arr1)\n",
    "    \n",
    "    for i in range(len(arr1)):\n",
    "        if arr1[i] > 0:\n",
    "            result[i] = np.sqrt(arr1[i]) + np.sin(arr2[i])\n",
    "        else:\n",
    "            result[i] = arr1[i] ** 2\n",
    "    \n",
    "    return np.sum(result), np.max(result)\n",
    "```\n",
    "\n",
    "#### **Supported Data Types:**\n",
    "- Integers: `int32`, `int64`, `uint32`, `uint64`\n",
    "- Floats: `float32`, `float64`\n",
    "- Complex: `complex64`, `complex128`\n",
    "- Booleans: `bool`\n",
    "- NumPy arrays of supported types\n",
    "- Tuples (with supported element types)\n",
    "\n",
    "### ‚ö†Ô∏è **Partially Supported Features**\n",
    "\n",
    "#### **Lists:**\n",
    "- Homogeneous lists (all elements same type) ‚úÖ\n",
    "- Heterogeneous lists (mixed types) ‚ùå\n",
    "\n",
    "```python\n",
    "@njit\n",
    "def list_example():\n",
    "    # ‚úÖ This works - homogeneous list\n",
    "    numbers = [1.0, 2.0, 3.0, 4.0]\n",
    "    \n",
    "    # ‚ùå This doesn't work - mixed types\n",
    "    # mixed = [1, 2.0, \"hello\"]  # Would cause compilation error\n",
    "    \n",
    "    return sum(numbers)\n",
    "```\n",
    "\n",
    "#### **Dictionaries:**\n",
    "- Simple dictionaries with supported key/value types ‚úÖ\n",
    "- Complex nested dictionaries ‚ùå\n",
    "\n",
    "### ‚ùå **Unsupported Features**\n",
    "\n",
    "#### **Python Objects:**\n",
    "- Custom classes and objects\n",
    "- Class methods and attributes\n",
    "- Object-oriented programming features\n",
    "\n",
    "```python\n",
    "# ‚ùå This won't work with @njit\n",
    "class MyClass:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def compute(self):\n",
    "        return self.value ** 2\n",
    "\n",
    "@njit  # This would fail\n",
    "def use_class():\n",
    "    obj = MyClass(5)\n",
    "    return obj.compute()\n",
    "```\n",
    "\n",
    "#### **String Operations:**\n",
    "- String manipulation\n",
    "- Regular expressions\n",
    "- String formatting\n",
    "\n",
    "```python\n",
    "# ‚ùå These don't work with @njit\n",
    "@njit\n",
    "def string_operations(text):\n",
    "    # None of these work in Numba\n",
    "    # result = text.upper()\n",
    "    # split_text = text.split(\",\")\n",
    "    # formatted = f\"Result: {text}\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "#### **File I/O and External Libraries:**\n",
    "- File reading/writing\n",
    "- Network operations\n",
    "- Most third-party libraries (except NumPy)\n",
    "\n",
    "#### **Advanced Python Features:**\n",
    "- Generators and iterators\n",
    "- Decorators\n",
    "- Context managers (`with` statements)\n",
    "- Exception handling (limited support)\n",
    "\n",
    "### üîß **Workarounds and Solutions**\n",
    "\n",
    "#### **1. Split Functions:**\n",
    "Separate Numba-compatible code from incompatible code:\n",
    "\n",
    "```python\n",
    "# Pure computational kernel - perfect for Numba\n",
    "@njit\n",
    "def compute_kernel(data):\n",
    "    result = np.zeros_like(data)\n",
    "    for i in range(len(data)):\n",
    "        result[i] = data[i] ** 2 + np.sin(data[i])\n",
    "    return result\n",
    "\n",
    "# Main function - handles I/O and object creation\n",
    "def main_function(filename):\n",
    "    # File I/O in regular Python\n",
    "    data = np.loadtxt(filename)\n",
    "    \n",
    "    # Computation in Numba\n",
    "    result = compute_kernel(data)\n",
    "    \n",
    "    # Save results in regular Python\n",
    "    np.savetxt(\"output.txt\", result)\n",
    "    return result\n",
    "```\n",
    "\n",
    "#### **2. Data Structure Conversion:**\n",
    "Convert complex structures to Numba-compatible formats:\n",
    "\n",
    "```python\n",
    "# Convert dictionary to arrays\n",
    "def dict_to_arrays(data_dict):\n",
    "    keys = np.array(list(data_dict.keys()))\n",
    "    values = np.array(list(data_dict.values()))\n",
    "    return keys, values\n",
    "\n",
    "@njit\n",
    "def process_arrays(keys, values):\n",
    "    # Process with Numba\n",
    "    return np.sum(values * keys)\n",
    "\n",
    "# Usage\n",
    "data = {1: 10, 2: 20, 3: 30}\n",
    "k, v = dict_to_arrays(data)\n",
    "result = process_arrays(k, v)\n",
    "```\n",
    "\n",
    "#### **3. Type Hints for Clarity:**\n",
    "Use explicit typing to catch incompatibilities early:\n",
    "\n",
    "```python\n",
    "from numba import njit, float64, int64\n",
    "\n",
    "@njit(float64(float64[:], int64))\n",
    "def typed_function(arr, n):\n",
    "    # Explicit types make requirements clear\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "```\n",
    "\n",
    "### üéØ **Development Strategy**\n",
    "\n",
    "1. **Start simple**: Begin with basic numerical operations\n",
    "2. **Test incrementally**: Add complexity gradually and test compilation\n",
    "3. **Profile bottlenecks**: Focus on the slowest parts of your code\n",
    "4. **Use fallbacks**: Keep Python versions for unsupported features\n",
    "5. **Read error messages**: Numba provides helpful compilation error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba Best Practices and Common Pitfalls\n",
    "print(\"=== Numba Best Practices ===\")\n",
    "\n",
    "# Example of what works well with Numba\n",
    "@njit\n",
    "def numba_friendly_function(arr):\n",
    "    \"\"\"Functions that work well with Numba\"\"\"\n",
    "    # ‚úÖ Numerical computations\n",
    "    # ‚úÖ Loops with numerical operations\n",
    "    # ‚úÖ NumPy arrays and basic math functions\n",
    "    result = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        result += arr[i] ** 2 + np.sin(arr[i])\n",
    "    return result\n",
    "\n",
    "# Example of what doesn't work well\n",
    "def numba_unfriendly_function(data):\n",
    "    \"\"\"Functions that don't work well with Numba (can't be compiled)\"\"\"\n",
    "    # ‚ùå Python lists with mixed types\n",
    "    # ‚ùå String operations\n",
    "    # ‚ùå Complex Python objects\n",
    "    # ‚ùå File I/O operations\n",
    "    \n",
    "    # This would fail with @njit\n",
    "    result = []\n",
    "    for item in data:\n",
    "        if isinstance(item, str):\n",
    "            result.append(len(item))\n",
    "        else:\n",
    "            result.append(item * 2)\n",
    "    return result\n",
    "\n",
    "# Demonstrate compilation overhead\n",
    "@njit\n",
    "def simple_function(x):\n",
    "    return x ** 2\n",
    "\n",
    "print(\"Compilation overhead demonstration:\")\n",
    "\n",
    "# First call includes compilation time\n",
    "start = time.time()\n",
    "result1 = simple_function(5.0)\n",
    "first_call_time = time.time() - start\n",
    "\n",
    "# Second call is much faster (already compiled)\n",
    "start = time.time()\n",
    "result2 = simple_function(10.0)\n",
    "second_call_time = time.time() - start\n",
    "\n",
    "print(f\"First call (with compilation):  {first_call_time:.6f} seconds\")\n",
    "print(f\"Second call (already compiled): {second_call_time:.6f} seconds\")\n",
    "print(f\"Compilation overhead: {(first_call_time - second_call_time) * 1000:.2f} milliseconds\")\n",
    "\n",
    "# Type stability example\n",
    "@njit\n",
    "def type_stable_function(arr):\n",
    "    \"\"\"Type-stable function (good for Numba)\"\"\"\n",
    "    total = 0.0  # Always float\n",
    "    for val in arr:\n",
    "        total += val\n",
    "    return total\n",
    "\n",
    "print(f\"\\nTesting type-stable function:\")\n",
    "test_arr = np.array([1.5, 2.3, 3.7, 4.1])\n",
    "result = type_stable_function(test_arr)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NUMBA BEST PRACTICES SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_practices = \"\"\"\n",
    "‚úÖ DO:\n",
    "‚Ä¢ Use for numerical computations and tight loops\n",
    "‚Ä¢ Work with NumPy arrays and basic math functions\n",
    "‚Ä¢ Keep functions type-stable (consistent types)\n",
    "‚Ä¢ Use @njit for maximum performance\n",
    "‚Ä¢ Consider @njit(parallel=True) for parallelizable loops\n",
    "‚Ä¢ Profile your code to identify bottlenecks first\n",
    "\n",
    "‚ùå DON'T:\n",
    "‚Ä¢ Use for string manipulation or file I/O\n",
    "‚Ä¢ Mix different data types in the same array\n",
    "‚Ä¢ Use Python lists with mixed types\n",
    "‚Ä¢ Expect speedup for single function calls (compilation overhead)\n",
    "‚Ä¢ Use for functions that are already fast enough\n",
    "\n",
    "üîß OPTIMIZATION TIPS:\n",
    "‚Ä¢ Use explicit types: @njit('float64(float64[:])')\n",
    "‚Ä¢ Avoid object mode compilation\n",
    "‚Ä¢ Use parallel=True for independent iterations\n",
    "‚Ä¢ Consider using numba.typed containers for complex data\n",
    "‚Ä¢ Pre-compile with eager compilation for production\n",
    "\n",
    "‚ö° WHEN TO USE NUMBA:\n",
    "‚Ä¢ Numerical algorithms with loops\n",
    "‚Ä¢ Scientific computing applications\n",
    "‚Ä¢ Monte Carlo simulations\n",
    "‚Ä¢ Image/signal processing\n",
    "‚Ä¢ Machine learning computations\n",
    "‚Ä¢ Any CPU-bound numerical code\n",
    "\"\"\"\n",
    "\n",
    "print(best_practices)\n",
    "\n",
    "# Performance summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(\"üöÄ Typical speedups with Numba:\")\n",
    "print(\"‚Ä¢ Simple loops: 10-100x faster\")\n",
    "print(\"‚Ä¢ Numerical algorithms: 50-1000x faster\") \n",
    "print(\"‚Ä¢ Monte Carlo methods: 100-500x faster\")\n",
    "print(\"‚Ä¢ Matrix operations: 2-50x faster (depends on size)\")\n",
    "print(\"‚Ä¢ Parallel algorithms: Additional 2-8x on multi-core systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Inference and Explicit Typing in Numba\n",
    "\n",
    "Understanding how Numba handles types is crucial for writing efficient and reliable compiled code.\n",
    "\n",
    "### üîç **Automatic Type Inference**\n",
    "\n",
    "By default, Numba automatically infers types from function arguments:\n",
    "\n",
    "```python\n",
    "@njit\n",
    "def auto_typed_function(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Numba infers types from actual arguments:\n",
    "result1 = auto_typed_function(5, 3)        # int64, int64 ‚Üí int64\n",
    "result2 = auto_typed_function(5.0, 3.0)    # float64, float64 ‚Üí float64\n",
    "result3 = auto_typed_function(5, 3.0)      # int64, float64 ‚Üí float64\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Easy to use - no type annotations needed\n",
    "- ‚úÖ Flexible - works with different input types\n",
    "- ‚úÖ Automatic promotion - handles mixed types sensibly\n",
    "\n",
    "**Disadvantages:**\n",
    "- ‚ö†Ô∏è Multiple compilations - different types create different compiled versions\n",
    "- ‚ö†Ô∏è Compilation overhead - each new type combination triggers compilation\n",
    "- ‚ö†Ô∏è Larger memory usage - multiple compiled versions stored\n",
    "\n",
    "### üéØ **Explicit Type Signatures**\n",
    "\n",
    "You can specify exact types to control compilation:\n",
    "\n",
    "```python\n",
    "from numba import njit, float64, int64, void\n",
    "\n",
    "# Single signature - only accepts these exact types\n",
    "@njit('float64(float64, float64)')\n",
    "def explicit_typed_function(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Multiple signatures - pre-compile for specific combinations\n",
    "@njit(['float64(float64, float64)', \n",
    "       'int64(int64, int64)',\n",
    "       'float64(int64, float64)'])\n",
    "def multi_signature_function(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Array signatures\n",
    "@njit('float64[:](float64[:])')  # 1D array input and output\n",
    "def array_function(arr):\n",
    "    return arr * 2\n",
    "\n",
    "# Void function (no return value)\n",
    "@njit('void(float64[:], float64)')\n",
    "def inplace_function(arr, value):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] += value\n",
    "```\n",
    "\n",
    "### üìã **Common Type Annotations**\n",
    "\n",
    "#### **Basic Types:**\n",
    "- `int8`, `int16`, `int32`, `int64` - Signed integers\n",
    "- `uint8`, `uint16`, `uint32`, `uint64` - Unsigned integers  \n",
    "- `float32`, `float64` - Floating point numbers\n",
    "- `complex64`, `complex128` - Complex numbers\n",
    "- `boolean` - Boolean values\n",
    "\n",
    "#### **Array Types:**\n",
    "- `float64[:]` - 1D array\n",
    "- `float64[:,:]` - 2D array\n",
    "- `float64[:,:,:]` - 3D array\n",
    "- `float64[::1]` - Contiguous 1D array (faster)\n",
    "\n",
    "#### **Container Types:**\n",
    "- `(float64, int64)` - Tuple with specific types\n",
    "- `ListType(float64)` - Homogeneous list\n",
    "\n",
    "### ‚ö° **Performance Implications**\n",
    "\n",
    "#### **Type Stability:**\n",
    "Keep variable types consistent throughout the function:\n",
    "\n",
    "```python\n",
    "# ‚ùå Type unstable - poor performance\n",
    "@njit\n",
    "def type_unstable():\n",
    "    x = 5        # int64\n",
    "    x = 5.0      # Now float64 - type changed!\n",
    "    return x\n",
    "\n",
    "# ‚úÖ Type stable - good performance  \n",
    "@njit\n",
    "def type_stable():\n",
    "    x = 5.0      # float64\n",
    "    x = x + 1.0  # Still float64\n",
    "    return x\n",
    "```\n",
    "\n",
    "#### **Array Contiguity:**\n",
    "Specify contiguous arrays for better performance:\n",
    "\n",
    "```python\n",
    "# Standard array - may not be contiguous\n",
    "@njit('float64[:](float64[:])')\n",
    "def standard_array_func(arr):\n",
    "    return arr * 2\n",
    "\n",
    "# Contiguous array - guaranteed contiguous, faster\n",
    "@njit('float64[::1](float64[::1])')\n",
    "def contiguous_array_func(arr):\n",
    "    return arr * 2\n",
    "```\n",
    "\n",
    "### üîß **Best Practices for Typing**\n",
    "\n",
    "#### **1. Start with Auto-Inference:**\n",
    "```python\n",
    "# Begin development with automatic inference\n",
    "@njit\n",
    "def develop_function(data):\n",
    "    # Develop and test your algorithm\n",
    "    return process_data(data)\n",
    "```\n",
    "\n",
    "#### **2. Add Explicit Types for Production:**\n",
    "```python\n",
    "# Add explicit types once algorithm is stable\n",
    "@njit('float64[:](float64[:], float64)')\n",
    "def production_function(data, parameter):\n",
    "    # Same algorithm, but with explicit types\n",
    "    return process_data(data, parameter)\n",
    "```\n",
    "\n",
    "#### **3. Use Type Checking During Development:**\n",
    "```python\n",
    "from numba import types\n",
    "\n",
    "@njit\n",
    "def debug_types(x, y):\n",
    "    # This helps debug type issues\n",
    "    print(\"x type:\", type(x))\n",
    "    print(\"y type:\", type(y))\n",
    "    return x + y\n",
    "```\n",
    "\n",
    "#### **4. Handle Type Errors Gracefully:**\n",
    "```python\n",
    "try:\n",
    "    @njit('int64(int64, int64)')\n",
    "    def strict_function(x, y):\n",
    "        return x + y\n",
    "    \n",
    "    # This will work\n",
    "    result = strict_function(5, 3)\n",
    "    \n",
    "    # This will raise TypeError\n",
    "    # result = strict_function(5.0, 3.0)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Type error: {e}\")\n",
    "    \n",
    "    # Fallback to auto-inference\n",
    "    @njit\n",
    "    def flexible_function(x, y):\n",
    "        return x + y\n",
    "    \n",
    "    result = flexible_function(5.0, 3.0)\n",
    "```\n",
    "\n",
    "### üéØ **When to Use Explicit Typing**\n",
    "\n",
    "#### **Use Explicit Types When:**\n",
    "- ‚úÖ Function is performance-critical\n",
    "- ‚úÖ You want to prevent accidental type changes\n",
    "- ‚úÖ You're building a library with consistent interface\n",
    "- ‚úÖ You want to catch type errors early\n",
    "\n",
    "#### **Use Auto-Inference When:**\n",
    "- ‚úÖ Prototyping and development\n",
    "- ‚úÖ Functions need to handle multiple input types\n",
    "- ‚úÖ Convenience is more important than maximum performance\n",
    "- ‚úÖ You're not sure what types you'll need\n",
    "\n",
    "### üìä **Type Signature Examples**\n",
    "\n",
    "```python\n",
    "# Function signatures follow pattern: 'return_type(arg1_type, arg2_type, ...)'\n",
    "\n",
    "@njit('float64(float64)')                    # f(x: float) ‚Üí float\n",
    "@njit('float64[:](float64[:], float64)')     # f(arr: float[], scalar: float) ‚Üí float[]\n",
    "@njit('(float64, int64)(float64[:])')        # f(arr: float[]) ‚Üí (float, int)\n",
    "@njit('void(float64[:], float64)')           # f(arr: float[], val: float) ‚Üí None\n",
    "@njit('float64[:,::1](float64[:,::1])')      # f(matrix: float[][]) ‚Üí float[][]\n",
    "```\n",
    "\n",
    "Understanding these concepts will help you write more efficient and reliable Numba code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Collections - Specialized Data Structures\n",
    "\n",
    "The `collections` module provides specialized data structures that extend Python's built-in data types with additional functionality and improved performance for specific use cases.\n",
    "\n",
    "## Key Collections Classes\n",
    "\n",
    "- **Counter**: Count hashable objects\n",
    "- **defaultdict**: Dictionary with default values\n",
    "- **deque**: Double-ended queue for efficient append/pop\n",
    "- **namedtuple**: Tuple subclass with named fields\n",
    "- **OrderedDict**: Dictionary that remembers insertion order\n",
    "- **ChainMap**: Combine multiple dictionaries\n",
    "\n",
    "## Why Use Collections?\n",
    "\n",
    "- **Performance**: Optimized implementations for specific patterns\n",
    "- **Convenience**: Less boilerplate code\n",
    "- **Readability**: More expressive than standard types\n",
    "- **Memory efficient**: Specialized storage for specific use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Counter Examples ===\n",
      "Character count: Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n"
     ]
    }
   ],
   "source": [
    "# Counter - Counting Hashable Objects\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "\n",
    "print(\"=== Counter Examples ===\")\n",
    "\n",
    "# Basic counting\n",
    "text = \"hello world\"\n",
    "char_count = Counter(text)\n",
    "print(f\"Character count: {char_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: Counter({'apple': 3, 'banana': 2, 'cherry': 1})\n",
      "Most common: [('apple', 3), ('banana', 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count words in text\n",
    "words = [\"apple\", \"banana\", \"apple\", \"cherry\", \"banana\", \"apple\"]\n",
    "word_count = Counter(words)\n",
    "print(f\"Word count: {word_count}\")\n",
    "\n",
    "# Most common elements\n",
    "print(f\"Most common: {word_count.most_common(2)}\")\n",
    "\n",
    "# Counter arithmetic\n",
    "counter1 = Counter(['a', 'b', 'c', 'a'])\n",
    "counter2 = Counter(['a', 'b', 'b', 'd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter 1: Counter({'a': 2, 'b': 1, 'c': 1})\n",
      "Counter 2: Counter({'b': 2, 'a': 1, 'd': 1})\n",
      "Addition: Counter({'a': 3, 'b': 3, 'c': 1, 'd': 1})\n",
      "Subtraction: Counter({'a': 1, 'c': 1})\n",
      "Intersection: Counter({'a': 1, 'b': 1})\n",
      "Union: Counter({'a': 2, 'b': 2, 'c': 1, 'd': 1})\n",
      "After update: Counter({'a': 2, 'e': 2, 'b': 1, 'c': 1, 'f': 1})\n",
      "Total items: 7\n",
      "All elements: ['a', 'a', 'b', 'c', 'e', 'e', 'f']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Counter 1: {counter1}\")\n",
    "print(f\"Counter 2: {counter2}\")\n",
    "print(f\"Addition: {counter1 + counter2}\")\n",
    "print(f\"Subtraction: {counter1 - counter2}\")\n",
    "print(f\"Intersection: {counter1 & counter2}\")\n",
    "print(f\"Union: {counter1 | counter2}\")\n",
    "\n",
    "# Update counter\n",
    "counter1.update(['e', 'e', 'f'])\n",
    "print(f\"After update: {counter1}\")\n",
    "\n",
    "# Total count\n",
    "print(f\"Total items: {sum(counter1.values())}\")\n",
    "\n",
    "# Elements (repeat each element count times)\n",
    "print(f\"All elements: {list(counter1.elements())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== defaultdict Examples ===\n",
      "Regular dict:\n",
      "KeyError: 'missing_key' not found\n"
     ]
    }
   ],
   "source": [
    "# defaultdict - Dictionary with Default Values\n",
    "print(\"=== defaultdict Examples ===\")\n",
    "\n",
    "# Compare regular dict vs defaultdict\n",
    "print(\"Regular dict:\")\n",
    "regular_dict = {}\n",
    "try:\n",
    "    print(regular_dict['missing_key'])\n",
    "except KeyError:\n",
    "    print(\"KeyError: 'missing_key' not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "defaultdict with list:\n",
      "list_dict: {'fruits': ['apple', 'banana'], 'vegetables': ['carrot']}\n",
      "Missing key returns: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\ndefaultdict with list:\")\n",
    "list_dict = defaultdict(list)\n",
    "list_dict['fruits'].append('apple')\n",
    "list_dict['fruits'].append('banana')\n",
    "list_dict['vegetables'].append('carrot')\n",
    "print(f\"list_dict: {dict(list_dict)}\")\n",
    "print(f\"Missing key returns: {list_dict['missing']}\")  # Returns empty list\n",
    "\n",
    "# Different default factories\n",
    "int_dict = defaultdict(int)  # Default value: 0\n",
    "int_dict['count'] += 1\n",
    "int_dict['total'] += 5\n",
    "print(f\"int_dict: {dict(int_dict)}\")\n",
    "print(f\"Missing key returns: {int_dict['new_key']}\")  # Returns 0\n",
    "\n",
    "set_dict = defaultdict(set)  # Default value: empty set\n",
    "set_dict['tags'].add('python')\n",
    "set_dict['tags'].add('programming')\n",
    "print(f\"set_dict: {dict(set_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequencies: {'the': 2, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Word frequency using defaultdict\n",
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "word_freq = defaultdict(lambda: 0)\n",
    "for word in text.split():\n",
    "    word_freq[word] += 1\n",
    "\n",
    "print(f\"Word frequencies: {dict(word_freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== namedtuple Examples ===\n",
      "Point p1: Point(x=3, y=4)\n",
      "Point p2: Point(x=1, y=2)\n",
      "Person: Person(name='Alice', age=30, city='New York')\n"
     ]
    }
   ],
   "source": [
    "# namedtuple - Tuple Subclass with Named Fields\n",
    "print(\"=== namedtuple Examples ===\")\n",
    "\n",
    "# Create a namedtuple class\n",
    "Point = namedtuple('Point', ['x', 'y'])\n",
    "Person = namedtuple('Person', ['name', 'age', 'city'])\n",
    "\n",
    "# Create instances\n",
    "p1 = Point(3, 4)\n",
    "p2 = Point(x=1, y=2)  # Can use keyword arguments\n",
    "person = Person('Alice', 30, 'New York')\n",
    "\n",
    "print(f\"Point p1: {p1}\")\n",
    "print(f\"Point p2: {p2}\")\n",
    "print(f\"Person: {person}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1.x = 3, p1.y = 4\n",
      "Person name: Alice, age: 30\n",
      "p1[0] = 3, p1[1] = 4\n",
      "Unpacked: x=3, y=4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Access fields by name (more readable than tuple[0])\n",
    "print(f\"p1.x = {p1.x}, p1.y = {p1.y}\")\n",
    "print(f\"Person name: {person.name}, age: {person.age}\")\n",
    "\n",
    "# Still works like a tuple\n",
    "print(f\"p1[0] = {p1[0]}, p1[1] = {p1[1]}\")\n",
    "x, y = p1  # Unpacking works\n",
    "print(f\"Unpacked: x={x}, y={y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "p1.x = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields: ('name', 'age', 'city')\n",
      "As dict: {'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
      "Updated person: Person(name='Alice', age=31, city='New York')\n",
      "\n",
      "Benefits of namedtuple:\n",
      "‚úÖ More readable than tuple[index]\n",
      "‚úÖ More memory efficient than dict\n",
      "‚úÖ Immutable (like tuples)\n",
      "‚úÖ Works with all tuple operations\n",
      "‚úÖ Self-documenting field names\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# namedtuple methods\n",
    "print(f\"Fields: {person._fields}\")\n",
    "print(f\"As dict: {person._asdict()}\")\n",
    "\n",
    "# Create new instance with some fields changed\n",
    "person2 = person._replace(age=31)\n",
    "print(f\"Updated person: {person2}\")\n",
    "\n",
    "# Benefits over regular tuples and dicts\n",
    "print(\"\\nBenefits of namedtuple:\")\n",
    "print(\"‚úÖ More readable than tuple[index]\")\n",
    "print(\"‚úÖ More memory efficient than dict\")\n",
    "print(\"‚úÖ Immutable (like tuples)\")\n",
    "print(\"‚úÖ Works with all tuple operations\")\n",
    "print(\"‚úÖ Self-documenting field names\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Functools - Functional Programming Utilities\n",
    "\n",
    "The `functools` module provides utilities for working with higher-order functions and operations on callable objects. It's essential for functional programming patterns in Python.\n",
    "\n",
    "## Key Functools Features\n",
    "\n",
    "- **@lru_cache**: Memoization for expensive function calls\n",
    "- **@wraps**: Proper decorator creation\n",
    "- **partial**: Create partial function applications\n",
    "- **reduce**: Apply function cumulatively to sequence\n",
    "- **singledispatch**: Function overloading based on type\n",
    "- **@cached_property**: Cached property decorator\n",
    "\n",
    "## Why Use Functools?\n",
    "\n",
    "- **Performance**: Caching and memoization\n",
    "- **Code reuse**: Partial function applications\n",
    "- **Clean decorators**: Proper metadata preservation\n",
    "- **Functional patterns**: Reduce, dispatch, composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @lru_cache - Memoization for Performance\n",
    "import functools\n",
    "import time\n",
    "\n",
    "print(\"=== @lru_cache Examples ===\")\n",
    "\n",
    "# Expensive function without caching\n",
    "def fibonacci_slow(n):\n",
    "    \"\"\"Slow recursive fibonacci\"\"\"\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci_slow(n-1) + fibonacci_slow(n-2)\n",
    "\n",
    "# Same function with caching\n",
    "@functools.lru_cache(maxsize=128)\n",
    "def fibonacci_cached(n):\n",
    "    \"\"\"Fast cached fibonacci\"\"\"\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci_cached(n-1) + fibonacci_cached(n-2)\n",
    "\n",
    "# Performance comparison\n",
    "def time_function(func, n):\n",
    "    start = time.time()\n",
    "    result = func(n)\n",
    "    end = time.time()\n",
    "    return result, end - start\n",
    "\n",
    "# Test with smaller number for slow version\n",
    "n = 30\n",
    "result_slow, time_slow = time_function(fibonacci_slow, n)\n",
    "result_cached, time_cached = time_function(fibonacci_cached, n)\n",
    "\n",
    "print(f\"Fibonacci({n}):\")\n",
    "print(f\"Without cache: {result_slow} (took {time_slow:.6f} seconds)\")\n",
    "print(f\"With cache:    {result_cached} (took {time_cached:.6f} seconds)\")\n",
    "print(f\"Speedup: {time_slow / time_cached:.1f}x faster!\")\n",
    "\n",
    "# Cache statistics\n",
    "print(f\"Cache info: {fibonacci_cached.cache_info()}\")\n",
    "\n",
    "# Clear cache\n",
    "fibonacci_cached.cache_clear()\n",
    "print(f\"After clearing cache: {fibonacci_cached.cache_info()}\")\n",
    "\n",
    "# Different cache sizes\n",
    "@functools.lru_cache(maxsize=None)  # Unlimited cache\n",
    "def unlimited_cache_func(x):\n",
    "    return x ** 2\n",
    "\n",
    "@functools.lru_cache(maxsize=2)  # Very small cache\n",
    "def small_cache_func(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Test cache behavior\n",
    "print(\"\\nCache behavior with different sizes:\")\n",
    "for i in range(5):\n",
    "    small_cache_func(i)\n",
    "    \n",
    "print(f\"Small cache info: {small_cache_func.cache_info()}\")\n",
    "\n",
    "# Practical example: API call caching\n",
    "@functools.lru_cache(maxsize=100)\n",
    "def fetch_user_data(user_id):\n",
    "    \"\"\"Simulate expensive API call\"\"\"\n",
    "    print(f\"Fetching data for user {user_id}...\")\n",
    "    time.sleep(0.1)  # Simulate network delay\n",
    "    return {'id': user_id, 'name': f'User{user_id}', 'email': f'user{user_id}@example.com'}\n",
    "\n",
    "# First calls are slow\n",
    "start = time.time()\n",
    "for user_id in [1, 2, 3, 1, 2]:  # Note: 1 and 2 are repeated\n",
    "    user_data = fetch_user_data(user_id)\n",
    "    print(f\"Got: {user_data['name']}\")\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Total time: {end - start:.2f} seconds\")\n",
    "print(f\"Cache info: {fetch_user_data.cache_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce and Other Functools Utilities\n",
    "print(\"=== reduce Examples ===\")\n",
    "\n",
    "# reduce applies function cumulatively to sequence\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Sum using reduce\n",
    "total = functools.reduce(lambda x, y: x + y, numbers)\n",
    "print(f\"Sum of {numbers} = {total}\")\n",
    "\n",
    "# Product using reduce\n",
    "product = functools.reduce(lambda x, y: x * y, numbers)\n",
    "print(f\"Product of {numbers} = {product}\")\n",
    "\n",
    "# Maximum using reduce\n",
    "maximum = functools.reduce(lambda x, y: x if x > y else y, numbers)\n",
    "print(f\"Maximum of {numbers} = {maximum}\")\n",
    "\n",
    "# Reduce with initial value\n",
    "total_with_init = functools.reduce(lambda x, y: x + y, numbers, 100)\n",
    "print(f\"Sum with initial value 100: {total_with_init}\")\n",
    "\n",
    "# String operations with reduce\n",
    "words = ['Python', 'is', 'awesome', 'for', 'data', 'science']\n",
    "sentence = functools.reduce(lambda x, y: x + ' ' + y, words)\n",
    "print(f\"Sentence: {sentence}\")\n",
    "\n",
    "# Practical example: Nested dictionary access\n",
    "nested_dict = {\n",
    "    'level1': {\n",
    "        'level2': {\n",
    "            'level3': {\n",
    "                'data': 'found it!'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_nested(dictionary, key):\n",
    "    return dictionary[key]\n",
    "\n",
    "keys = ['level1', 'level2', 'level3', 'data']\n",
    "result = functools.reduce(get_nested, keys, nested_dict)\n",
    "print(f\"Nested access result: {result}\")\n",
    "\n",
    "print(\"\\n=== @wraps - Proper Decorator Creation ===\")\n",
    "\n",
    "# Without @wraps (bad)\n",
    "def bad_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"Calling {func.__name__}\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "# With @wraps (good)\n",
    "def good_decorator(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"Calling {func.__name__}\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@bad_decorator\n",
    "def function_with_bad_decorator():\n",
    "    \"\"\"This function has a bad decorator\"\"\"\n",
    "    return \"Hello from bad decorator\"\n",
    "\n",
    "@good_decorator\n",
    "def function_with_good_decorator():\n",
    "    \"\"\"This function has a good decorator\"\"\"\n",
    "    return \"Hello from good decorator\"\n",
    "\n",
    "# Compare the results\n",
    "print(f\"Bad decorator name: {function_with_bad_decorator.__name__}\")\n",
    "print(f\"Bad decorator doc: {function_with_bad_decorator.__doc__}\")\n",
    "\n",
    "print(f\"Good decorator name: {function_with_good_decorator.__name__}\")\n",
    "print(f\"Good decorator doc: {function_with_good_decorator.__doc__}\")\n",
    "\n",
    "print(\"\\n=== @singledispatch - Function Overloading ===\")\n",
    "\n",
    "@functools.singledispatch\n",
    "def process_data(arg):\n",
    "    \"\"\"Default implementation\"\"\"\n",
    "    print(f\"Processing unknown type: {type(arg).__name__}\")\n",
    "    return str(arg)\n",
    "\n",
    "@process_data.register\n",
    "def _(arg: int):\n",
    "    \"\"\"Handle integers\"\"\"\n",
    "    print(f\"Processing integer: {arg}\")\n",
    "    return arg * 2\n",
    "\n",
    "@process_data.register\n",
    "def _(arg: str):\n",
    "    \"\"\"Handle strings\"\"\"\n",
    "    print(f\"Processing string: {arg}\")\n",
    "    return arg.upper()\n",
    "\n",
    "@process_data.register\n",
    "def _(arg: list):\n",
    "    \"\"\"Handle lists\"\"\"\n",
    "    print(f\"Processing list of {len(arg)} items\")\n",
    "    return sum(arg) if all(isinstance(x, (int, float)) for x in arg) else len(arg)\n",
    "\n",
    "# Test singledispatch\n",
    "test_values = [42, \"hello\", [1, 2, 3, 4], {'key': 'value'}]\n",
    "\n",
    "for value in test_values:\n",
    "    result = process_data(value)\n",
    "    print(f\"Result: {result}\\n\")\n",
    "\n",
    "print(\"=== Summary ===\")\n",
    "print(\"‚úÖ @lru_cache: Automatic memoization for expensive functions\")\n",
    "print(\"‚úÖ partial: Create specialized functions by fixing some arguments\")\n",
    "print(\"‚úÖ reduce: Apply function cumulatively to sequences\")\n",
    "print(\"‚úÖ @wraps: Preserve function metadata in decorators\")\n",
    "print(\"‚úÖ @singledispatch: Function overloading based on first argument type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ YAML - Human-Readable Data Serialization\n",
    "\n",
    "YAML (YAML Ain't Markup Language) is a human-readable data serialization standard commonly used for configuration files, data exchange, and documentation.\n",
    "\n",
    "## Why Use YAML?\n",
    "\n",
    "- **Human-readable**: Easy to read and write\n",
    "- **Configuration files**: Docker, Kubernetes, CI/CD pipelines\n",
    "- **Data exchange**: Between applications and systems\n",
    "- **Documentation**: Self-documenting configuration\n",
    "- **Language agnostic**: Works with many programming languages\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Indentation-based structure (like Python)\n",
    "- Support for complex data types\n",
    "- Comments allowed\n",
    "- Multi-document support\n",
    "- References and anchors\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install PyYAML\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic YAML Syntax and Data Types\n",
    "import yaml\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "print(\"=== Basic YAML Data Types ===\")\n",
    "\n",
    "# Basic YAML content\n",
    "basic_yaml = \"\"\"\n",
    "# This is a comment\n",
    "string_value: \"Hello, World!\"\n",
    "integer_value: 42\n",
    "float_value: 3.14159\n",
    "boolean_true: true\n",
    "boolean_false: false\n",
    "null_value: null\n",
    "empty_value: \n",
    "\n",
    "# Different string formats\n",
    "single_quoted: 'Single quotes'\n",
    "double_quoted: \"Double quotes\"\n",
    "unquoted: Unquoted string\n",
    "multiline_string: |\n",
    "  This is a multiline string\n",
    "  that preserves line breaks\n",
    "  and formatting.\n",
    "\n",
    "folded_string: >\n",
    "  This is a folded string\n",
    "  that will be joined into\n",
    "  a single line with spaces.\n",
    "\"\"\"\n",
    "\n",
    "# Parse YAML\n",
    "try:\n",
    "    data = yaml.safe_load(basic_yaml)\n",
    "    print(\"Parsed YAML data:\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"  {key}: {value} ({type(value).__name__})\")\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"YAML Error: {e}\")\n",
    "\n",
    "print(f\"\\nMultiline string:\\n{repr(data['multiline_string'])}\")\n",
    "print(f\"\\nFolded string:\\n{repr(data['folded_string'])}\")\n",
    "\n",
    "# Convert back to YAML\n",
    "print(\"\\n=== Converting Python to YAML ===\")\n",
    "\n",
    "python_data = {\n",
    "    'name': 'Alice',\n",
    "    'age': 30,\n",
    "    'active': True,\n",
    "    'score': 95.5,\n",
    "    'metadata': None\n",
    "}\n",
    "\n",
    "yaml_output = yaml.dump(python_data, default_flow_style=False)\n",
    "print(\"Python dict to YAML:\")\n",
    "print(yaml_output)\n",
    "\n",
    "# Pretty printing with custom formatting\n",
    "yaml_formatted = yaml.dump(\n",
    "    python_data, \n",
    "    default_flow_style=False,\n",
    "    indent=2,\n",
    "    sort_keys=True\n",
    ")\n",
    "print(\"Formatted YAML:\")\n",
    "print(yaml_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML Collections and Complex Data Structures\n",
    "print(\"=== YAML Collections ===\")\n",
    "\n",
    "collections_yaml = \"\"\"\n",
    "# Lists (Arrays)\n",
    "fruits:\n",
    "  - apple\n",
    "  - banana\n",
    "  - cherry\n",
    "\n",
    "# Inline list format\n",
    "colors: [red, green, blue]\n",
    "\n",
    "# Nested lists\n",
    "matrix:\n",
    "  - [1, 2, 3]\n",
    "  - [4, 5, 6]\n",
    "  - [7, 8, 9]\n",
    "\n",
    "# Dictionaries (Maps)\n",
    "person:\n",
    "  name: Alice\n",
    "  age: 30\n",
    "  address:\n",
    "    street: 123 Main St\n",
    "    city: New York\n",
    "    zip: 10001\n",
    "\n",
    "# Inline dictionary format\n",
    "point: {x: 10, y: 20}\n",
    "\n",
    "# List of dictionaries\n",
    "employees:\n",
    "  - name: Alice\n",
    "    department: Engineering\n",
    "    salary: 75000\n",
    "  - name: Bob\n",
    "    department: Marketing\n",
    "    salary: 65000\n",
    "  - name: Charlie\n",
    "    department: Engineering\n",
    "    salary: 80000\n",
    "\n",
    "# Mixed complex structure\n",
    "project:\n",
    "  name: \"Data Analysis Tool\"\n",
    "  version: \"1.2.3\"\n",
    "  dependencies:\n",
    "    - numpy>=1.20.0\n",
    "    - pandas>=1.3.0\n",
    "    - matplotlib>=3.4.0\n",
    "  config:\n",
    "    debug: false\n",
    "    max_workers: 4\n",
    "    output_formats: [csv, json, xlsx]\n",
    "  team:\n",
    "    lead: Alice\n",
    "    members:\n",
    "      - Bob\n",
    "      - Charlie\n",
    "      - Diana\n",
    "\"\"\"\n",
    "\n",
    "# Parse complex YAML\n",
    "collections_data = yaml.safe_load(collections_yaml)\n",
    "\n",
    "print(\"Fruits list:\", collections_data['fruits'])\n",
    "print(\"Person info:\", collections_data['person'])\n",
    "print(\"Project dependencies:\", collections_data['project']['dependencies'])\n",
    "\n",
    "# Access nested data\n",
    "print(f\"\\nProject lead: {collections_data['project']['team']['lead']}\")\n",
    "print(f\"First employee: {collections_data['employees'][0]['name']}\")\n",
    "print(f\"Address city: {collections_data['person']['address']['city']}\")\n",
    "\n",
    "# Convert complex Python structure to YAML\n",
    "complex_data = {\n",
    "    'database': {\n",
    "        'host': 'localhost',\n",
    "        'port': 5432,\n",
    "        'credentials': {\n",
    "            'username': 'admin',\n",
    "            'password': 'secret123'\n",
    "        },\n",
    "        'pools': {\n",
    "            'min_connections': 5,\n",
    "            'max_connections': 20\n",
    "        }\n",
    "    },\n",
    "    'api': {\n",
    "        'endpoints': [\n",
    "            {'path': '/users', 'methods': ['GET', 'POST']},\n",
    "            {'path': '/orders', 'methods': ['GET', 'POST', 'PUT']},\n",
    "            {'path': '/health', 'methods': ['GET']}\n",
    "        ],\n",
    "        'rate_limiting': {\n",
    "            'enabled': True,\n",
    "            'requests_per_minute': 1000\n",
    "        }\n",
    "    },\n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'handlers': ['console', 'file'],\n",
    "        'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    }\n",
    "}\n",
    "\n",
    "yaml_complex = yaml.dump(complex_data, default_flow_style=False, indent=2)\n",
    "print(\"\\n=== Complex Data as YAML ===\")\n",
    "print(yaml_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced YAML Features\n",
    "print(\"=== YAML Anchors and References ===\")\n",
    "\n",
    "# YAML with anchors (&) and references (*)\n",
    "advanced_yaml = \"\"\"\n",
    "# Define anchors for reuse\n",
    "defaults: &defaults\n",
    "  timeout: 30\n",
    "  retries: 3\n",
    "  log_level: INFO\n",
    "\n",
    "# Database configurations using anchors\n",
    "database_config:\n",
    "  development:\n",
    "    <<: *defaults  # Merge defaults\n",
    "    host: dev-db.example.com\n",
    "    port: 5432\n",
    "    debug: true\n",
    "    \n",
    "  staging:\n",
    "    <<: *defaults\n",
    "    host: staging-db.example.com\n",
    "    port: 5432\n",
    "    debug: false\n",
    "    \n",
    "  production:\n",
    "    <<: *defaults\n",
    "    host: prod-db.example.com\n",
    "    port: 5432\n",
    "    timeout: 60  # Override default timeout\n",
    "    debug: false\n",
    "\n",
    "# Reference the same values\n",
    "admin_user: &admin\n",
    "  username: admin\n",
    "  permissions:\n",
    "    - read\n",
    "    - write\n",
    "    - delete\n",
    "\n",
    "# Use the reference\n",
    "users:\n",
    "  primary: *admin\n",
    "  backup: *admin\n",
    "\n",
    "# List anchors\n",
    "common_dependencies: &common_deps\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "\n",
    "projects:\n",
    "  project_a:\n",
    "    name: \"Data Analysis\"\n",
    "    dependencies:\n",
    "      - *common_deps\n",
    "      - scipy\n",
    "      - sklearn\n",
    "      \n",
    "  project_b:\n",
    "    name: \"Visualization\"\n",
    "    dependencies:\n",
    "      - *common_deps\n",
    "      - seaborn\n",
    "      - plotly\n",
    "\"\"\"\n",
    "\n",
    "advanced_data = yaml.safe_load(advanced_yaml)\n",
    "\n",
    "print(\"Development config:\", advanced_data['database_config']['development'])\n",
    "print(\"Production config:\", advanced_data['database_config']['production'])\n",
    "print(\"Admin user:\", advanced_data['users']['primary'])\n",
    "\n",
    "print(\"\\n=== Multi-Document YAML ===\")\n",
    "\n",
    "# Multiple documents in one YAML string\n",
    "multi_doc_yaml = \"\"\"\n",
    "---\n",
    "# Document 1: Configuration\n",
    "name: \"Application Config\"\n",
    "version: \"1.0\"\n",
    "settings:\n",
    "  debug: true\n",
    "  port: 8080\n",
    "\n",
    "---\n",
    "# Document 2: Users\n",
    "users:\n",
    "  - name: Alice\n",
    "    role: admin\n",
    "  - name: Bob\n",
    "    role: user\n",
    "\n",
    "---\n",
    "# Document 3: Database\n",
    "database:\n",
    "  host: localhost\n",
    "  port: 5432\n",
    "  name: myapp_db\n",
    "\"\"\"\n",
    "\n",
    "# Load all documents\n",
    "documents = list(yaml.safe_load_all(multi_doc_yaml))\n",
    "\n",
    "print(f\"Number of documents: {len(documents)}\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"Document {i}: {list(doc.keys())}\")\n",
    "\n",
    "print(\"\\n=== YAML Validation and Error Handling ===\")\n",
    "\n",
    "# Invalid YAML examples\n",
    "invalid_yamls = [\n",
    "    \"key: value\\n  invalid_indent: bad\",  # Inconsistent indentation\n",
    "    \"key: [unclosed, list\",  # Unclosed bracket\n",
    "    \"duplicate_key: value1\\nduplicate_key: value2\"  # Duplicate keys (allowed by default)\n",
    "]\n",
    "\n",
    "for i, invalid_yaml in enumerate(invalid_yamls, 1):\n",
    "    try:\n",
    "        result = yaml.safe_load(invalid_yaml)\n",
    "        print(f\"Invalid YAML {i} loaded: {result}\")\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Invalid YAML {i} error: {e}\")\n",
    "\n",
    "print(\"\\n=== Safe vs Unsafe Loading ===\")\n",
    "\n",
    "# Potentially dangerous YAML (with Python objects)\n",
    "dangerous_yaml = \"\"\"\n",
    "# This could be dangerous with yaml.load()\n",
    "data: !!python/object/apply:os.system ['echo \"This could be dangerous\"']\n",
    "safe_data: \"This is safe\"\n",
    "\"\"\"\n",
    "\n",
    "# Always use safe_load for untrusted input\n",
    "try:\n",
    "    safe_result = yaml.safe_load(dangerous_yaml)\n",
    "    print(\"Safe load result:\", safe_result)\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"Safe load error: {e}\")\n",
    "\n",
    "print(\"\\n=== Working with Files ===\")\n",
    "\n",
    "# Create a sample config file content\n",
    "config_content = {\n",
    "    'app': {\n",
    "        'name': 'My Application',\n",
    "        'version': '2.1.0',\n",
    "        'debug': False\n",
    "    },\n",
    "    'database': {\n",
    "        'host': 'localhost',\n",
    "        'port': 5432,\n",
    "        'name': 'app_db',\n",
    "        'pool_size': 10\n",
    "    },\n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'file': 'app.log',\n",
    "        'max_size': '10MB'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to YAML string (simulating file content)\n",
    "yaml_file_content = yaml.dump(config_content, default_flow_style=False, indent=2)\n",
    "print(\"Config file content:\")\n",
    "print(yaml_file_content)\n",
    "\n",
    "# Parse it back\n",
    "parsed_config = yaml.safe_load(yaml_file_content)\n",
    "print(\"Parsed config:\")\n",
    "print(f\"App name: {parsed_config['app']['name']}\")\n",
    "print(f\"Database host: {parsed_config['database']['host']}\")\n",
    "print(f\"Log level: {parsed_config['logging']['level']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical YAML Examples and Use Cases\n",
    "print(\"=== Docker Compose Example ===\")\n",
    "\n",
    "docker_compose = \"\"\"\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  web:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - DEBUG=1\n",
    "      - DATABASE_URL=postgresql://user:pass@db:5432/myapp\n",
    "    depends_on:\n",
    "      - db\n",
    "      - redis\n",
    "    volumes:\n",
    "      - .:/app\n",
    "      - /app/node_modules\n",
    "\n",
    "  db:\n",
    "    image: postgres:13\n",
    "    environment:\n",
    "      POSTGRES_DB: myapp\n",
    "      POSTGRES_USER: user\n",
    "      POSTGRES_PASSWORD: pass\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "\n",
    "  redis:\n",
    "    image: redis:6-alpine\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "\n",
    "networks:\n",
    "  default:\n",
    "    driver: bridge\n",
    "\"\"\"\n",
    "\n",
    "compose_data = yaml.safe_load(docker_compose)\n",
    "print(\"Docker Compose services:\", list(compose_data['services'].keys()))\n",
    "print(\"Web service ports:\", compose_data['services']['web']['ports'])\n",
    "\n",
    "print(\"\\n=== CI/CD Pipeline Example (GitHub Actions) ===\")\n",
    "\n",
    "github_actions = \"\"\"\n",
    "name: Python CI/CD\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main, develop]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "env:\n",
    "  PYTHON_VERSION: \"3.9\"\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    strategy:\n",
    "      matrix:\n",
    "        python-version: [3.8, 3.9, \"3.10\"]\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v3\n",
    "    \n",
    "    - name: Set up Python ${{ matrix.python-version }}\n",
    "      uses: actions/setup-python@v4\n",
    "      with:\n",
    "        python-version: ${{ matrix.python-version }}\n",
    "    \n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install -r requirements.txt\n",
    "        pip install pytest coverage\n",
    "    \n",
    "    - name: Run tests\n",
    "      run: |\n",
    "        pytest tests/ --cov=src/\n",
    "        coverage xml\n",
    "    \n",
    "    - name: Upload coverage\n",
    "      uses: codecov/codecov-action@v3\n",
    "      with:\n",
    "        file: ./coverage.xml\n",
    "\n",
    "  deploy:\n",
    "    needs: test\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.ref == 'refs/heads/main'\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v3\n",
    "    \n",
    "    - name: Deploy to production\n",
    "      run: |\n",
    "        echo \"Deploying to production...\"\n",
    "        # Add deployment commands here\n",
    "\"\"\"\n",
    "\n",
    "ci_data = yaml.safe_load(github_actions)\n",
    "print(\"CI/CD jobs:\", list(ci_data['jobs'].keys()))\n",
    "print(\"Python versions tested:\", ci_data['jobs']['test']['strategy']['matrix']['python-version'])\n",
    "\n",
    "print(\"\\n=== Kubernetes Configuration Example ===\")\n",
    "\n",
    "k8s_config = \"\"\"\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: web-app\n",
    "  labels:\n",
    "    app: web-app\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: web-app\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: web-app\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: web-app\n",
    "        image: myapp:latest\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "        env:\n",
    "        - name: DATABASE_URL\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: db-secret\n",
    "              key: url\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"250m\"\n",
    "          limits:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: web-app-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: web-app\n",
    "  ports:\n",
    "  - protocol: TCP\n",
    "    port: 80\n",
    "    targetPort: 8000\n",
    "  type: LoadBalancer\n",
    "\"\"\"\n",
    "\n",
    "k8s_docs = list(yaml.safe_load_all(k8s_config))\n",
    "print(\"Kubernetes resources:\", [doc['kind'] for doc in k8s_docs])\n",
    "print(\"Deployment replicas:\", k8s_docs[0]['spec']['replicas'])\n",
    "\n",
    "print(\"\\n=== Application Configuration Example ===\")\n",
    "\n",
    "# Real-world application config\n",
    "app_config = {\n",
    "    'app': {\n",
    "        'name': 'Data Processing Pipeline',\n",
    "        'version': '2.3.1',\n",
    "        'environment': 'production'\n",
    "    },\n",
    "    'server': {\n",
    "        'host': '0.0.0.0',\n",
    "        'port': 8080,\n",
    "        'workers': 4,\n",
    "        'timeout': 30\n",
    "    },\n",
    "    'database': {\n",
    "        'primary': {\n",
    "            'host': 'db-primary.example.com',\n",
    "            'port': 5432,\n",
    "            'database': 'app_prod',\n",
    "            'pool': {\n",
    "                'min_connections': 5,\n",
    "                'max_connections': 20,\n",
    "                'timeout': 10\n",
    "            }\n",
    "        },\n",
    "        'replica': {\n",
    "            'host': 'db-replica.example.com',\n",
    "            'port': 5432,\n",
    "            'database': 'app_prod',\n",
    "            'readonly': True\n",
    "        }\n",
    "    },\n",
    "    'redis': {\n",
    "        'host': 'redis.example.com',\n",
    "        'port': 6379,\n",
    "        'db': 0,\n",
    "        'ttl': 3600\n",
    "    },\n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        'handlers': [\n",
    "            {\n",
    "                'type': 'console',\n",
    "                'level': 'INFO'\n",
    "            },\n",
    "            {\n",
    "                'type': 'file',\n",
    "                'level': 'DEBUG',\n",
    "                'filename': '/var/log/app.log',\n",
    "                'max_bytes': 10485760,  # 10MB\n",
    "                'backup_count': 5\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    'features': {\n",
    "        'enable_caching': True,\n",
    "        'enable_metrics': True,\n",
    "        'enable_tracing': False,\n",
    "        'max_file_size_mb': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to YAML\n",
    "config_yaml = yaml.dump(app_config, default_flow_style=False, indent=2, sort_keys=True)\n",
    "print(\"Application Configuration YAML:\")\n",
    "print(config_yaml[:500] + \"...\")  # Show first 500 chars\n",
    "\n",
    "print(\"\\n=== YAML Best Practices ===\")\n",
    "print(\"\"\"\n",
    "‚úÖ DO:\n",
    "‚Ä¢ Use consistent indentation (2 or 4 spaces)\n",
    "‚Ä¢ Add comments to explain complex configurations\n",
    "‚Ä¢ Use meaningful key names\n",
    "‚Ä¢ Validate YAML syntax before deployment\n",
    "‚Ä¢ Use anchors (&) and references (*) to avoid duplication\n",
    "‚Ä¢ Always use yaml.safe_load() for untrusted input\n",
    "\n",
    "‚ùå DON'T:\n",
    "‚Ä¢ Mix tabs and spaces for indentation\n",
    "‚Ä¢ Use yaml.load() with untrusted input (security risk)\n",
    "‚Ä¢ Create overly nested structures (hard to read)\n",
    "‚Ä¢ Ignore YAML syntax errors\n",
    "‚Ä¢ Use special characters in keys without quotes\n",
    "\n",
    "üîß COMMON USE CASES:\n",
    "‚Ä¢ Configuration files (apps, servers, tools)\n",
    "‚Ä¢ CI/CD pipeline definitions (GitHub Actions, GitLab CI)\n",
    "‚Ä¢ Infrastructure as Code (Kubernetes, Docker Compose)\n",
    "‚Ä¢ Data exchange between systems\n",
    "‚Ä¢ Documentation with structured data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ TOML Tutorial - Tom's Obvious Minimal Language\n",
    "\n",
    "**TOML** (Tom's Obvious Minimal Language) is a human-readable configuration file format that's designed to be easy to read and write. It's commonly used for configuration files in modern projects, especially in the Python ecosystem.\n",
    "\n",
    "## üéØ **Why TOML?**\n",
    "\n",
    "- **Human-readable**: Clear, minimal syntax that's easy to understand\n",
    "- **Unambiguous**: Well-defined specification with clear rules\n",
    "- **Type-safe**: Supports common data types with clear semantics\n",
    "- **Popular**: Used by Python's `pyproject.toml`, Rust's `Cargo.toml`, and many other tools\n",
    "- **Better than**: JSON (more readable), INI (more structured), XML (less verbose)\n",
    "\n",
    "## üîß **Common Use Cases**\n",
    "\n",
    "- **Python projects**: `pyproject.toml` for project configuration\n",
    "- **Application configuration**: Settings, database connections, API keys\n",
    "- **Build tools**: Cargo (Rust), Poetry (Python), etc.\n",
    "- **Docker**: Docker Compose alternative configurations\n",
    "- **CI/CD**: Configuration for various tools and pipelines\n",
    "\n",
    "## üì¶ **Installation**\n",
    "\n",
    "TOML support is built into Python 3.11+, but for older versions:\n",
    "\n",
    "```bash\n",
    "pip install tomli tomli-w  # For reading and writing TOML\n",
    "# or\n",
    "pip install toml  # Alternative library\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic TOML Syntax and Data Types\n",
    "import sys\n",
    "\n",
    "# Python 3.11+ has built-in tomllib for reading TOML\n",
    "if sys.version_info >= (3, 11):\n",
    "    import tomllib\n",
    "    # For writing, we still need external library\n",
    "    try:\n",
    "        import tomli_w\n",
    "        HAS_TOMLI_W = True\n",
    "    except ImportError:\n",
    "        HAS_TOMLI_W = False\n",
    "        print(\"‚ö†Ô∏è  Install tomli-w for writing TOML: pip install tomli-w\")\n",
    "else:\n",
    "    # For older Python versions\n",
    "    try:\n",
    "        import tomli as tomllib\n",
    "        import tomli_w\n",
    "        HAS_TOMLI_W = True\n",
    "    except ImportError:\n",
    "        try:\n",
    "            import toml as tomllib\n",
    "            HAS_TOMLI_W = True\n",
    "            tomli_w = tomllib  # toml library can both read and write\n",
    "        except ImportError:\n",
    "            print(\"‚ùå Install TOML library: pip install tomli tomli-w\")\n",
    "            print(\"   Or for Python 3.11+, no installation needed for reading\")\n",
    "\n",
    "print(\"=== TOML Basic Data Types ===\")\n",
    "\n",
    "# Basic TOML syntax examples\n",
    "basic_toml = '''\n",
    "# This is a TOML comment\n",
    "\n",
    "# Key-value pairs\n",
    "title = \"My Application\"\n",
    "version = \"1.0.0\"\n",
    "debug = true\n",
    "port = 8080\n",
    "pi = 3.14159\n",
    "\n",
    "# Strings\n",
    "name = \"John Doe\"\n",
    "multiline_string = \"\"\"\n",
    "This is a multiline string.\n",
    "It can span multiple lines.\n",
    "\"\"\"\n",
    "\n",
    "# Dates and times\n",
    "created_date = 2025-08-13\n",
    "created_time = 2025-08-13T10:30:00Z\n",
    "local_time = 10:30:00\n",
    "\n",
    "# Arrays\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "mixed_types = [\"string\", 123, true, 3.14]\n",
    "nested_arrays = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "# Inline tables (like dictionaries)\n",
    "database = { host = \"localhost\", port = 5432, name = \"myapp\" }\n",
    "'''\n",
    "\n",
    "# Parse the TOML string\n",
    "try:\n",
    "    if sys.version_info >= (3, 11):\n",
    "        data = tomllib.loads(basic_toml)\n",
    "    else:\n",
    "        data = tomllib.loads(basic_toml)\n",
    "    \n",
    "    print(\"‚úÖ TOML parsed successfully!\")\n",
    "    print(f\"Title: {data['title']}\")\n",
    "    print(f\"Version: {data['version']}\")\n",
    "    print(f\"Debug mode: {data['debug']}\")\n",
    "    print(f\"Port: {data['port']}\")\n",
    "    print(f\"Numbers array: {data['numbers']}\")\n",
    "    print(f\"Database config: {data['database']}\")\n",
    "    print(f\"Created date: {data['created_date']} (type: {type(data['created_date'])})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error parsing TOML: {e}\")\n",
    "\n",
    "print(\"\\n=== Data Type Details ===\")\n",
    "print(\"TOML supports these data types:\")\n",
    "print(\"‚Ä¢ String: 'text' or \\\"text\\\" or '''multiline'''\")\n",
    "print(\"‚Ä¢ Integer: 123, +456, -789\")\n",
    "print(\"‚Ä¢ Float: 3.14, -0.01, 5e+22\")\n",
    "print(\"‚Ä¢ Boolean: true, false\")\n",
    "print(\"‚Ä¢ Datetime: 1979-05-27T07:32:00Z\")\n",
    "print(\"‚Ä¢ Local Datetime: 1979-05-27T07:32:00\")\n",
    "print(\"‚Ä¢ Local Date: 1979-05-27\")\n",
    "print(\"‚Ä¢ Local Time: 07:32:00\")\n",
    "print(\"‚Ä¢ Array: [1, 2, 3]\")\n",
    "print(\"‚Ä¢ Inline Table: { key = \\\"value\\\", num = 42 }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOML Tables and Sections\n",
    "print(\"=== TOML Tables (Sections) ===\")\n",
    "\n",
    "# TOML with tables/sections\n",
    "config_toml = '''\n",
    "# Global settings\n",
    "app_name = \"My Web App\"\n",
    "version = \"2.1.0\"\n",
    "\n",
    "# Table/Section for database configuration\n",
    "[database]\n",
    "host = \"localhost\"\n",
    "port = 5432\n",
    "username = \"admin\"\n",
    "password = \"secret123\"\n",
    "database_name = \"myapp_prod\"\n",
    "ssl_mode = \"require\"\n",
    "\n",
    "# Another table for server configuration\n",
    "[server]\n",
    "host = \"0.0.0.0\"\n",
    "port = 8080\n",
    "workers = 4\n",
    "timeout = 30\n",
    "enable_ssl = true\n",
    "\n",
    "# Nested tables using dot notation\n",
    "[logging.handlers]\n",
    "console = { level = \"INFO\", format = \"%(levelname)s: %(message)s\" }\n",
    "file = { level = \"DEBUG\", filename = \"/var/log/app.log\" }\n",
    "\n",
    "[logging.loggers]\n",
    "\"myapp.database\" = { level = \"WARNING\" }\n",
    "\"myapp.auth\" = { level = \"INFO\" }\n",
    "\n",
    "# Arrays of tables\n",
    "[[users]]\n",
    "name = \"Alice\"\n",
    "email = \"alice@example.com\"\n",
    "role = \"admin\"\n",
    "active = true\n",
    "\n",
    "[[users]]\n",
    "name = \"Bob\"\n",
    "email = \"bob@example.com\"\n",
    "role = \"user\"\n",
    "active = true\n",
    "\n",
    "[[users]]\n",
    "name = \"Charlie\"\n",
    "email = \"charlie@example.com\"\n",
    "role = \"moderator\"\n",
    "active = false\n",
    "\n",
    "# Complex nested structure\n",
    "[features]\n",
    "authentication = true\n",
    "caching = true\n",
    "rate_limiting = false\n",
    "\n",
    "[features.cache]\n",
    "backend = \"redis\"\n",
    "ttl = 3600\n",
    "max_size = \"100MB\"\n",
    "\n",
    "[features.auth]\n",
    "providers = [\"local\", \"oauth\", \"ldap\"]\n",
    "session_timeout = 1800\n",
    "max_attempts = 3\n",
    "'''\n",
    "\n",
    "# Parse the configuration\n",
    "try:\n",
    "    config_data = tomllib.loads(config_toml)\n",
    "    \n",
    "    print(\"‚úÖ Configuration loaded successfully!\")\n",
    "    print(f\"App: {config_data['app_name']} v{config_data['version']}\")\n",
    "    print(f\"Database: {config_data['database']['host']}:{config_data['database']['port']}\")\n",
    "    print(f\"Server: {config_data['server']['host']}:{config_data['server']['port']}\")\n",
    "    \n",
    "    print(f\"\\nLogging handlers: {list(config_data['logging']['handlers'].keys())}\")\n",
    "    print(f\"Console log level: {config_data['logging']['handlers']['console']['level']}\")\n",
    "    \n",
    "    print(f\"\\nUsers ({len(config_data['users'])}):\")\n",
    "    for user in config_data['users']:\n",
    "        status = \"‚úÖ\" if user['active'] else \"‚ùå\"\n",
    "        print(f\"  {status} {user['name']} ({user['role']}) - {user['email']}\")\n",
    "    \n",
    "    print(f\"\\nFeatures enabled:\")\n",
    "    for feature, enabled in config_data['features'].items():\n",
    "        if isinstance(enabled, bool):\n",
    "            status = \"‚úÖ\" if enabled else \"‚ùå\"\n",
    "            print(f\"  {status} {feature}\")\n",
    "    \n",
    "    print(f\"\\nCache configuration:\")\n",
    "    cache_config = config_data['features']['cache']\n",
    "    print(f\"  Backend: {cache_config['backend']}\")\n",
    "    print(f\"  TTL: {cache_config['ttl']} seconds\")\n",
    "    print(f\"  Max size: {cache_config['max_size']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error parsing configuration: {e}\")\n",
    "\n",
    "print(\"\\n=== TOML Table Syntax Rules ===\")\n",
    "print(\"\"\"\n",
    "1. [table] - Creates a new table/section\n",
    "2. [parent.child] - Creates nested table\n",
    "3. [[array_of_tables]] - Creates array of tables\n",
    "4. Key-value pairs under a table belong to that table\n",
    "5. Tables can be defined in any order\n",
    "6. Duplicate table names are not allowed\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing TOML and File Operations\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "print(\"=== Writing TOML Data ===\")\n",
    "\n",
    "# Create sample configuration data\n",
    "app_config = {\n",
    "    'app': {\n",
    "        'name': 'Data Processing Pipeline',\n",
    "        'version': '3.2.1',\n",
    "        'description': 'A high-performance data processing application',\n",
    "        'author': 'Development Team',\n",
    "        'license': 'MIT'\n",
    "    },\n",
    "    'server': {\n",
    "        'host': '0.0.0.0',\n",
    "        'port': 8080,\n",
    "        'workers': 4,\n",
    "        'debug': False,\n",
    "        'reload': True\n",
    "    },\n",
    "    'database': {\n",
    "        'primary': {\n",
    "            'host': 'db-primary.example.com',\n",
    "            'port': 5432,\n",
    "            'database': 'app_prod',\n",
    "            'username': 'app_user',\n",
    "            'ssl_mode': 'require',\n",
    "            'pool_size': 20,\n",
    "            'timeout': 30.0\n",
    "        },\n",
    "        'replica': {\n",
    "            'host': 'db-replica.example.com', \n",
    "            'port': 5432,\n",
    "            'database': 'app_prod',\n",
    "            'readonly': True\n",
    "        }\n",
    "    },\n",
    "    'cache': {\n",
    "        'backend': 'redis',\n",
    "        'host': 'cache.example.com',\n",
    "        'port': 6379,\n",
    "        'db': 0,\n",
    "        'ttl': 3600,\n",
    "        'max_memory': '2GB'\n",
    "    },\n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        'file': '/var/log/app.log',\n",
    "        'rotation': {\n",
    "            'max_size': '100MB',\n",
    "            'backup_count': 5\n",
    "        }\n",
    "    },\n",
    "    'features': {\n",
    "        'authentication': True,\n",
    "        'rate_limiting': True,\n",
    "        'monitoring': True,\n",
    "        'analytics': False\n",
    "    },\n",
    "    'api': {\n",
    "        'version': 'v2',\n",
    "        'base_url': '/api/v2',\n",
    "        'rate_limit': 1000,\n",
    "        'timeout': 30,\n",
    "        'allowed_methods': ['GET', 'POST', 'PUT', 'DELETE'],\n",
    "        'cors': {\n",
    "            'enabled': True,\n",
    "            'origins': ['https://app.example.com', 'https://admin.example.com'],\n",
    "            'methods': ['GET', 'POST', 'PUT'],\n",
    "            'headers': ['Content-Type', 'Authorization']\n",
    "        }\n",
    "    },\n",
    "    'monitoring': [\n",
    "        {\n",
    "            'name': 'Prometheus',\n",
    "            'endpoint': '/metrics',\n",
    "            'enabled': True,\n",
    "            'interval': 30\n",
    "        },\n",
    "        {\n",
    "            'name': 'Health Check',\n",
    "            'endpoint': '/health',\n",
    "            'enabled': True,\n",
    "            'interval': 10\n",
    "        }\n",
    "    ],\n",
    "    'metadata': {\n",
    "        'created': datetime.now().date(),\n",
    "        'last_updated': datetime.now().date(),\n",
    "        'config_version': '2.0'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write TOML to string\n",
    "if HAS_TOMLI_W:\n",
    "    try:\n",
    "        toml_string = tomli_w.dumps(app_config)\n",
    "        print(\"‚úÖ TOML string created successfully!\")\n",
    "        print(\"First 500 characters:\")\n",
    "        print(toml_string[:500])\n",
    "        print(\"...\")\n",
    "        \n",
    "        # Write to temporary file and read it back\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.toml', delete=False) as f:\n",
    "            f.write(toml_string)\n",
    "            temp_file = f.name\n",
    "        \n",
    "        print(f\"\\n‚úÖ TOML written to temporary file: {temp_file}\")\n",
    "        \n",
    "        # Read the file back\n",
    "        with open(temp_file, 'rb') as f:\n",
    "            loaded_config = tomllib.load(f)\n",
    "        \n",
    "        print(\"‚úÖ TOML file read back successfully!\")\n",
    "        print(f\"App name: {loaded_config['app']['name']}\")\n",
    "        print(f\"App version: {loaded_config['app']['version']}\")\n",
    "        print(f\"Database host: {loaded_config['database']['primary']['host']}\")\n",
    "        print(f\"API endpoints: {len(loaded_config['monitoring'])} monitoring endpoints\")\n",
    "        \n",
    "        # Clean up\n",
    "        Path(temp_file).unlink()\n",
    "        print(f\"üóëÔ∏è  Temporary file cleaned up\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with TOML operations: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  TOML writing not available. Install tomli-w or toml library.\")\n",
    "\n",
    "print(\"\\n=== TOML vs Other Formats ===\")\n",
    "print(\"TOML advantages:\")\n",
    "print(\"‚úÖ More readable than JSON\")\n",
    "print(\"‚úÖ More structured than INI\")\n",
    "print(\"‚úÖ Less verbose than XML/YAML\")\n",
    "print(\"‚úÖ Built-in data types (dates, times)\")\n",
    "print(\"‚úÖ Comments support\")\n",
    "print(\"‚úÖ No ambiguity in parsing\")\n",
    "\n",
    "print(\"\\nTOML limitations:\")\n",
    "print(\"‚ùå Less flexible than YAML\")\n",
    "print(\"‚ùå No multi-line arrays\")\n",
    "print(\"‚ùå Limited nesting compared to JSON\")\n",
    "print(\"‚ùå Newer format (less tooling)\")\n",
    "\n",
    "print(\"\\n=== Best Practices ===\")\n",
    "print(\"1. Use TOML for configuration files\")\n",
    "print(\"2. Group related settings in tables\")\n",
    "print(\"3. Use meaningful comments\")\n",
    "print(\"4. Prefer explicit over implicit\")\n",
    "print(\"5. Use arrays of tables for repeated structures\")\n",
    "print(\"6. Keep nesting reasonable (max 2-3 levels)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-World TOML Examples and Use Cases\n",
    "print(\"=== Python pyproject.toml Example ===\")\n",
    "\n",
    "pyproject_toml = '''\n",
    "[build-system]\n",
    "requires = [\"poetry-core\"]\n",
    "build-backend = \"poetry.core.masonry.api\"\n",
    "\n",
    "[tool.poetry]\n",
    "name = \"my-awesome-package\"\n",
    "version = \"0.1.0\"\n",
    "description = \"A package that does awesome things\"\n",
    "authors = [\"Your Name <you@example.com>\"]\n",
    "license = \"MIT\"\n",
    "readme = \"README.md\"\n",
    "homepage = \"https://github.com/yourusername/my-awesome-package\"\n",
    "repository = \"https://github.com/yourusername/my-awesome-package\"\n",
    "documentation = \"https://my-awesome-package.readthedocs.io\"\n",
    "keywords = [\"python\", \"awesome\", \"package\"]\n",
    "classifiers = [\n",
    "    \"Development Status :: 4 - Beta\",\n",
    "    \"Intended Audience :: Developers\",\n",
    "    \"License :: OSI Approved :: MIT License\",\n",
    "    \"Programming Language :: Python :: 3\",\n",
    "    \"Programming Language :: Python :: 3.8\",\n",
    "    \"Programming Language :: Python :: 3.9\",\n",
    "    \"Programming Language :: Python :: 3.10\",\n",
    "    \"Programming Language :: Python :: 3.11\",\n",
    "]\n",
    "\n",
    "[tool.poetry.dependencies]\n",
    "python = \"^3.8\"\n",
    "requests = \"^2.28.0\"\n",
    "click = \"^8.1.0\"\n",
    "pydantic = \"^1.10.0\"\n",
    "\n",
    "[tool.poetry.group.dev.dependencies]\n",
    "pytest = \"^7.1.0\"\n",
    "black = \"^22.3.0\"\n",
    "isort = \"^5.10.0\"\n",
    "flake8 = \"^4.0.0\"\n",
    "mypy = \"^0.961\"\n",
    "pre-commit = \"^2.19.0\"\n",
    "\n",
    "[tool.poetry.scripts]\n",
    "my-cli = \"my_package.cli:main\"\n",
    "\n",
    "[tool.black]\n",
    "line-length = 88\n",
    "target-version = ['py38', 'py39', 'py310', 'py311']\n",
    "include = '\\\\.pyi?$'\n",
    "exclude = '''\n",
    "/(\n",
    "    \\\\.git\n",
    "  | \\\\.venv\n",
    "  | build\n",
    "  | dist\n",
    ")/\n",
    "'''\n",
    "\n",
    "[tool.isort]\n",
    "profile = \"black\"\n",
    "multi_line_output = 3\n",
    "line_length = 88\n",
    "\n",
    "[tool.mypy]\n",
    "python_version = \"3.8\"\n",
    "warn_return_any = true\n",
    "warn_unused_configs = true\n",
    "disallow_untyped_defs = true\n",
    "\n",
    "[tool.pytest.ini_options]\n",
    "testpaths = [\"tests\"]\n",
    "python_files = [\"test_*.py\"]\n",
    "python_classes = [\"Test*\"]\n",
    "python_functions = [\"test_*\"]\n",
    "addopts = \"-v --tb=short --strict-markers\"\n",
    "markers = [\n",
    "    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n",
    "    \"integration: marks tests as integration tests\",\n",
    "]\n",
    "'''\n",
    "\n",
    "try:\n",
    "    pyproject_data = tomllib.loads(pyproject_toml)\n",
    "    print(\"‚úÖ pyproject.toml parsed successfully!\")\n",
    "    print(f\"Package: {pyproject_data['tool']['poetry']['name']}\")\n",
    "    print(f\"Version: {pyproject_data['tool']['poetry']['version']}\")\n",
    "    print(f\"Python requirement: {pyproject_data['tool']['poetry']['dependencies']['python']}\")\n",
    "    print(f\"Dependencies: {len(pyproject_data['tool']['poetry']['dependencies']) - 1}\")  # -1 for python\n",
    "    print(f\"Dev dependencies: {len(pyproject_data['tool']['poetry']['group']['dev']['dependencies'])}\")\n",
    "    print(f\"Black line length: {pyproject_data['tool']['black']['line-length']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error parsing pyproject.toml: {e}\")\n",
    "\n",
    "print(\"\\n=== Rust Cargo.toml Example ===\")\n",
    "\n",
    "cargo_toml = '''\n",
    "[package]\n",
    "name = \"my-rust-app\"\n",
    "version = \"0.1.0\"\n",
    "edition = \"2021\"\n",
    "authors = [\"Your Name <you@example.com>\"]\n",
    "license = \"MIT OR Apache-2.0\"\n",
    "description = \"A fast and reliable Rust application\"\n",
    "homepage = \"https://github.com/yourusername/my-rust-app\"\n",
    "repository = \"https://github.com/yourusername/my-rust-app\"\n",
    "readme = \"README.md\"\n",
    "keywords = [\"cli\", \"performance\", \"rust\"]\n",
    "categories = [\"command-line-utilities\"]\n",
    "\n",
    "[dependencies]\n",
    "clap = { version = \"4.0\", features = [\"derive\"] }\n",
    "tokio = { version = \"1.0\", features = [\"full\"] }\n",
    "serde = { version = \"1.0\", features = [\"derive\"] }\n",
    "serde_json = \"1.0\"\n",
    "reqwest = { version = \"0.11\", features = [\"json\"] }\n",
    "anyhow = \"1.0\"\n",
    "tracing = \"0.1\"\n",
    "tracing-subscriber = \"0.3\"\n",
    "\n",
    "[dev-dependencies]\n",
    "criterion = \"0.5\"\n",
    "tempfile = \"3.0\"\n",
    "\n",
    "[[bin]]\n",
    "name = \"my-app\"\n",
    "path = \"src/main.rs\"\n",
    "\n",
    "[[bench]]\n",
    "name = \"performance\"\n",
    "harness = false\n",
    "\n",
    "[profile.release]\n",
    "opt-level = 3\n",
    "lto = true\n",
    "codegen-units = 1\n",
    "panic = \"abort\"\n",
    "\n",
    "[profile.dev]\n",
    "opt-level = 0\n",
    "debug = true\n",
    "'''\n",
    "\n",
    "try:\n",
    "    cargo_data = tomllib.loads(cargo_toml)\n",
    "    print(\"‚úÖ Cargo.toml parsed successfully!\")\n",
    "    print(f\"Package: {cargo_data['package']['name']}\")\n",
    "    print(f\"Edition: {cargo_data['package']['edition']}\")\n",
    "    print(f\"Dependencies: {len(cargo_data['dependencies'])}\")\n",
    "    print(f\"Release optimization: {cargo_data['profile']['release']['opt-level']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error parsing Cargo.toml: {e}\")\n",
    "\n",
    "print(\"\\n=== Application Configuration Example ===\")\n",
    "\n",
    "app_config_toml = '''\n",
    "# Application Configuration\n",
    "[app]\n",
    "name = \"E-commerce API\"\n",
    "version = \"2.4.1\"\n",
    "environment = \"production\"\n",
    "debug = false\n",
    "\n",
    "[server]\n",
    "host = \"0.0.0.0\"\n",
    "port = 8000\n",
    "workers = 8\n",
    "keep_alive = 65\n",
    "max_request_size = \"10MB\"\n",
    "\n",
    "[database]\n",
    "url = \"postgresql://user:pass@db.example.com:5432/ecommerce\"\n",
    "pool_size = 20\n",
    "max_overflow = 30\n",
    "pool_timeout = 30\n",
    "pool_recycle = 3600\n",
    "\n",
    "[cache]\n",
    "backend = \"redis\"\n",
    "url = \"redis://cache.example.com:6379/0\"\n",
    "default_timeout = 300\n",
    "key_prefix = \"ecom:\"\n",
    "\n",
    "[security]\n",
    "secret_key = \"your-super-secret-key-here\"\n",
    "algorithm = \"HS256\"\n",
    "access_token_expire_minutes = 30\n",
    "refresh_token_expire_days = 7\n",
    "\n",
    "[email]\n",
    "smtp_host = \"smtp.example.com\"\n",
    "smtp_port = 587\n",
    "smtp_user = \"noreply@example.com\"\n",
    "smtp_password = \"email-password\"\n",
    "use_tls = true\n",
    "\n",
    "[logging]\n",
    "level = \"INFO\"\n",
    "format = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "\n",
    "[logging.handlers.file]\n",
    "filename = \"/var/log/ecommerce-api.log\"\n",
    "max_bytes = 10485760  # 10MB\n",
    "backup_count = 5\n",
    "\n",
    "[logging.handlers.console]\n",
    "stream = \"ext://sys.stdout\"\n",
    "\n",
    "# Payment providers\n",
    "[[payment.providers]]\n",
    "name = \"stripe\"\n",
    "api_key = \"sk_live_...\"\n",
    "webhook_secret = \"whsec_...\"\n",
    "enabled = true\n",
    "\n",
    "[[payment.providers]]\n",
    "name = \"paypal\"\n",
    "client_id = \"paypal_client_id\"\n",
    "client_secret = \"paypal_secret\"\n",
    "sandbox = false\n",
    "enabled = true\n",
    "\n",
    "# Feature flags\n",
    "[features]\n",
    "user_registration = true\n",
    "email_verification = true\n",
    "two_factor_auth = false\n",
    "social_login = true\n",
    "product_reviews = true\n",
    "wishlist = true\n",
    "recommendations = false\n",
    "'''\n",
    "\n",
    "try:\n",
    "    app_config_data = tomllib.loads(app_config_toml)\n",
    "    print(\"‚úÖ Application config parsed successfully!\")\n",
    "    print(f\"App: {app_config_data['app']['name']} v{app_config_data['app']['version']}\")\n",
    "    print(f\"Environment: {app_config_data['app']['environment']}\")\n",
    "    print(f\"Server: {app_config_data['server']['host']}:{app_config_data['server']['port']}\")\n",
    "    print(f\"Workers: {app_config_data['server']['workers']}\")\n",
    "    print(f\"Payment providers: {len(app_config_data['payment']['providers'])}\")\n",
    "    \n",
    "    enabled_features = [k for k, v in app_config_data['features'].items() if v]\n",
    "    print(f\"Enabled features: {', '.join(enabled_features)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error parsing application config: {e}\")\n",
    "\n",
    "print(\"\\n=== TOML Use Cases Summary ===\")\n",
    "print(\"\"\"\n",
    "üêç Python Projects:\n",
    "  ‚Ä¢ pyproject.toml - Project metadata, dependencies, tool configuration\n",
    "  ‚Ä¢ setup.cfg alternative for project configuration\n",
    "  ‚Ä¢ Tool-specific configs (black, isort, pytest, mypy)\n",
    "\n",
    "ü¶Ä Rust Projects:\n",
    "  ‚Ä¢ Cargo.toml - Package metadata, dependencies, build configuration\n",
    "  ‚Ä¢ Workspace configuration for multi-crate projects\n",
    "\n",
    "‚öôÔ∏è Applications:\n",
    "  ‚Ä¢ Configuration files for web applications\n",
    "  ‚Ä¢ Database connection settings\n",
    "  ‚Ä¢ API configurations and feature flags\n",
    "  ‚Ä¢ CI/CD pipeline configurations\n",
    "\n",
    "üîß Tools & Systems:\n",
    "  ‚Ä¢ Docker Compose alternatives\n",
    "  ‚Ä¢ Infrastructure as Code configurations\n",
    "  ‚Ä¢ Static site generators (Hugo, etc.)\n",
    "  ‚Ä¢ Package managers and build tools\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Tutorial Summary: Essential Python Libraries\n",
    "\n",
    "Congratulations! You've explored 7 essential Python libraries that will significantly enhance your programming productivity and capabilities:\n",
    "\n",
    "## üìÅ **Pathlib** - Modern Path Handling\n",
    "- **Purpose**: Object-oriented file system paths\n",
    "- **Key Benefits**: Cross-platform compatibility, intuitive API, chain operations\n",
    "- **When to Use**: File operations, path manipulations, directory traversals\n",
    "- **Power Feature**: `Path.glob()` for pattern matching\n",
    "\n",
    "## üç¶ **iceCream** - Enhanced Debugging  \n",
    "- **Purpose**: Better debugging with automatic variable name detection\n",
    "- **Key Benefits**: Zero configuration, colorized output, conditional debugging\n",
    "- **When to Use**: Development, debugging, data exploration\n",
    "- **Power Feature**: `ic.configureOutput()` for custom formatting\n",
    "\n",
    "## ‚ö° **Numba** - High-Performance Computing\n",
    "- **Purpose**: JIT compilation for numerical Python code\n",
    "- **Key Benefits**: 10-1000x speed improvements, easy integration\n",
    "- **When to Use**: Numerical computations, loops, mathematical functions\n",
    "- **Power Feature**: `@njit` for automatic optimization\n",
    "\n",
    "## üóÇÔ∏è **Collections** - Specialized Data Structures\n",
    "- **Purpose**: Enhanced alternatives to built-in data types\n",
    "- **Key Benefits**: Optimized for specific use cases, clean APIs\n",
    "- **When to Use**: Counting, default values, ordered data, named tuples\n",
    "- **Power Feature**: `Counter` for frequency analysis\n",
    "\n",
    "## üîß **Functools** - Functional Programming Tools\n",
    "- **Purpose**: Higher-order functions and operations on callable objects\n",
    "- **Key Benefits**: Caching, partial application, decorators\n",
    "- **When to Use**: Performance optimization, functional programming patterns\n",
    "- **Power Feature**: `@lru_cache` for automatic memoization\n",
    "\n",
    "## üìÑ **YAML** - Human-Readable Data Serialization\n",
    "- **Purpose**: Configuration files and data exchange\n",
    "- **Key Benefits**: Human-readable, supports complex data structures\n",
    "- **When to Use**: Config files, CI/CD, Kubernetes, Docker Compose\n",
    "- **Power Feature**: Anchors & references for reducing duplication\n",
    "\n",
    "## üìã **TOML** - Tom's Obvious Minimal Language\n",
    "- **Purpose**: Configuration files with clear, unambiguous syntax\n",
    "- **Key Benefits**: Human-readable, type-safe, built into Python 3.11+\n",
    "- **When to Use**: Python projects (pyproject.toml), app configs, build tools\n",
    "- **Power Feature**: Tables and arrays of tables for structured data\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **Next Steps**\n",
    "1. **Practice**: Try implementing examples from each tutorial\n",
    "2. **Integrate**: Use these libraries in your projects\n",
    "3. **Explore**: Check official documentation for advanced features\n",
    "4. **Combine**: Many libraries work great together (e.g., Pathlib + YAML/TOML for config loading)\n",
    "\n",
    "## üí° **Pro Tips**\n",
    "- Start with **iceCream** for immediate debugging improvements\n",
    "- Use **Pathlib** instead of `os.path` for all new projects  \n",
    "- Apply **Numba** to your slowest numerical functions\n",
    "- Keep **Collections** in mind when working with data structures\n",
    "- Leverage **Functools** for cleaner, more efficient code\n",
    "- Use **YAML** for complex configurations and **TOML** for Python projects\n",
    "- Choose **TOML** for `pyproject.toml` and clear, type-safe configs\n",
    "\n",
    "Happy coding! üêç‚ú®"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOx7X+DxNeKu1zUVVCmsSHJ",
   "provenance": [
    {
     "file_id": "1_9UtYmPVVGmnWIKdBzPYkbtTlTbd0clo",
     "timestamp": 1735604987843
    },
    {
     "file_id": "15x56uwwONMo_ilzUJgt6UcX1d552xH6X",
     "timestamp": 1708441161475
    },
    {
     "file_id": "1LbG88IWtk30WlIoINzG4_vXHoJAvoDaP",
     "timestamp": 1683614319950
    }
   ]
  },
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
