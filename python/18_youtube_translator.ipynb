{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5606eff4",
   "metadata": {},
   "source": [
    "\"\"\"youtube_translation_pipeline.py\n",
    "\n",
    "A self‑contained OOP pipeline that\n",
    "1. Grabs basic YouTube metadata **with pytube** (no Data API needed)\n",
    "2. Pulls the English transcript via *youtube‑transcript‑api*\n",
    "3. Translates the full transcript → Armenian with four back‑ends:\n",
    "      • Google Translate (googletrans)\n",
    "      • DeepL\n",
    "      • OpenAI GPT\n",
    "      • Anthropic Claude\n",
    "4. Stores all results + source metadata in `<video_id>_translations.json`.\n",
    "\n",
    "Install requirements:\n",
    "    pip install pytube youtube-transcript-api googletrans==4.0.0-rc1 \\\n",
    "                deepl openai anthropic\n",
    "\n",
    "Set env vars for the keys you actually use:\n",
    "    export DEEPL_API_KEY=...\n",
    "    export OPENAI_API_KEY=...\n",
    "    export ANTHROPIC_API_KEY=...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ace70b",
   "metadata": {},
   "source": [
    "# Google AI Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a52d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44ab2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6150357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make decisions or perform tasks, mimicking human intelligence.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "key = \"AIzaSyBL4SGRSnP_uSUCfyL7bOgZFlZnCUa875c\"\n",
    "client = genai.Client(api_key=key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f208dd6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-tts', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 164>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbits_per_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: bits_per_sample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m\"\u001b[39m: rate}\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 165\u001b[0m     \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m generate_content_config \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[0;32m     51\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     52\u001b[0m     response_modalities\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     ),\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m file_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content_stream(\n\u001b[0;32m     66\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     67\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m     68\u001b[0m     config\u001b[38;5;241m=\u001b[39mgenerate_content_config,\n\u001b[0;32m     69\u001b[0m ):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     71\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mcandidates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     ):\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\models.py:5974\u001b[0m, in \u001b[0;36mModels.generate_content_stream\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5968\u001b[0m function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   5971\u001b[0m   \u001b[38;5;66;03m# First request gets a function call.\u001b[39;00m\n\u001b[0;32m   5972\u001b[0m   \u001b[38;5;66;03m# Then get function response parts.\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m   \u001b[38;5;66;03m# Yield chunks only if there's no function response parts.\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m   5975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n\u001b[0;32m   5976\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\models.py:4859\u001b[0m, in \u001b[0;36mModels._generate_content_stream\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m   4852\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4853\u001b[0m ):\n\u001b[0;32m   4854\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4855\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessing the raw HTTP response is not supported in streaming\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4856\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4857\u001b[0m   )\n\u001b[1;32m-> 4859\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest_streamed(\n\u001b[0;32m   4860\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[0;32m   4861\u001b[0m ):\n\u001b[0;32m   4863\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[0;32m   4864\u001b[0m     response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(response_dict)\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\_api_client.py:1004\u001b[0m, in \u001b[0;36mBaseApiClient.request_streamed\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest_streamed\u001b[39m(\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    995\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    998\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    999\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[Any, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m   1000\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m   1001\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m   1002\u001b[0m   )\n\u001b[1;32m-> 1004\u001b[0m   session_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m session_response\u001b[38;5;241m.\u001b[39msegments():\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\_api_client.py:879\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request\u001b[39m(\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    876\u001b[0m     http_request: HttpRequest,\n\u001b[0;32m    877\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    878\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HttpResponse:\n\u001b[1;32m--> 879\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\_api_client.py:857\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    849\u001b[0m   httpx_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    850\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    851\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    854\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    855\u001b[0m   )\n\u001b[0;32m    856\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39msend(httpx_request, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m--> 857\u001b[0m   \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    858\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    859\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    860\u001b[0m   )\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\errors.py:104\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    102\u001b[0m status_code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m--> 104\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[1;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-tts', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}"
     ]
    }
   ],
   "source": [
    "# To run this code you need to install the following dependencies:\n",
    "# pip install google-genai\n",
    "\n",
    "import base64\n",
    "import mimetypes\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "def save_binary_file(file_name, data):\n",
    "    f = open(file_name, \"wb\")\n",
    "    f.write(data)\n",
    "    f.close()\n",
    "    print(f\"File saved to to: {file_name}\")\n",
    "\n",
    "key = \"AIzaSyBL4SGRSnP_uSUCfyL7bOgZFlZnCUa875c\"\n",
    "\n",
    "def generate():\n",
    "    client = genai.Client(\n",
    "        api_key=\"AIzaSyBL4SGRSnP_uSUCfyL7bOgZFlZnCUa875c\",\n",
    "    )\n",
    "\n",
    "    model = \"gemini-2.5-pro-preview-tts\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=\"\"\"Կուզես պայթիր, կուզես ճչա,\n",
    "Քեզ մարդու տեղ դնող չկա,\n",
    "Զգույշ, գլխիդ փորձանք չգա,\n",
    "Սիրտ, անցել է սրտի դարը:\n",
    "Էլ չեն երդվում քո արևով,\n",
    "Չեն տաքանում քո բարևով,\n",
    "Էլ չես վառում դու վառվելով\n",
    "Սիրտ, անցել է քո հազարը:\n",
    "Ինչքան տխրես, ինչքան ժպտաս\n",
    "Ինչքան խփես ու թպրտաս,\n",
    "Միևնույն է, տանուլ կտաս,\n",
    "Էլ չի բերում, սիրտ քո զարը:\n",
    "Միտքն է հիմա սերն աշխարհի,\n",
    "Աշխարհակալ տերն աշխարհի,\n",
    "Բեռնակիրն ու բեռն աշարհի,\n",
    "Եվ աշխարհի ճանապարհը:\"\"\"),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        response_modalities=[\n",
    "            \"audio\",\n",
    "        ],\n",
    "        speech_config=types.SpeechConfig(\n",
    "            voice_config=types.VoiceConfig(\n",
    "                prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                    voice_name=\"Zephyr\"\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    file_index = 0\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        if (\n",
    "            chunk.candidates is None\n",
    "            or chunk.candidates[0].content is None\n",
    "            or chunk.candidates[0].content.parts is None\n",
    "        ):\n",
    "            continue\n",
    "        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
    "            file_name = f\"ENTER_FILE_NAME_{file_index}\"\n",
    "            file_index += 1\n",
    "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
    "            data_buffer = inline_data.data\n",
    "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
    "            if file_extension is None:\n",
    "                file_extension = \".wav\"\n",
    "                data_buffer = convert_to_wav(inline_data.data, inline_data.mime_type)\n",
    "            save_binary_file(f\"{file_name}{file_extension}\", data_buffer)\n",
    "        else:\n",
    "            print(chunk.text)\n",
    "\n",
    "def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:\n",
    "    \"\"\"Generates a WAV file header for the given audio data and parameters.\n",
    "\n",
    "    Args:\n",
    "        audio_data: The raw audio data as a bytes object.\n",
    "        mime_type: Mime type of the audio data.\n",
    "\n",
    "    Returns:\n",
    "        A bytes object representing the WAV file header.\n",
    "    \"\"\"\n",
    "    parameters = parse_audio_mime_type(mime_type)\n",
    "    bits_per_sample = parameters[\"bits_per_sample\"]\n",
    "    sample_rate = parameters[\"rate\"]\n",
    "    num_channels = 1\n",
    "    data_size = len(audio_data)\n",
    "    bytes_per_sample = bits_per_sample // 8\n",
    "    block_align = num_channels * bytes_per_sample\n",
    "    byte_rate = sample_rate * block_align\n",
    "    chunk_size = 36 + data_size  # 36 bytes for header fields before data chunk size\n",
    "\n",
    "    # http://soundfile.sapp.org/doc/WaveFormat/\n",
    "\n",
    "    header = struct.pack(\n",
    "        \"<4sI4s4sIHHIIHH4sI\",\n",
    "        b\"RIFF\",          # ChunkID\n",
    "        chunk_size,       # ChunkSize (total file size - 8 bytes)\n",
    "        b\"WAVE\",          # Format\n",
    "        b\"fmt \",          # Subchunk1ID\n",
    "        16,               # Subchunk1Size (16 for PCM)\n",
    "        1,                # AudioFormat (1 for PCM)\n",
    "        num_channels,     # NumChannels\n",
    "        sample_rate,      # SampleRate\n",
    "        byte_rate,        # ByteRate\n",
    "        block_align,      # BlockAlign\n",
    "        bits_per_sample,  # BitsPerSample\n",
    "        b\"data\",          # Subchunk2ID\n",
    "        data_size         # Subchunk2Size (size of audio data)\n",
    "    )\n",
    "    return header + audio_data\n",
    "\n",
    "def parse_audio_mime_type(mime_type: str) -> dict[str, int | None]:\n",
    "    \"\"\"Parses bits per sample and rate from an audio MIME type string.\n",
    "\n",
    "    Assumes bits per sample is encoded like \"L16\" and rate as \"rate=xxxxx\".\n",
    "\n",
    "    Args:\n",
    "        mime_type: The audio MIME type string (e.g., \"audio/L16;rate=24000\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with \"bits_per_sample\" and \"rate\" keys. Values will be\n",
    "        integers if found, otherwise None.\n",
    "    \"\"\"\n",
    "    bits_per_sample = 16\n",
    "    rate = 24000\n",
    "\n",
    "    # Extract rate from parameters\n",
    "    parts = mime_type.split(\";\")\n",
    "    for param in parts: # Skip the main type part\n",
    "        param = param.strip()\n",
    "        if param.lower().startswith(\"rate=\"):\n",
    "            try:\n",
    "                rate_str = param.split(\"=\", 1)[1]\n",
    "                rate = int(rate_str)\n",
    "            except (ValueError, IndexError):\n",
    "                # Handle cases like \"rate=\" with no value or non-integer value\n",
    "                pass # Keep rate as default\n",
    "        elif param.startswith(\"audio/L\"):\n",
    "            try:\n",
    "                bits_per_sample = int(param.split(\"L\", 1)[1])\n",
    "            except (ValueError, IndexError):\n",
    "                pass # Keep bits_per_sample as default if conversion fails\n",
    "\n",
    "    return {\"bits_per_sample\": bits_per_sample, \"rate\": rate}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c116f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m client \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mClient(api_key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[0;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m     16\u001b[0m    model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.5-flash-preview-tts\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m    contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSay cheerfully: Պանիր\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m    )\n\u001b[0;32m     28\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minline_data\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     32\u001b[0m file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m wave_file(file_name, data) \u001b[38;5;66;03m# Saves the file to current directory\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parts'"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import wave\n",
    "\n",
    "# Set up the wave file to save the output:\n",
    "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
    "   with wave.open(filename, \"wb\") as wf:\n",
    "      wf.setnchannels(channels)\n",
    "      wf.setsampwidth(sample_width)\n",
    "      wf.setframerate(rate)\n",
    "      wf.writeframes(pcm)\n",
    "\n",
    "client = genai.Client(api_key=key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "   model=\"gemini-2.5-flash-preview-tts\",\n",
    "   contents=\"Say cheerfully: Պանիր\",\n",
    "   config=types.GenerateContentConfig(\n",
    "      response_modalities=[\"AUDIO\"],\n",
    "      speech_config=types.SpeechConfig(\n",
    "         voice_config=types.VoiceConfig(\n",
    "            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "               voice_name='Kore',\n",
    "            )\n",
    "         )\n",
    "      ),\n",
    "   )\n",
    ")\n",
    "\n",
    "data = response.candidates[0].content.parts[0].inline_data.data\n",
    "\n",
    "file_name='out.wav'\n",
    "wave_file(file_name, data) # Saves the file to current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126642e",
   "metadata": {},
   "source": [
    "# Manim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13709b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create --name youtube \n",
    "# pip install pytube youtube_transcript_api deepl openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a827a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# --- third‑party deps -------------------------------------------------------\n",
    "from pytubefix import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi  # for captions\n",
    "from googletrans import Translator as _GoogleTranslator # https://github.com/microsoft/TaskWeaver/issues/172\n",
    "import deepl  \n",
    "import openai \n",
    "# import anthropic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/microsoft/TaskWeaver/issues/172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b4322",
   "metadata": {},
   "source": [
    "# Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f1d6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class VideoInfo:\n",
    "    video_id: str\n",
    "    title: str\n",
    "    channel: str\n",
    "    publish_date: str  # ISO‑8601 date string\n",
    "    description: str\n",
    "    keywords: List[str]\n",
    "    length_seconds: int\n",
    "    url: str\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class TranscriptSegment:\n",
    "    start: float\n",
    "    duration: float\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class TranslationResult:\n",
    "    engine: str  # e.g. \"google\", \"deepl\", \"openai\", \"claude\"\n",
    "    translated_text: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b6606",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e07db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseTranslator(ABC):\n",
    "    \"\"\"Abstract translator: subclasses implement *translate()* returning Armenian text.\"\"\"\n",
    "\n",
    "    def __init__(self, target_lang: str = \"hy\") -> None:\n",
    "        self.target_lang = target_lang\n",
    "\n",
    "    @abstractmethod\n",
    "    def translate(self, text: str) -> str:\n",
    "        \"\"\"Translate *text* to *self.target_lang* and return the result.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2fb0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GoogleTranslator(BaseTranslator):\n",
    "    def __init__(self, target_lang: str = \"hy\") -> None:\n",
    "        super().__init__(target_lang)\n",
    "        self._client = _GoogleTranslator()\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        return self._client.translate(text, dest=self.target_lang).text  # type: ignore[attr-defined]\n",
    "\n",
    "\n",
    "# class DeepLTranslator(BaseTranslator):\n",
    "#     def __init__(self, api_key: Optional[str] = None, target_lang: str = \"hy\") -> None:\n",
    "#         super().__init__(target_lang)\n",
    "#         api_key = api_key or os.getenv(\"DEEPL_API_KEY\")\n",
    "#         if not api_key:\n",
    "#             raise RuntimeError(\"DEEPL_API_KEY env var required for DeepL translator\")\n",
    "#         self._client = deepl.Translator(api_key)\n",
    "\n",
    "#     def translate(self, text: str) -> str:\n",
    "#         result = self._client.translate_text(text, target_lang=self.target_lang.upper())\n",
    "#         return result.text  # type: ignore[attr-defined]\n",
    "\n",
    "\n",
    "# class OpenAITranslator(BaseTranslator):\n",
    "#     def __init__(self, model: str = \"gpt-4o-mini\", temperature: float = 0.0, target_lang: str = \"hy\") -> None:\n",
    "#         super().__init__(target_lang)\n",
    "#         self.model = model\n",
    "#         self.temperature = temperature\n",
    "\n",
    "#     def translate(self, text: str) -> str:\n",
    "#         openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#         if not openai.api_key:\n",
    "#             raise RuntimeError(\"OPENAI_API_KEY env var not set\")\n",
    "#         response = .create(  # type: ignore[attr-defined]\n",
    "#             model=self.model,\n",
    "#             messages=[\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": \"Translate the following text to Armenian (hy) keeping formatting and line breaks where reasonable.\"\n",
    "#                 },\n",
    "#                 {\"role\": \"user\", \"content\": text},\n",
    "#             ],\n",
    "#             temperature=self.temperature,\n",
    "#         )\n",
    "#         return response.choices[0].message.content.strip()  # type: ignore[attr-defined]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1-nano\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4ae0c",
   "metadata": {},
   "source": [
    "# YouTube metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19c85008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_video_info(url: str) -> VideoInfo:\n",
    "    yt = YouTube(url)\n",
    "    print(f\"Fetching video info for {url}...\")\n",
    "    print(f\"Title: {yt.title}\")\n",
    "    return VideoInfo(\n",
    "        video_id=yt.video_id,\n",
    "        title=yt.title or \"\",\n",
    "        channel=yt.author or \"\",\n",
    "        publish_date=yt.publish_date.isoformat() if yt.publish_date else \"\",\n",
    "        description=yt.description or \"\",\n",
    "        keywords=yt.keywords or [],\n",
    "        length_seconds=yt.length,\n",
    "        url=url,\n",
    "    )\n",
    "\n",
    "\n",
    "def fetch_transcript(video_id: str, lang: str = \"en\") -> List[TranscriptSegment]:\n",
    "    raw = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])\n",
    "    return [TranscriptSegment(**seg) for seg in raw]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_video_info(\"https://www.youtube.com/watch?v=3MqYE2UuN24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_transcript(\"3MqYE2UuN24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35f96490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching video info for https://www.youtube.com/watch?v=3MqYE2UuN24...\n",
      "Title: Is it Better to Walk or Run in the Rain?\n",
      "Title: Is it Better to Walk or Run in the Rain?\n",
      "Translating with GoogleTranslator…\n",
      "Translating with GoogleTranslator…\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m example_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=3MqYE2UuN24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m TranslationPipeline(\n\u001b[0;32m     53\u001b[0m     url\u001b[38;5;241m=\u001b[39mexample_url,\n\u001b[0;32m     54\u001b[0m     translators\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     ],\n\u001b[0;32m     60\u001b[0m )\n\u001b[1;32m---> 61\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mTranslationPipeline.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslators:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslating with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     armenian_text \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(TranslationResult(engine\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, translated_text\u001b[38;5;241m=\u001b[39marmenian_text))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 3. persist\u001b[39;00m\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mGoogleTranslator.translate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtranslate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_lang\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# YouTube utilities (pytube + youtube_transcript_api)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Orchestration pipeline\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class TranslationPipeline:\n",
    "    url: str\n",
    "    translators: List[BaseTranslator] = field(default_factory=list)\n",
    "    out_dir: str = \"out\"\n",
    "\n",
    "    def run(self) -> None:\n",
    "        # 1. fetch metadata + transcript\n",
    "        info = fetch_video_info(self.url)\n",
    "        transcript_segments = fetch_transcript(info.video_id)\n",
    "        full_text = \"\\n\".join(seg.text for seg in transcript_segments)\n",
    "\n",
    "        # 2. run each translator\n",
    "        results: List[TranslationResult] = []\n",
    "        for t in self.translators:\n",
    "            print(f\"Translating with {t.__class__.__name__}…\")\n",
    "            armenian_text = t.translate(full_text)\n",
    "            results.append(TranslationResult(engine=t.__class__.__name__, translated_text=armenian_text))\n",
    "\n",
    "        # 3. persist\n",
    "        self.out_dir.mkdir(exist_ok=True)\n",
    "        out_path = self.out_dir / f\"{info.video_id}_translations.json\"\n",
    "        with out_path.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            json.dump(\n",
    "                {\n",
    "                    \"video\": asdict(info),\n",
    "                    \"translations\": [asdict(r) for r in results],\n",
    "                    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                },\n",
    "                fp,\n",
    "                ensure_ascii=False,\n",
    "                indent=2,\n",
    "            )\n",
    "        print(f\"Saved ⇒ {out_path}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Simple entry‑point (no argparse)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # example_url = input(\"YouTube URL: \").strip()\n",
    "    example_url = \"https://www.youtube.com/watch?v=3MqYE2UuN24\"\n",
    "    pipeline = TranslationPipeline(\n",
    "        url=example_url,\n",
    "        translators=[\n",
    "            GoogleTranslator(),\n",
    "            # DeepLTranslator(),\n",
    "            # OpenAITranslator(),\n",
    "            # ClaudeTranslator(),\n",
    "        ],\n",
    "    )\n",
    "    pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71374677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(os.environ)\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY env var not set\")\n",
    "response = openai.ChatCompletion.create(  # type: ignore[attr-defined]\n",
    "    model=self.model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Translate the following text to Armenian (hy) keeping formatting and line breaks where reasonable.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Cheese\"},\n",
    "    ],\n",
    "    temperature=self.temperature,\n",
    ")\n",
    "return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93036335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc3874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
