{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5606eff4",
   "metadata": {},
   "source": [
    "\"\"\"youtube_translation_pipeline.py\n",
    "\n",
    "A self‑contained OOP pipeline that\n",
    "1. Grabs basic YouTube metadata **with pytube** (no Data API needed)\n",
    "2. Pulls the English transcript via *youtube‑transcript‑api*\n",
    "3. Translates the full transcript → Armenian with four back‑ends:\n",
    "      • Google Translate (googletrans)\n",
    "      • DeepL\n",
    "      • OpenAI GPT\n",
    "      • Anthropic Claude\n",
    "4. Stores all results + source metadata in `<video_id>_translations.json`.\n",
    "\n",
    "Install requirements:\n",
    "    pip install pytube youtube-transcript-api googletrans==4.0.0-rc1 \\\n",
    "                deepl openai anthropic\n",
    "\n",
    "Set env vars for the keys you actually use:\n",
    "    export DEEPL_API_KEY=...\n",
    "    export OPENAI_API_KEY=...\n",
    "    export ANTHROPIC_API_KEY=...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ace70b",
   "metadata": {},
   "source": [
    "# Google AI Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a52d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44ab2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6150357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make decisions or perform tasks, mimicking human intelligence.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "key = \"\"\n",
    "client = genai.Client(api_key=key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208dd6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-tts', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 164>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbits_per_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: bits_per_sample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m\"\u001b[39m: rate}\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 165\u001b[0m     \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m generate_content_config \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[0;32m     51\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     52\u001b[0m     response_modalities\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     ),\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m file_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content_stream(\n\u001b[0;32m     66\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     67\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m     68\u001b[0m     config\u001b[38;5;241m=\u001b[39mgenerate_content_config,\n\u001b[0;32m     69\u001b[0m ):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     71\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mcandidates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     ):\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\models.py:5974\u001b[0m, in \u001b[0;36mModels.generate_content_stream\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5968\u001b[0m function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   5971\u001b[0m   \u001b[38;5;66;03m# First request gets a function call.\u001b[39;00m\n\u001b[0;32m   5972\u001b[0m   \u001b[38;5;66;03m# Then get function response parts.\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m   \u001b[38;5;66;03m# Yield chunks only if there's no function response parts.\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m   5975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n\u001b[0;32m   5976\u001b[0m       \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\models.py:4859\u001b[0m, in \u001b[0;36mModels._generate_content_stream\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m   4852\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4853\u001b[0m ):\n\u001b[0;32m   4854\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4855\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessing the raw HTTP response is not supported in streaming\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4856\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4857\u001b[0m   )\n\u001b[1;32m-> 4859\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest_streamed(\n\u001b[0;32m   4860\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[0;32m   4861\u001b[0m ):\n\u001b[0;32m   4863\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[0;32m   4864\u001b[0m     response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(response_dict)\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\_api_client.py:1004\u001b[0m, in \u001b[0;36mBaseApiClient.request_streamed\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest_streamed\u001b[39m(\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    995\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    998\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    999\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[Any, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m   1000\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m   1001\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m   1002\u001b[0m   )\n\u001b[1;32m-> 1004\u001b[0m   session_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m session_response\u001b[38;5;241m.\u001b[39msegments():\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\_api_client.py:879\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request\u001b[39m(\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    876\u001b[0m     http_request: HttpRequest,\n\u001b[0;32m    877\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    878\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HttpResponse:\n\u001b[1;32m--> 879\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\_api_client.py:857\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    849\u001b[0m   httpx_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    850\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    851\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    854\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    855\u001b[0m   )\n\u001b[0;32m    856\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39msend(httpx_request, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m--> 857\u001b[0m   \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    858\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    859\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    860\u001b[0m   )\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\google\\genai\\errors.py:104\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    102\u001b[0m status_code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m--> 104\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[1;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-tts', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-tts'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}"
     ]
    }
   ],
   "source": [
    "# # To run this code you need to install the following dependencies:\n",
    "# # pip install google-genai\n",
    "\n",
    "# import base64\n",
    "# import mimetypes\n",
    "# import os\n",
    "# import re\n",
    "# import struct\n",
    "# from google import genai\n",
    "# from google.genai import types\n",
    "\n",
    "\n",
    "# def save_binary_file(file_name, data):\n",
    "#     f = open(file_name, \"wb\")\n",
    "#     f.write(data)\n",
    "#     f.close()\n",
    "#     print(f\"File saved to to: {file_name}\")\n",
    "\n",
    "# key = \"AIzaSyBL4SGRSnP_uSUCfyL7bOgZFlZnCUa875c\"\n",
    "\n",
    "# def generate():\n",
    "#     client = genai.Client(\n",
    "#         api_key=\"AIzaSyBL4SGRSnP_uSUCfyL7bOgZFlZnCUa875c\",\n",
    "#     )\n",
    "\n",
    "#     model = \"gemini-2.5-pro-preview-tts\"\n",
    "#     contents = [\n",
    "#         types.Content(\n",
    "#             role=\"user\",\n",
    "#             parts=[\n",
    "#                 types.Part.from_text(text=\"\"\"Կուզես պայթիր, կուզես ճչա,\n",
    "# Քեզ մարդու տեղ դնող չկա,\n",
    "# Զգույշ, գլխիդ փորձանք չգա,\n",
    "# Սիրտ, անցել է սրտի դարը:\n",
    "# Էլ չեն երդվում քո արևով,\n",
    "# Չեն տաքանում քո բարևով,\n",
    "# Էլ չես վառում դու վառվելով\n",
    "# Սիրտ, անցել է քո հազարը:\n",
    "# Ինչքան տխրես, ինչքան ժպտաս\n",
    "# Ինչքան խփես ու թպրտաս,\n",
    "# Միևնույն է, տանուլ կտաս,\n",
    "# Էլ չի բերում, սիրտ քո զարը:\n",
    "# Միտքն է հիմա սերն աշխարհի,\n",
    "# Աշխարհակալ տերն աշխարհի,\n",
    "# Բեռնակիրն ու բեռն աշարհի,\n",
    "# Եվ աշխարհի ճանապարհը:\"\"\"),\n",
    "#             ],\n",
    "#         ),\n",
    "#     ]\n",
    "#     generate_content_config = types.GenerateContentConfig(\n",
    "#         temperature=1,\n",
    "#         response_modalities=[\n",
    "#             \"audio\",\n",
    "#         ],\n",
    "#         speech_config=types.SpeechConfig(\n",
    "#             voice_config=types.VoiceConfig(\n",
    "#                 prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "#                     voice_name=\"Zephyr\"\n",
    "#                 )\n",
    "#             )\n",
    "#         ),\n",
    "#     )\n",
    "\n",
    "#     file_index = 0\n",
    "#     for chunk in client.models.generate_content_stream(\n",
    "#         model=model,\n",
    "#         contents=contents,\n",
    "#         config=generate_content_config,\n",
    "#     ):\n",
    "#         if (\n",
    "#             chunk.candidates is None\n",
    "#             or chunk.candidates[0].content is None\n",
    "#             or chunk.candidates[0].content.parts is None\n",
    "#         ):\n",
    "#             continue\n",
    "#         if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
    "#             file_name = f\"ENTER_FILE_NAME_{file_index}\"\n",
    "#             file_index += 1\n",
    "#             inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
    "#             data_buffer = inline_data.data\n",
    "#             file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
    "#             if file_extension is None:\n",
    "#                 file_extension = \".wav\"\n",
    "#                 data_buffer = convert_to_wav(inline_data.data, inline_data.mime_type)\n",
    "#             save_binary_file(f\"{file_name}{file_extension}\", data_buffer)\n",
    "#         else:\n",
    "#             print(chunk.text)\n",
    "\n",
    "# def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:\n",
    "#     \"\"\"Generates a WAV file header for the given audio data and parameters.\n",
    "\n",
    "#     Args:\n",
    "#         audio_data: The raw audio data as a bytes object.\n",
    "#         mime_type: Mime type of the audio data.\n",
    "\n",
    "#     Returns:\n",
    "#         A bytes object representing the WAV file header.\n",
    "#     \"\"\"\n",
    "#     parameters = parse_audio_mime_type(mime_type)\n",
    "#     bits_per_sample = parameters[\"bits_per_sample\"]\n",
    "#     sample_rate = parameters[\"rate\"]\n",
    "#     num_channels = 1\n",
    "#     data_size = len(audio_data)\n",
    "#     bytes_per_sample = bits_per_sample // 8\n",
    "#     block_align = num_channels * bytes_per_sample\n",
    "#     byte_rate = sample_rate * block_align\n",
    "#     chunk_size = 36 + data_size  # 36 bytes for header fields before data chunk size\n",
    "\n",
    "#     # http://soundfile.sapp.org/doc/WaveFormat/\n",
    "\n",
    "#     header = struct.pack(\n",
    "#         \"<4sI4s4sIHHIIHH4sI\",\n",
    "#         b\"RIFF\",          # ChunkID\n",
    "#         chunk_size,       # ChunkSize (total file size - 8 bytes)\n",
    "#         b\"WAVE\",          # Format\n",
    "#         b\"fmt \",          # Subchunk1ID\n",
    "#         16,               # Subchunk1Size (16 for PCM)\n",
    "#         1,                # AudioFormat (1 for PCM)\n",
    "#         num_channels,     # NumChannels\n",
    "#         sample_rate,      # SampleRate\n",
    "#         byte_rate,        # ByteRate\n",
    "#         block_align,      # BlockAlign\n",
    "#         bits_per_sample,  # BitsPerSample\n",
    "#         b\"data\",          # Subchunk2ID\n",
    "#         data_size         # Subchunk2Size (size of audio data)\n",
    "#     )\n",
    "#     return header + audio_data\n",
    "\n",
    "# def parse_audio_mime_type(mime_type: str) -> dict[str, int | None]:\n",
    "#     \"\"\"Parses bits per sample and rate from an audio MIME type string.\n",
    "\n",
    "#     Assumes bits per sample is encoded like \"L16\" and rate as \"rate=xxxxx\".\n",
    "\n",
    "#     Args:\n",
    "#         mime_type: The audio MIME type string (e.g., \"audio/L16;rate=24000\").\n",
    "\n",
    "#     Returns:\n",
    "#         A dictionary with \"bits_per_sample\" and \"rate\" keys. Values will be\n",
    "#         integers if found, otherwise None.\n",
    "#     \"\"\"\n",
    "#     bits_per_sample = 16\n",
    "#     rate = 24000\n",
    "\n",
    "#     # Extract rate from parameters\n",
    "#     parts = mime_type.split(\";\")\n",
    "#     for param in parts: # Skip the main type part\n",
    "#         param = param.strip()\n",
    "#         if param.lower().startswith(\"rate=\"):\n",
    "#             try:\n",
    "#                 rate_str = param.split(\"=\", 1)[1]\n",
    "#                 rate = int(rate_str)\n",
    "#             except (ValueError, IndexError):\n",
    "#                 # Handle cases like \"rate=\" with no value or non-integer value\n",
    "#                 pass # Keep rate as default\n",
    "#         elif param.startswith(\"audio/L\"):\n",
    "#             try:\n",
    "#                 bits_per_sample = int(param.split(\"L\", 1)[1])\n",
    "#             except (ValueError, IndexError):\n",
    "#                 pass # Keep bits_per_sample as default if conversion fails\n",
    "\n",
    "#     return {\"bits_per_sample\": bits_per_sample, \"rate\": rate}\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c116f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m client \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mClient(api_key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[0;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m     16\u001b[0m    model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.5-flash-preview-tts\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m    contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSay cheerfully: Պանիր\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m    )\n\u001b[0;32m     28\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minline_data\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     32\u001b[0m file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m wave_file(file_name, data) \u001b[38;5;66;03m# Saves the file to current directory\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parts'"
     ]
    }
   ],
   "source": [
    "# from google import genai\n",
    "# from google.genai import types\n",
    "# import wave\n",
    "\n",
    "# # Set up the wave file to save the output:\n",
    "# def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
    "#    with wave.open(filename, \"wb\") as wf:\n",
    "#       wf.setnchannels(channels)\n",
    "#       wf.setsampwidth(sample_width)\n",
    "#       wf.setframerate(rate)\n",
    "#       wf.writeframes(pcm)\n",
    "\n",
    "# client = genai.Client(api_key=key)\n",
    "\n",
    "# response = client.models.generate_content(\n",
    "#    model=\"gemini-2.5-flash-preview-tts\",\n",
    "#    contents=\"Say cheerfully: Պանիր\",\n",
    "#    config=types.GenerateContentConfig(\n",
    "#       response_modalities=[\"AUDIO\"],\n",
    "#       speech_config=types.SpeechConfig(\n",
    "#          voice_config=types.VoiceConfig(\n",
    "#             prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "#                voice_name='Kore',\n",
    "#             )\n",
    "#          )\n",
    "#       ),\n",
    "#    )\n",
    "# )\n",
    "\n",
    "# data = response.candidates[0].content.parts[0].inline_data.data\n",
    "\n",
    "# file_name='out.wav'\n",
    "# wave_file(file_name, data) # Saves the file to current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126642e",
   "metadata": {},
   "source": [
    "# Manim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13709b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create --name youtube \n",
    "# pip install pytube youtube_transcript_api deepl openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a827a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# --- third‑party deps -------------------------------------------------------\n",
    "from pytubefix import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi  # for captions\n",
    "from googletrans import Translator as _GoogleTranslator # https://github.com/microsoft/TaskWeaver/issues/172\n",
    "# import deepl  \n",
    "# import openai \n",
    "# import anthropic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/microsoft/TaskWeaver/issues/172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b4322",
   "metadata": {},
   "source": [
    "# Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f1d6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class VideoInfo:\n",
    "    video_id: str\n",
    "    title: str\n",
    "    channel: str\n",
    "    publish_date: str  # ISO‑8601 date string\n",
    "    description: str\n",
    "    keywords: List[str]\n",
    "    length_seconds: int\n",
    "    url: str\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class TranscriptSegment:\n",
    "    start: float\n",
    "    duration: float\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class TranslationResult:\n",
    "    engine: str  # e.g. \"google\", \"deepl\", \"openai\", \"claude\"\n",
    "    translated_text: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b6606",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e07db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseTranslator(ABC):\n",
    "    \"\"\"Abstract translator: subclasses implement *translate()* returning Armenian text.\"\"\"\n",
    "\n",
    "    def __init__(self, target_lang: str = \"hy\") -> None:\n",
    "        self.target_lang = target_lang\n",
    "\n",
    "    @abstractmethod\n",
    "    def translate(self, text: str) -> str:\n",
    "        \"\"\"Translate *text* to *self.target_lang* and return the result.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2fb0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GoogleTranslator(BaseTranslator):\n",
    "    def __init__(self, target_lang: str = \"hy\") -> None:\n",
    "        super().__init__(target_lang)\n",
    "        self._client = _GoogleTranslator()\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        return self._client.translate(text, dest=self.target_lang).text  # type: ignore[attr-defined]\n",
    "\n",
    "\n",
    "# class DeepLTranslator(BaseTranslator):\n",
    "#     def __init__(self, api_key: Optional[str] = None, target_lang: str = \"hy\") -> None:\n",
    "#         super().__init__(target_lang)\n",
    "#         api_key = api_key or os.getenv(\"DEEPL_API_KEY\")\n",
    "#         if not api_key:\n",
    "#             raise RuntimeError(\"DEEPL_API_KEY env var required for DeepL translator\")\n",
    "#         self._client = deepl.Translator(api_key)\n",
    "\n",
    "#     def translate(self, text: str) -> str:\n",
    "#         result = self._client.translate_text(text, target_lang=self.target_lang.upper())\n",
    "#         return result.text  # type: ignore[attr-defined]\n",
    "\n",
    "\n",
    "# class OpenAITranslator(BaseTranslator):\n",
    "#     def __init__(self, model: str = \"gpt-4o-mini\", temperature: float = 0.0, target_lang: str = \"hy\") -> None:\n",
    "#         super().__init__(target_lang)\n",
    "#         self.model = model\n",
    "#         self.temperature = temperature\n",
    "\n",
    "#     def translate(self, text: str) -> str:\n",
    "#         openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#         if not openai.api_key:\n",
    "#             raise RuntimeError(\"OPENAI_API_KEY env var not set\")\n",
    "#         response = .create(  # type: ignore[attr-defined]\n",
    "#             model=self.model,\n",
    "#             messages=[\n",
    "#                 {\n",
    "#                     \"role\": \"system\",\n",
    "#                     \"content\": \"Translate the following text to Armenian (hy) keeping formatting and line breaks where reasonable.\"\n",
    "#                 },\n",
    "#                 {\"role\": \"user\", \"content\": text},\n",
    "#             ],\n",
    "#             temperature=self.temperature,\n",
    "#         )\n",
    "#         return response.choices[0].message.content.strip()  # type: ignore[attr-defined]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd34b845",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      6\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4.1-nano\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a three sentence bedtime story about a unicorn.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\openai\\_client.py:126\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    124\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1-nano\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4ae0c",
   "metadata": {},
   "source": [
    "# YouTube metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19c85008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_video_info(url: str) -> VideoInfo:\n",
    "    yt = YouTube(url)\n",
    "    print(f\"Fetching video info for {url}...\")\n",
    "    print(f\"Title: {yt.title}\")\n",
    "    return VideoInfo(\n",
    "        video_id=yt.video_id,\n",
    "        title=yt.title or \"\",\n",
    "        channel=yt.author or \"\",\n",
    "        publish_date=yt.publish_date.isoformat() if yt.publish_date else \"\",\n",
    "        description=yt.description or \"\",\n",
    "        keywords=yt.keywords or [],\n",
    "        length_seconds=yt.length,\n",
    "        url=url,\n",
    "        \n",
    "    ), yt\n",
    "    # return yt \n",
    "\n",
    "\n",
    "def fetch_transcript(video_id: str, lang: str = \"en\") -> List[TranscriptSegment]:\n",
    "    raw = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])\n",
    "    return [TranscriptSegment(**seg) for seg in raw]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e0b6375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching video info for https://www.youtube.com/watch?v=3MqYE2UuN24...\n",
      "Title: Is it Better to Walk or Run in the Rain?\n"
     ]
    }
   ],
   "source": [
    "yt = fetch_video_info(\"https://www.youtube.com/watch?v=3MqYE2UuN24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dacfe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hayk_\\\\OneDrive\\\\Desktop\\\\python_math_ml_course\\\\python\\\\video.mp4'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt[1].streams.filter(progressive=True, file_extension=\"mp4\").order_by(\"resolution\")\\\n",
    ".desc().first().download(filename=\"video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "814fc0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hayk_\\\\OneDrive\\\\Desktop\\\\python_math_ml_course\\\\python\\\\audio.mp3'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt[1].streams.get_audio_only().download(filename=\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f378984",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = yt[1].captions[\"en\"]#.download(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf7a499b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On those cold, rainy days when you forget your rain jacket or umbrella and you want to stay as dry as possible… should you walk and spend more time in the rain? Or should you run, which means you'll be smashing into more raindrops from the side? Assuming you haven't been fully soaked yet and you aren't jumping into puddles, the answer is simple. As you move out of the way of one falling raindrop, you move into the way of another. So the amount of rain hitting the top of you is constant, regardless of how fast you're going. Alternatively, you can picture that the raindrops themselves are stationary and you (and the earth beneath you) are moving upwards through the rain! And since the volume of a parallelepiped (that's a 3D parallelogram) doesn't depend at all on its slant, then no matter how fast you're moving horizontally the same amount of rain will land on top of you each second. Now, if you're not moving, the rain from the top is all you'll get. But if you ARE moving, you'll also run into raindrops from the side and you'll get wetter. So in any given second, you stay driest by standing still, and the faster you move the wetter you become. But if you're trying to get from point A to point B, then standing still won't do you much good. And en route from point A to point B, the total amount of rain you run into from the side has nothing to do with how fast you're going - just like how a snowplow will plow the same amount of snow from a stretch of road regardless of the exact speed it drives. In the case of running through the rain, you can figure that out using parallelepipeds again. So over a given period of time, the same amount of rain will hit you from the top, regardless of how fast you're going. And over a given distance, you'll hit the same amount of rain from the side - again, regardless of how fast you're going. So your total wetness is equal to the wetness per second for rain from the top times the amount of time you spend in the rain, plus the wetness per meter for rain from the side times the number of meters you travel. So to stay driest getting from one point to another, you should try to minimize the amount of water falling onto you from above. And quite simply, that means getting out of the rain as fast as possible.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.generate_txt_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c96b6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0db7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fabb6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tr.translate(text=\"Hello, world!\", dest=\"hy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "769497bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m translator\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m안녕하세요.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)  \u001b[38;5;66;03m# <Translated src=ko dest=en text=Good evening. pronunciation=Good evening.>\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from googletrans import Translator\n",
    "\n",
    "async def translate_text():\n",
    "    async with Translator() as translator:\n",
    "        result = await translator.translate('안녕하세요.')\n",
    "        print(result)  # <Translated src=ko dest=en text=Good evening. pronunciation=Good evening.>\n",
    "\n",
    "  \n",
    "asyncio.run(translate_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c929f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    print(1)\n",
    "    \n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317139cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated(src=en, dest=hy, text=պանիր, pronunciation=panir, extra_data=\"{'translat...\")\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from googletrans import Translator\n",
    "\n",
    "# https://stackoverflow.com/questions/55409641/asyncio-run-cannot-be-called-from-a-running-event-loop-when-using-jupyter-no\n",
    "\n",
    "async def translate_text():\n",
    "    async with Translator() as translator:\n",
    "        result = await translator.translate('cheese', dest='hy')\n",
    "        print(result)  # <Translated src=ko dest=en text=Good evening. pronunciation=Good evening.>\n",
    "\n",
    "await translate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour à tous !\n"
     ]
    }
   ],
   "source": [
    "import deepl\n",
    "\n",
    "auth_key = \"\"  # Replace with your key\n",
    "deepl_client = deepl.DeepLClient(auth_key)\n",
    "\n",
    "result = deepl_client.translate_text(\"Hello, world!\", target_lang=\"FR\")\n",
    "print(result.text)  # \"Bonjour, le monde !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b24c7fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mGoogleTranslator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_txt_captions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mGoogleTranslator.translate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtranslate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_lang\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "GoogleTranslator().translate(c.generate_txt_captions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d3d62b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_js',\n",
       " '_js_url',\n",
       " '_vid_info',\n",
       " '_vid_details',\n",
       " '_watch_html',\n",
       " '_embed_html',\n",
       " '_player_config_args',\n",
       " '_age_restricted',\n",
       " '_fmt_streams',\n",
       " '_initial_data',\n",
       " '_metadata',\n",
       " 'video_id',\n",
       " 'watch_url',\n",
       " 'embed_url',\n",
       " 'client',\n",
       " 'fallback_clients',\n",
       " '_signature_timestamp',\n",
       " '_visitor_data',\n",
       " 'stream_monostate',\n",
       " '_author',\n",
       " '_title',\n",
       " '_publish_date',\n",
       " 'use_oauth',\n",
       " 'allow_oauth_cache',\n",
       " 'token_file',\n",
       " 'oauth_verifier',\n",
       " 'use_po_token',\n",
       " 'po_token_verifier',\n",
       " 'po_token',\n",
       " '_pot',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " '__repr__',\n",
       " '__eq__',\n",
       " 'watch_html',\n",
       " 'embed_html',\n",
       " 'age_restricted',\n",
       " 'js_url',\n",
       " 'js',\n",
       " 'visitor_data',\n",
       " 'pot',\n",
       " 'initial_data',\n",
       " 'streaming_data',\n",
       " 'fmt_streams',\n",
       " 'check_availability',\n",
       " 'signature_timestamp',\n",
       " 'video_playback_ustreamer_config',\n",
       " 'server_abr_streaming_url',\n",
       " 'vid_info',\n",
       " 'vid_details',\n",
       " 'age_check',\n",
       " 'caption_tracks',\n",
       " 'captions',\n",
       " 'chapters',\n",
       " 'key_moments',\n",
       " 'replayed_heatmap',\n",
       " 'streams',\n",
       " 'thumbnail_url',\n",
       " 'publish_date',\n",
       " 'title',\n",
       " 'description',\n",
       " 'rating',\n",
       " 'length',\n",
       " 'views',\n",
       " 'author',\n",
       " 'keywords',\n",
       " 'channel_id',\n",
       " 'channel_url',\n",
       " 'likes',\n",
       " 'metadata',\n",
       " 'register_on_progress_callback',\n",
       " 'register_on_complete_callback',\n",
       " 'from_id',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__hash__',\n",
       " '__new__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt[1].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_transcript(\"3MqYE2UuN24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35f96490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching video info for https://www.youtube.com/watch?v=3MqYE2UuN24...\n",
      "Title: Is it Better to Walk or Run in the Rain?\n",
      "Title: Is it Better to Walk or Run in the Rain?\n",
      "Translating with GoogleTranslator…\n",
      "Translating with GoogleTranslator…\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m example_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=3MqYE2UuN24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m TranslationPipeline(\n\u001b[0;32m     53\u001b[0m     url\u001b[38;5;241m=\u001b[39mexample_url,\n\u001b[0;32m     54\u001b[0m     translators\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     ],\n\u001b[0;32m     60\u001b[0m )\n\u001b[1;32m---> 61\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mTranslationPipeline.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslators:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslating with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     armenian_text \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(TranslationResult(engine\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, translated_text\u001b[38;5;241m=\u001b[39marmenian_text))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 3. persist\u001b[39;00m\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mGoogleTranslator.translate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtranslate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_lang\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# YouTube utilities (pytube + youtube_transcript_api)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Orchestration pipeline\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class TranslationPipeline:\n",
    "    url: str\n",
    "    translators: List[BaseTranslator] = field(default_factory=list)\n",
    "    out_dir: str = \"out\"\n",
    "\n",
    "    def run(self) -> None:\n",
    "        # 1. fetch metadata + transcript\n",
    "        info = fetch_video_info(self.url)\n",
    "        transcript_segments = fetch_transcript(info.video_id)\n",
    "        full_text = \"\\n\".join(seg.text for seg in transcript_segments)\n",
    "\n",
    "        # 2. run each translator\n",
    "        results: List[TranslationResult] = []\n",
    "        for t in self.translators:\n",
    "            print(f\"Translating with {t.__class__.__name__}…\")\n",
    "            armenian_text = t.translate(full_text)\n",
    "            results.append(TranslationResult(engine=t.__class__.__name__, translated_text=armenian_text))\n",
    "\n",
    "        # 3. persist\n",
    "        self.out_dir.mkdir(exist_ok=True)\n",
    "        out_path = self.out_dir / f\"{info.video_id}_translations.json\"\n",
    "        with out_path.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            json.dump(\n",
    "                {\n",
    "                    \"video\": asdict(info),\n",
    "                    \"translations\": [asdict(r) for r in results],\n",
    "                    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                },\n",
    "                fp,\n",
    "                ensure_ascii=False,\n",
    "                indent=2,\n",
    "            )\n",
    "        print(f\"Saved ⇒ {out_path}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Simple entry‑point (no argparse)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # example_url = input(\"YouTube URL: \").strip()\n",
    "    example_url = \"https://www.youtube.com/watch?v=3MqYE2UuN24\"\n",
    "    pipeline = TranslationPipeline(\n",
    "        url=example_url,\n",
    "        translators=[\n",
    "            GoogleTranslator(),\n",
    "            # DeepLTranslator(),\n",
    "            # OpenAITranslator(),\n",
    "            # ClaudeTranslator(),\n",
    "        ],\n",
    "    )\n",
    "    pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71374677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(os.environ)\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY env var not set\")\n",
    "response = openai.ChatCompletion.create(  # type: ignore[attr-defined]\n",
    "    model=self.model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Translate the following text to Armenian (hy) keeping formatting and line breaks where reasonable.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Cheese\"},\n",
    "    ],\n",
    "    temperature=self.temperature,\n",
    ")\n",
    "return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93036335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc3874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
