{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"10 Scraping; Parallel Processing\"\n",
    "description: \"Beautiful Soup, Joblib, Scrapy, and Selenium\"\n",
    "lightbox: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "number-offset: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "![image.png](../background_photos/libs_10_sunset.jpg)\n",
    "\n",
    "‘µ÷Ä÷á’°’∂, [’¨’∏÷Ç’Ω’°’∂’Ø’°÷Ä’´ ’∞’≤’∏÷Ç’¥’®](https://unsplash.com/photos/iDQogDbHvsc), ’Ä’•’≤’´’∂’°’Ø’ù [Armen Harutunian](https://unsplash.com/@arm98)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<a href=\"ToDo\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> (ToDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "> Song reference - ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìå ’Ü’Ø’°÷Ä’°’£’´÷Ä\n",
    "\n",
    "[üìö ‘±’¥’¢’∏’≤’ª’°’Ø’°’∂ ’∂’µ’∏÷Ç’©’®]()\n",
    "\n",
    "#### üì∫ ’è’•’Ω’°’∂’µ’∏÷Ç’©’•÷Ä\n",
    "#### üè° ’è’∂’°’µ’´’∂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìö ’Ü’µ’∏÷Ç’©’®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê HTML Basics - Understanding Web Structure\n",
    "\n",
    "Before diving into web scraping, it's essential to understand the structure of web pages. HTML (HyperText Markup Language) provides the structure of web pages.\n",
    "\n",
    "### What is HTML?\n",
    "\n",
    "HTML uses **tags** to define elements. Tags are enclosed in angle brackets `< >` and usually come in pairs:\n",
    "\n",
    "```html\n",
    "<tagname>Content goes here</tagname>\n",
    "```\n",
    "\n",
    "### Basic HTML Document Structure:\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Page Title</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Main Heading</h1>\n",
    "    <p>This is a paragraph.</p>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common HTML Tags for Scraping:\n",
    "\n",
    "#### Document Structure:\n",
    "- `<html>` - Root element\n",
    "- `<head>` - Contains metadata\n",
    "- `<title>` - Page title\n",
    "- `<body>` - Visible page content\n",
    "\n",
    "#### Text Content:\n",
    "- `<h1>`, `<h2>`, `<h3>` - Headers (most important to least)\n",
    "- `<p>` - Paragraphs\n",
    "- `<span>` - Inline text container\n",
    "\n",
    "#### Containers:\n",
    "- `<div>` - Block-level container (most common)\n",
    "- `<section>` - Semantic section\n",
    "- `<article>` - Independent content\n",
    "\n",
    "#### Lists and Links:\n",
    "- `<ul>`, `<ol>`, `<li>` - Unordered/ordered lists and list items\n",
    "- `<a>` - Links\n",
    "- `<img>` - Images\n",
    "\n",
    "#### Data Tables:\n",
    "- `<table>`, `<tr>`, `<td>`, `<th>` - Tables, rows, cells, headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Attributes - The Key to Scraping\n",
    "\n",
    "Attributes provide additional information about elements and are **crucial** for web scraping:\n",
    "\n",
    "```html\n",
    "<div id=\"content\" class=\"main-section\">\n",
    "<a href=\"https://example.com\" target=\"_blank\">Link</a>\n",
    "<img src=\"image.jpg\" alt=\"Description\">\n",
    "<div data-price=\"29.99\" data-category=\"electronics\">Product</div>\n",
    "```\n",
    "\n",
    "**Most Important Attributes for Scraping:**\n",
    "- `id` - Unique identifier (use with `#` in CSS selectors)\n",
    "- `class` - CSS class name(s) (use with `.` in CSS selectors)\n",
    "- `href` - Link destination\n",
    "- `src` - Source for images/scripts\n",
    "- `data-*` - Custom data attributes (very common in modern websites)\n",
    "\n",
    "**Why Attributes Matter:**\n",
    "- They help us target specific elements\n",
    "- They often contain valuable data\n",
    "- They make our scrapers more precise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ CSS Selectors - Your Scraping Toolkit\n",
    "\n",
    "CSS selectors are **THE MOST IMPORTANT** concept in web scraping. They tell your scraper exactly which elements to extract.\n",
    "\n",
    "### Basic Selectors:\n",
    "\n",
    "#### 1. Element Selector:\n",
    "```css\n",
    "p          /* Selects all <p> elements */\n",
    "div        /* Selects all <div> elements */\n",
    "h1         /* Selects all <h1> elements */\n",
    "```\n",
    "\n",
    "#### 2. Class Selector (starts with .):\n",
    "```css\n",
    ".classname     /* Selects elements with class=\"classname\" */\n",
    ".post-title    /* Selects elements with class=\"post-title\" */\n",
    ".btn-primary   /* Selects elements with class=\"btn-primary\" */\n",
    "```\n",
    "\n",
    "#### 3. ID Selector (starts with #):\n",
    "```css\n",
    "#idname        /* Selects element with id=\"idname\" */\n",
    "#main-content  /* Selects element with id=\"main-content\" */\n",
    "#header        /* Selects element with id=\"header\" */\n",
    "```\n",
    "\n",
    "#### 4. Attribute Selector:\n",
    "```css\n",
    "[href]                    /* Elements with href attribute */\n",
    "[class=\"post\"]           /* Elements with class=\"post\" */\n",
    "[data-price=\"29.99\"]     /* Elements with data-price=\"29.99\" */\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced CSS Selectors:\n",
    "\n",
    "#### Combination Selectors:\n",
    "```css\n",
    "div p              /* All <p> inside <div> (descendant) */\n",
    "div > p            /* Direct <p> children of <div> */\n",
    "h1 + p             /* First <p> immediately after <h1> */\n",
    ".post .title       /* Elements with class \"title\" inside elements with class \"post\" */\n",
    "```\n",
    "\n",
    "#### Multiple Classes:\n",
    "```css\n",
    ".post.featured     /* Elements with BOTH classes \"post\" AND \"featured\" */\n",
    ".btn.btn-primary   /* Elements with BOTH classes \"btn\" AND \"btn-primary\" */\n",
    "```\n",
    "\n",
    "#### Pseudo-selectors:\n",
    "```css\n",
    "p:first-child      /* First <p> element of its parent */\n",
    "p:last-child       /* Last <p> element of its parent */\n",
    "p:nth-child(2)     /* Second <p> element of its parent */\n",
    "a:contains(\"Next\") /* Links containing text \"Next\" */\n",
    "```\n",
    "\n",
    "#### Complex Examples:\n",
    "```css\n",
    "div.post-content p.highlight    /* <p> with class \"highlight\" inside <div> with class \"post-content\" */\n",
    "#main-content .sidebar a[href]  /* Links inside sidebar inside main content */\n",
    "table tr:nth-child(odd)         /* Odd rows in a table */\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ü•Ñ Beautiful Soup - Your HTML Parsing Companion\n",
    "\n",
    "Beautiful Soup is perfect for beginners and handles most scraping tasks effectively. It makes parsing HTML as easy as navigating a family tree!\n",
    "\n",
    "### Why Beautiful Soup?\n",
    "- **Easy to learn**: Intuitive syntax\n",
    "- **Powerful**: Handles messy HTML gracefully\n",
    "- **Flexible**: Multiple ways to find elements\n",
    "- **Robust**: Handles encoding issues automatically\n",
    "\n",
    "### Core Concepts:\n",
    "1. **Parsing**: Convert HTML text into a navigable object\n",
    "2. **Searching**: Find specific elements using tags, attributes, or CSS selectors\n",
    "3. **Extracting**: Get text, attributes, or sub-elements\n",
    "4. **Navigating**: Move between parent, children, and sibling elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sample HTML](scraping/sample_page.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div class=\"top-section\" id=\"header\">\n",
      "   <h1 class=\"main-title\">\n",
      "    Welcome to Our Store\n",
      "   </h1>\n",
      "   <nav class=\"navigation\">\n",
      "    <a href=\"/home\">\n",
      "     Home\n",
      "    </a>\n",
      "    <a href=\"/products\">\n",
      "     Products\n",
      "    </a>\n",
      "    <a href=\"/contact\">\n",
      "     Contact\n",
      "    </a>\n",
      "   </nav>\n",
      "  </div>\n",
      "  <div id=\"main-content\">\n",
      "   <div class=\"product featured\" data-price=\"199.99\">\n",
      "    <h2 class=\"product-title\">\n",
      "     iPhone 15\n",
      "    </h2>\n",
      "    <p class=\"description\">\n",
      "     Latest smartphone with amazing features\n",
      "    </p>\n",
      "    <span class=\"price\">\n",
      "     $199.99\n",
      "    </span>\n",
      "   </div>\n",
      "   <div class=\"product\" data-price=\"89.99\">\n",
      "    <h2 class=\"product-title\">\n",
      "     Headphones\n",
      "    </h2>\n",
      "    <p class=\"description\">\n",
      "     High-quality wireless headphones\n",
      "    </p>\n",
      "    <span class=\"price\">\n",
      "     $89.99\n",
      "    </span>\n",
      "   </div>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Sample HTML for practicing CSS selectors\n",
    "practice_html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "    <div id=\"header\" class=\"top-section\">\n",
    "        <h1 class=\"main-title\">Welcome to Our Store</h1>\n",
    "        <nav class=\"navigation\">\n",
    "            <a href=\"/home\">Home</a>\n",
    "            <a href=\"/products\">Products</a>\n",
    "            <a href=\"/contact\">Contact</a>\n",
    "        </nav>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"main-content\">\n",
    "        <div class=\"product featured\" data-price=\"199.99\">\n",
    "            <h2 class=\"product-title\">iPhone 15</h2>\n",
    "            <p class=\"description\">Latest smartphone with amazing features</p>\n",
    "            <span class=\"price\">$199.99</span>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"product\" data-price=\"89.99\">\n",
    "            <h2 class=\"product-title\">Headphones</h2>\n",
    "            <p class=\"description\">High-quality wireless headphones</p>\n",
    "            <span class=\"price\">$89.99</span>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(practice_html, 'html.parser')\n",
    "\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"product-title\">iPhone 15</h2>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('h2')\n",
    "\n",
    "soup.h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"product featured\" data-price=\"199.99\">\n",
       " <h2 class=\"product-title\">iPhone 15</h2>\n",
       " <p class=\"description\">Latest smartphone with amazing features</p>\n",
       " <span class=\"price\">$199.99</span>\n",
       " </div>,\n",
       " <div class=\"product\" data-price=\"89.99\">\n",
       " <h2 class=\"product-title\">Headphones</h2>\n",
       " <p class=\"description\">High-quality wireless headphones</p>\n",
       " <span class=\"price\">$89.99</span>\n",
       " </div>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.product') # . - class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"main-content\">\n",
       " <div class=\"product featured\" data-price=\"199.99\">\n",
       " <h2 class=\"product-title\">iPhone 15</h2>\n",
       " <p class=\"description\">Latest smartphone with amazing features</p>\n",
       " <span class=\"price\">$199.99</span>\n",
       " </div>\n",
       " <div class=\"product\" data-price=\"89.99\">\n",
       " <h2 class=\"product-title\">Headphones</h2>\n",
       " <p class=\"description\">High-quality wireless headphones</p>\n",
       " <span class=\"price\">$89.99</span>\n",
       " </div>\n",
       " </div>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('#main-content') # # - id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£ Basic Selectors:\n",
      "All h2 elements: 2 found\n",
      "Elements with class 'product': 2 found\n",
      "Element with id 'header': 1 found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Basic selectors\n",
    "print(\"\\n1Ô∏è‚É£ Basic Selectors:\")\n",
    "print(f\"All h2 elements: {len(soup.select('h2'))} found\")\n",
    "print(f\"Elements with class 'product': {len(soup.select('.product'))} found\")\n",
    "print(f\"Element with id 'header': {len(soup.select('#header'))} found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Ô∏è‚É£ Finding Specific Content:\n",
      "Welcome to Our Store\n"
     ]
    }
   ],
   "source": [
    "# 2. Find specific content\n",
    "print(\"2Ô∏è‚É£ Finding Specific Content:\")\n",
    "main_title = soup.select_one('h1.main-title')\n",
    "\n",
    "\n",
    "print(main_title.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/home\">Home</a>, <a href=\"/products\">Products</a>, <a href=\"/contact\">Contact</a>]\n",
      "Home\n",
      "/home\n",
      "Products\n",
      "/products\n",
      "Contact\n",
      "/contact\n"
     ]
    }
   ],
   "source": [
    "navigation_links = soup.select('nav.navigation a')\n",
    "print(navigation_links)\n",
    "\n",
    "for nav in navigation_links:\n",
    "    print(nav.text)\n",
    "    print(nav[\"href\"]) # hyper href attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Extract Product Information:\n",
      "[<div class=\"product featured\" data-price=\"199.99\">\n",
      "<h2 class=\"product-title\">iPhone 15</h2>\n",
      "<p class=\"description\">Latest smartphone with amazing features</p>\n",
      "<span class=\"price\">$199.99</span>\n",
      "</div>, <div class=\"product\" data-price=\"89.99\">\n",
      "<h2 class=\"product-title\">Headphones</h2>\n",
      "<p class=\"description\">High-quality wireless headphones</p>\n",
      "<span class=\"price\">$89.99</span>\n",
      "</div>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div class=\"product featured\" data-price=\"199.99\">\n",
       "<h2 class=\"product-title\">iPhone 15</h2>\n",
       "<p class=\"description\">Latest smartphone with amazing features</p>\n",
       "<span class=\"price\">$199.99</span>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Product information\n",
    "print(\"\\n3Ô∏è‚É£ Extract Product Information:\")\n",
    "products = soup.select('div.product')\n",
    "\n",
    "print(products)\n",
    "products[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "  Price: $199.99\n",
      "  Featured: ‚úÖ\n",
      "title\n",
      "  Price: $89.99\n",
      "  Featured: ‚ùå\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for product in products:\n",
    "    title = product.select_one('.product-title').text\n",
    "    price = product.select_one('.price').text\n",
    "    is_featured = 'featured' in product.get('class', [])\n",
    "    \n",
    "    print(\"title\")\n",
    "    print(f\"  Price: {price}\")\n",
    "    print(f\"  Featured: {'‚úÖ' if is_featured else '‚ùå'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Advanced Selectors:\n",
      "Featured product: iPhone 15\n",
      "Products with price data: 2\n"
     ]
    }
   ],
   "source": [
    "# 4. Advanced selectors\n",
    "print(\"\\n4Ô∏è‚É£ Advanced Selectors:\")\n",
    "featured_product = soup.select_one('.product.featured .product-title')\n",
    "if featured_product:\n",
    "    print(f\"Featured product: {featured_product.text}\")\n",
    "\n",
    "expensive_products = soup.select('[data-price]')\n",
    "print(f\"Products with price data: {len(expensive_products)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup Complete Example - Part 2: Finding Elements\n",
    "# Using the same soup object from Part 1\n",
    "\n",
    "print(\"ü•Ñ Beautiful Soup Complete Example - Part 2\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nüîç Different Ways to Find Elements:\")\n",
    "\n",
    "# Method 1: By tag name\n",
    "print(\"\\n1Ô∏è‚É£ Find by tag name:\")\n",
    "titles = soup.find_all('h2')\n",
    "print(f\"   Found {len(titles)} h2 elements:\")\n",
    "for i, title in enumerate(titles, 1):\n",
    "    print(f\"     {i}. {title.text}\")\n",
    "\n",
    "# Method 2: By class\n",
    "print(\"\\n2Ô∏è‚É£ Find by class:\")\n",
    "posts = soup.find_all('span', class_='price')\n",
    "print(f\"   Found {len(posts)} articles with class 'post'\")\n",
    "\n",
    "# Method 3: By ID\n",
    "print(\"\\n3Ô∏è‚É£ Find by ID:\")\n",
    "header = soup.find('header', id='main-header')\n",
    "if header:\n",
    "    print(f\"   Header found: {header.h1.text}\")\n",
    "\n",
    "# Method 4: By multiple attributes\n",
    "print(\"\\n4Ô∏è‚É£ Find by multiple attributes:\")\n",
    "featured_post = soup.find('article', {'class': 'post featured'})\n",
    "if featured_post:\n",
    "    print(f\"   Featured post: {featured_post.find('h2').text}\")\n",
    "\n",
    "# Method 5: By custom attributes\n",
    "print(\"\\n5Ô∏è‚É£ Find by custom attributes:\")\n",
    "post_123 = soup.find('article', {'data-id': '123'})\n",
    "if post_123:\n",
    "    author = post_123.find('span', class_='author').text\n",
    "    print(f\"   Post 123 author: {author}\")\n",
    "\n",
    "print(\"\\nüí° Key Takeaway:\")\n",
    "print(\"   find() ‚Üí First match or None\")\n",
    "print(\"   find_all() ‚Üí List of all matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåê Real Website Scraping Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required libraries for web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\">\n",
      "   <div class=\"row header-box\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <h1>\n",
      "      <a href=\"/\" style=\"text-decoration: none\">\n",
      "       Quotes to Scrape\n",
      "      </a>\n",
      "     </h1>\n",
      "    </div>\n",
      "    <div class=\"col-md-4\">\n",
      "     <p>\n",
      "      <a href=\"/login\">\n",
      "       Login\n",
      "      </a>\n",
      "     </p>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"row\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/change/page/1/\">\n",
      "        change\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">\n",
      "        deep-thoughts\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/thinking/page/1/\">\n",
      "        thinking\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/world/page/1/\">\n",
      "        world\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúIt is our choices, Harry, that show what we truly are, far more than our abilities.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        J.K. Rowling\n",
      "       </small>\n",
      "       <a href=\"/author/J-K-Rowling\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"abilities,choices\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/abilities/page/1/\">\n",
      "        abilities\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/choices/page/1/\">\n",
      "        choices\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/inspirational/page/1/\">\n",
      "        inspirational\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/life/page/1/\">\n",
      "        life\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/live/page/1/\">\n",
      "        live\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/miracle/page/1/\">\n",
      "        miracle\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/miracles/page/1/\">\n",
      "        miracles\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Jane Austen\n",
      "       </small>\n",
      "       <a href=\"/author/Jane-Austen\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"aliteracy,books,classic,humor\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">\n",
      "        aliteracy\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/books/page/1/\">\n",
      "        books\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/classic/page/1/\">\n",
      "        classic\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/humor/page/1/\">\n",
      "        humor\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Marilyn Monroe\n",
      "       </small>\n",
      "       <a href=\"/author/Marilyn-Monroe\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"be-yourself,inspirational\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">\n",
      "        be-yourself\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/inspirational/page/1/\">\n",
      "        inspirational\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúTry not to become a man of success. Rather become a man of value.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"adulthood,success,value\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/adulthood/page/1/\">\n",
      "        adulthood\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/success/page/1/\">\n",
      "        success\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/value/page/1/\">\n",
      "        value\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúIt is better to be hated for what you are than to be loved for what you are not.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Andr√© Gide\n",
      "       </small>\n",
      "       <a href=\"/author/Andre-Gide\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"life,love\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/life/page/1/\">\n",
      "        life\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/love/page/1/\">\n",
      "        love\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúI have not failed. I've just found 10,000 ways that won't work.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Thomas A. Edison\n",
      "       </small>\n",
      "       <a href=\"/author/Thomas-A-Edison\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/edison/page/1/\">\n",
      "        edison\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/failure/page/1/\">\n",
      "        failure\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/inspirational/page/1/\">\n",
      "        inspirational\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">\n",
      "        paraphrased\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúA woman is like a tea bag; you never know how strong it is until it's in hot water.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Eleanor Roosevelt\n",
      "       </small>\n",
      "       <a href=\"/author/Eleanor-Roosevelt\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"misattributed-eleanor-roosevelt\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">\n",
      "        misattributed-eleanor-roosevelt\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       ‚ÄúA day without sunshine is like, you know, night.‚Äù\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Steve Martin\n",
      "       </small>\n",
      "       <a href=\"/author/Steve-Martin\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"humor,obvious,simile\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/humor/page/1/\">\n",
      "        humor\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/obvious/page/1/\">\n",
      "        obvious\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/simile/page/1/\">\n",
      "        simile\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <nav>\n",
      "      <ul class=\"pager\">\n",
      "       <li class=\"next\">\n",
      "        <a href=\"/page/2/\">\n",
      "         Next\n",
      "         <span aria-hidden=\"true\">\n",
      "          ‚Üí\n",
      "         </span>\n",
      "        </a>\n",
      "       </li>\n",
      "      </ul>\n",
      "     </nav>\n",
      "    </div>\n",
      "    <div class=\"col-md-4 tags-box\">\n",
      "     <h2>\n",
      "      Top Ten tags\n",
      "     </h2>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/love/\" style=\"font-size: 28px\">\n",
      "       love\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/inspirational/\" style=\"font-size: 26px\">\n",
      "       inspirational\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/life/\" style=\"font-size: 26px\">\n",
      "       life\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/humor/\" style=\"font-size: 24px\">\n",
      "       humor\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/books/\" style=\"font-size: 22px\">\n",
      "       books\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/reading/\" style=\"font-size: 14px\">\n",
      "       reading\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/friendship/\" style=\"font-size: 10px\">\n",
      "       friendship\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/friends/\" style=\"font-size: 8px\">\n",
      "       friends\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/truth/\" style=\"font-size: 8px\">\n",
      "       truth\n",
      "      </a>\n",
      "     </span>\n",
      "     <span class=\"tag-item\">\n",
      "      <a class=\"tag\" href=\"/tag/simile/\" style=\"font-size: 6px\">\n",
      "       simile\n",
      "      </a>\n",
      "     </span>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      "  <footer class=\"footer\">\n",
      "   <div class=\"container\">\n",
      "    <p class=\"text-muted\">\n",
      "     Quotes by:\n",
      "     <a href=\"https://www.goodreads.com/quotes\">\n",
      "      GoodReads.com\n",
      "     </a>\n",
      "    </p>\n",
      "    <p class=\"copyright\">\n",
      "     Made with\n",
      "     <span class=\"zyte\">\n",
      "      ‚ù§\n",
      "     </span>\n",
      "     by\n",
      "     <a class=\"zyte\" href=\"https://www.zyte.com\">\n",
      "      Zyte\n",
      "     </a>\n",
      "    </p>\n",
      "   </div>\n",
      "  </footer>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"http://quotes.toscrape.com/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise exception for bad status codes\n",
    "\n",
    "print(response.status_code)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>\n",
       " <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
       " </h1>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"h1 a\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = soup.find_all(\"div\", class_=\"quote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       " <a href=\"/author/Albert-Einstein\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
       " <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
       " <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
       " <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúIt is our choices, Harry, that show what we truly are, far more than our abilities.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n",
       " <a href=\"/author/J-K-Rowling\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"abilities,choices\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n",
       " <a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       " <a href=\"/author/Albert-Einstein\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
       " <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n",
       " <a class=\"tag\" href=\"/tag/live/page/1/\">live</a>\n",
       " <a class=\"tag\" href=\"/tag/miracle/page/1/\">miracle</a>\n",
       " <a class=\"tag\" href=\"/tag/miracles/page/1/\">miracles</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Jane Austen</small>\n",
       " <a href=\"/author/Jane-Austen\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"aliteracy,books,classic,humor\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">aliteracy</a>\n",
       " <a class=\"tag\" href=\"/tag/books/page/1/\">books</a>\n",
       " <a class=\"tag\" href=\"/tag/classic/page/1/\">classic</a>\n",
       " <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Marilyn Monroe</small>\n",
       " <a href=\"/author/Marilyn-Monroe\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"be-yourself,inspirational\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">be-yourself</a>\n",
       " <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúTry not to become a man of success. Rather become a man of value.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       " <a href=\"/author/Albert-Einstein\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"adulthood,success,value\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/adulthood/page/1/\">adulthood</a>\n",
       " <a class=\"tag\" href=\"/tag/success/page/1/\">success</a>\n",
       " <a class=\"tag\" href=\"/tag/value/page/1/\">value</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúIt is better to be hated for what you are than to be loved for what you are not.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Andr√© Gide</small>\n",
       " <a href=\"/author/Andre-Gide\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"life,love\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n",
       " <a class=\"tag\" href=\"/tag/love/page/1/\">love</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúI have not failed. I've just found 10,000 ways that won't work.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Thomas A. Edison</small>\n",
       " <a href=\"/author/Thomas-A-Edison\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/edison/page/1/\">edison</a>\n",
       " <a class=\"tag\" href=\"/tag/failure/page/1/\">failure</a>\n",
       " <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
       " <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">paraphrased</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúA woman is like a tea bag; you never know how strong it is until it's in hot water.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Eleanor Roosevelt</small>\n",
       " <a href=\"/author/Eleanor-Roosevelt\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"misattributed-eleanor-roosevelt\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">misattributed-eleanor-roosevelt</a>\n",
       " </div>\n",
       " </div>,\n",
       " <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       " <span class=\"text\" itemprop=\"text\">‚ÄúA day without sunshine is like, you know, night.‚Äù</span>\n",
       " <span>by <small class=\"author\" itemprop=\"author\">Steve Martin</small>\n",
       " <a href=\"/author/Steve-Martin\">(about)</a>\n",
       " </span>\n",
       " <div class=\"tags\">\n",
       "             Tags:\n",
       "             <meta class=\"keywords\" content=\"humor,obvious,simile\" itemprop=\"keywords\"/>\n",
       " <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n",
       " <a class=\"tag\" href=\"/tag/obvious/page/1/\">obvious</a>\n",
       " <a class=\"tag\" href=\"/tag/simile/page/1/\">simile</a>\n",
       " </div>\n",
       " </div>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div.quote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote in quotes:\n",
    "    text = quote.select_one(\".text\").text\n",
    "    author = quote.select_one(\".author\").text\n",
    "    tags = [tag.text for tag in quote.select(\".tag\")]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep-thoughts'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "quotes[0].select(\".tag\")[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Page {i + 1}\")\n",
    "    url = f\"https://quotes.toscrape.com/page/{i}/\"\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise exception for bad status codes\n",
    "\n",
    "# or find next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(url):\n",
    "    print(\"processing\", url)\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    quotes = soup.select(\"div.quote\")\n",
    "    for quote in quotes:\n",
    "        text = quote.select_one(\".text\").text\n",
    "        author = quote.select_one(\".author\").text\n",
    "        tags = [tag.text for tag in quote.select(\".tag\")]\n",
    "        # print(f\"Text: {text}, Author: {author}, Tags: {tags}\")\n",
    "        break\n",
    "    \n",
    "    next_page = soup.select_one(\".next a\")[\"href\"]\n",
    "    next_url = f\"https://quotes.toscrape.com{next_page}\"\n",
    "    \n",
    "    process_page(next_url)\n",
    "\n",
    "process_page(\"https://quotes.toscrape.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToDo  \n",
    "\n",
    "1. Advanced Parsing\n",
    "2. pip install \n",
    "3. robots.txt # file:///C:/Users/hayk_/Downloads/sitemap-1.xml/sitemap-1.xml \n",
    "4. waiting\n",
    "5. joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Advanced Beautiful Soup Techniques\n",
    "\n",
    "#### 1. Different Parsing Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Advanced Beautiful Soup Techniques:\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Finding by attributes:\n",
      "   Laptop: $599.99\n"
     ]
    }
   ],
   "source": [
    "# Advanced Beautiful Soup techniques\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "sample_html = \"\"\"\n",
    "<div class=\"container\">\n",
    "    <div class=\"product\" data-price=\"29.99\" data-category=\"electronics\">\n",
    "        <h3>Smartphone</h3>\n",
    "        <p class=\"description\">Latest smartphone with amazing features</p>\n",
    "        <span class=\"price\">$29.99</span>\n",
    "        <div class=\"reviews\">\n",
    "            <span class=\"rating\">4.5</span>\n",
    "            <span class=\"review-count\">(150 reviews)</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"product\" data-price=\"599.99\" data-category=\"electronics\">\n",
    "        <h3>Laptop</h3>\n",
    "        <p class=\"description\">High-performance laptop for professionals</p>\n",
    "        <span class=\"price\">$599.99</span>\n",
    "        <div class=\"reviews\">\n",
    "            <span class=\"rating\">4.8</span>\n",
    "            <span class=\"review-count\">(89 reviews)</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <article class=\"blog-post\">\n",
    "        <h2>Tech News</h2>\n",
    "        <p>Latest technology trends and updates...</p>\n",
    "        <time datetime=\"2025-01-15\">January 15, 2025</time>\n",
    "    </article>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(sample_html, 'html.parser')\n",
    "\n",
    "print(\"üîß Advanced Beautiful Soup Techniques:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Find with attributes\n",
    "print(\"\\n1Ô∏è‚É£ Finding by attributes:\")\n",
    "expensive_products = soup.find_all('div', {'data-price': lambda x: x and float(x) > 100})\n",
    "\n",
    "for product in expensive_products:\n",
    "    name = product.h3.text\n",
    "    price = product.get('data-price')\n",
    "    print(f\"   {name}: ${price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Using regex patterns:\n",
      "   Found price: $29.99\n",
      "   Found price: $599.99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Using regular expressions\n",
    "print(\"\\n2Ô∏è‚É£ Using regex patterns:\")\n",
    "price_spans = soup.find_all('span', string=re.compile(r'\\$\\d+\\.\\d+'))\n",
    "# r'\\$\\d+\\.\\d+' - this regex matches dollar amounts like $29.99\n",
    "for span in price_spans:\n",
    "    print(f\"   Found price: {span.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Advanced CSS selectors:\n",
      "   High-rated: Laptop (4.8‚≠ê)\n"
     ]
    }
   ],
   "source": [
    "# 3. CSS selectors advanced\n",
    "print(\"\\n3Ô∏è‚É£ Advanced CSS selectors:\")\n",
    "# Products with rating above 4.6\n",
    "high_rated = soup.select('div.product:has(.rating)')\n",
    "for product in high_rated:\n",
    "    name = product.h3.text\n",
    "    rating = product.select_one('.rating').text\n",
    "    if float(rating) > 4.6:\n",
    "        print(f\"   High-rated: {name} ({rating}‚≠ê)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Navigation between elements:\n",
      "   Parent element: div with class '['reviews']'\n",
      "   Review count: (150 reviews)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 4. Parent and sibling navigation\n",
    "print(\"\\n4Ô∏è‚É£ Navigation between elements:\")\n",
    "rating_element = soup.find('span', class_='rating')\n",
    "if rating_element:\n",
    "    # Get parent\n",
    "    reviews_div = rating_element.parent\n",
    "    print(f\"   Parent element: {reviews_div.name} with class '{reviews_div.get('class', [])}'\")\n",
    "    \n",
    "    # Get sibling\n",
    "    review_count = rating_element.find_next_sibling('span')\n",
    "    print(f\"   Review count: {review_count.text}\")\n",
    "    \n",
    "    print(review_count.find_next_sibling('span'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöó Selenium - For Dynamic and JavaScript-Heavy Websites\n",
    "\n",
    "### ü§î When Do You Need Selenium?\n",
    "\n",
    "**Beautiful Soup + Requests** works great for static HTML, but many modern websites use JavaScript to load content dynamically. This is where Selenium comes in.\n",
    "\n",
    "#### Signs You Need Selenium:\n",
    "- Content loads after the page loads (AJAX)\n",
    "- You need to click buttons or fill forms\n",
    "- The data you want appears only after user interaction\n",
    "- The website is a Single Page Application (SPA)\n",
    "- You see \"Loading...\" messages or spinners\n",
    "\n",
    "#### What Selenium Does:\n",
    "- **Controls a real browser** (Chrome, Firefox, Safari)\n",
    "- **Executes JavaScript** like a human user\n",
    "- **Waits for content** to load dynamically\n",
    "- **Simulates user actions** (clicks, typing, scrolling)\n",
    "\n",
    "### ‚ö° Selenium vs Beautiful Soup Comparison:\n",
    "\n",
    "| Feature | Beautiful Soup | Selenium |\n",
    "|---------|----------------|----------|\n",
    "| **Speed** | ‚ö° Very fast | üêå Slower (launches browser) |\n",
    "| **JavaScript** | ‚ùå No support | ‚úÖ Full support |\n",
    "| **User Interaction** | ‚ùå Cannot click/type | ‚úÖ Can simulate user actions |\n",
    "| **Memory Usage** | üíö Low | üî¥ High (browser overhead) |\n",
    "| **Complexity** | üíö Simple | üü° More complex setup |\n",
    "| **Best For** | Static websites | Dynamic/interactive websites |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Selenium Installation & Setup\n",
    "\n",
    "#### Step 1: Install Selenium\n",
    "```bash\n",
    "pip install selenium webdriver-manager\n",
    "```\n",
    "\n",
    "#### Step 2: Understanding WebDrivers\n",
    "Selenium needs a **WebDriver** to control browsers:\n",
    "- **ChromeDriver** - For Google Chrome\n",
    "- **GeckoDriver** - For Firefox  \n",
    "- **EdgeDriver** - For Microsoft Edge\n",
    "\n",
    "**Good News**: `webdriver-manager` automatically downloads the correct driver!\n",
    "\n",
    "#### Step 3: Basic Setup Options\n",
    "\n",
    "```python\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Option 1: Visible browser (for development/debugging)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Option 2: Headless browser (for production)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "```\n",
    "\n",
    "#### Step 4: Common Chrome Options\n",
    "```python\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")          # Run without GUI\n",
    "options.add_argument(\"--no-sandbox\")        # Required for some environments\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "options.add_argument(\"--window-size=1920,1080\")  # Set window size\n",
    "options.add_argument(\"--user-agent=Custom User Agent\")  # Custom user agent\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Selenium and WebDriver\n",
    "!pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium Basic Example - Part 1: Setup and Navigation\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def selenium_basic_demo():\n",
    "    \"\"\"Demonstrate Selenium basic usage\"\"\"\n",
    "    \n",
    "    print(\"üöó Selenium Basic Demo - Part 1: Setup\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Setup Chrome options for demo\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run without GUI for demo\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nüìã Step 1: Initialize WebDriver\")\n",
    "        # This automatically downloads ChromeDriver if needed\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        print(\"   ‚úÖ Chrome WebDriver initialized successfully\")\n",
    "        \n",
    "        print(\"\\nüåê Step 2: Navigate to website\")\n",
    "        url = \"https://quotes.toscrape.com/js/\"  # JavaScript version\n",
    "        driver.get(url)\n",
    "        print(f\"   üìç Navigated to: {url}\")\n",
    "        print(f\"   üìÑ Page title: {driver.title}\")\n",
    "        \n",
    "        print(\"\\n‚è≥ Step 3: Wait for content to load\")\n",
    "        # Wait up to 10 seconds for quotes to appear\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        quotes = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"quote\")))\n",
    "        print(f\"   ‚úÖ Found {len(quotes)} quotes after waiting for JavaScript\")\n",
    "        \n",
    "        print(f\"\\nüìä Page Information:\")\n",
    "        print(f\"   Current URL: {driver.current_url}\")\n",
    "        print(f\"   Page source length: {len(driver.page_source):,} characters\")\n",
    "        \n",
    "        return driver, quotes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Selenium demo: {e}\")\n",
    "        return None, []\n",
    "\n",
    "# Note: This demo shows setup - actual scraping in next cell\n",
    "print(\"\udca1 Note: This example shows Selenium setup and navigation.\")\n",
    "print(\"\udd04 For full functionality, Chrome browser and ChromeDriver are required.\")\n",
    "print(\"\udcdd In Colab/Jupyter environments, additional setup might be needed.\")\n",
    "\n",
    "# Uncomment the line below to run the demo (if Chrome is available)\n",
    "# driver, quotes = selenium_basic_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium Basic Example - Part 2: Data Extraction and Interaction\n",
    "# This continues from Part 1\n",
    "\n",
    "def selenium_scraping_demo():\n",
    "    \"\"\"Demonstrate Selenium data extraction and interaction\"\"\"\n",
    "    \n",
    "    print(\"üöó Selenium Basic Demo - Part 2: Data Extraction\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüìù Common Selenium Element Location Methods:\")\n",
    "    print(\"   By.CLASS_NAME    ‚Üí find_element(By.CLASS_NAME, 'quote')\")\n",
    "    print(\"   By.ID            ‚Üí find_element(By.ID, 'main-content')\")\n",
    "    print(\"   By.TAG_NAME      ‚Üí find_element(By.TAG_NAME, 'h1')\")\n",
    "    print(\"   By.CSS_SELECTOR  ‚Üí find_element(By.CSS_SELECTOR, '.quote .text')\")\n",
    "    print(\"   By.XPATH         ‚Üí find_element(By.XPATH, '//div[@class=\\\"quote\\\"]')\")\n",
    "    \n",
    "    # Simulated data extraction (would work with real driver)\n",
    "    simulated_quotes = [\n",
    "        {\n",
    "            'text': '\"The world as we have created it is a process of our thinking.\"',\n",
    "            'author': 'Albert Einstein',\n",
    "            'tags': ['change', 'deep-thoughts', 'thinking', 'world']\n",
    "        },\n",
    "        {\n",
    "            'text': '\"It is our choices, Harry, that show what we truly are.\"',\n",
    "            'author': 'J.K. Rowling',\n",
    "            'tags': ['abilities', 'choices']\n",
    "        },\n",
    "        {\n",
    "            'text': '\"There are only two ways to live your life.\"',\n",
    "            'author': 'Albert Einstein',\n",
    "            'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüîç Extracting Data with Selenium:\")\n",
    "    print(\"   (Simulated - shows the process)\")\n",
    "    \n",
    "    for i, quote_data in enumerate(simulated_quotes, 1):\n",
    "        print(f\"\\nüí¨ Quote {i}:\")\n",
    "        print(f\"   Text: {quote_data['text']}\")\n",
    "        print(f\"   Author: {quote_data['author']}\")\n",
    "        print(f\"   Tags: {', '.join(quote_data['tags'])}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Real Selenium Code Pattern:\")\n",
    "    selenium_code = '''\n",
    "# Real Selenium extraction code:\n",
    "quotes = driver.find_elements(By.CLASS_NAME, \"quote\")\n",
    "\n",
    "for quote in quotes:\n",
    "    text = quote.find_element(By.CLASS_NAME, \"text\").text\n",
    "    author = quote.find_element(By.CLASS_NAME, \"author\").text\n",
    "    tags = [tag.text for tag in quote.find_elements(By.CLASS_NAME, \"tag\")]\n",
    "    \n",
    "    quote_data = {\n",
    "        'text': text,\n",
    "        'author': author,\n",
    "        'tags': tags\n",
    "    }\n",
    "'''\n",
    "    \n",
    "    print(selenium_code)\n",
    "    \n",
    "    print(f\"\\nüñ±Ô∏è Selenium Interaction Examples:\")\n",
    "    interaction_code = '''\n",
    "# Click elements\n",
    "button = driver.find_element(By.ID, \"load-more-btn\")\n",
    "button.click()\n",
    "\n",
    "# Fill forms\n",
    "search_box = driver.find_element(By.NAME, \"search\")\n",
    "search_box.send_keys(\"python\")\n",
    "search_box.submit()\n",
    "\n",
    "# Scroll page\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "# Wait for specific conditions\n",
    "wait = WebDriverWait(driver, 10)\n",
    "element = wait.until(EC.element_to_be_clickable((By.ID, \"submit-btn\")))\n",
    "'''\n",
    "    \n",
    "    print(interaction_code)\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Important Selenium Concepts:\")\n",
    "    print(\"   üïê Explicit Waits: Wait for specific conditions\")\n",
    "    print(\"   üïë Implicit Waits: Global wait time for all elements\")\n",
    "    print(\"   üé≠ Headless Mode: Run without visible browser\")\n",
    "    print(\"   üîí Always Close: driver.quit() to free resources\")\n",
    "\n",
    "# Run the demo\n",
    "selenium_scraping_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Parallel Web Scraping & Multiprocessing\n",
    "\n",
    "When scraping large amounts of data, performance becomes crucial. Python's multiprocessing and libraries like `joblib` allow us to speed up scraping by processing multiple URLs simultaneously.\n",
    "\n",
    "## üß† Why Use Parallel Processing?\n",
    "\n",
    "**Sequential Processing:**\n",
    "- Scrapes one URL at a time\n",
    "- Total time = (number of URLs) √ó (average time per URL)\n",
    "- CPU cores remain underutilized\n",
    "\n",
    "**Parallel Processing:**\n",
    "- Scrapes multiple URLs simultaneously\n",
    "- Total time ‚âà (number of URLs) √∑ (number of workers) √ó (average time per URL)\n",
    "- Better resource utilization\n",
    "\n",
    "‚ö†Ô∏è **Important**: Always respect websites' rate limits and robots.txt when using parallel processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Basic Multiprocessing Concepts\n",
    "\n",
    "Before applying multiprocessing to web scraping, let's understand the basics with simple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Introduction to Joblib\n",
    "\n",
    "`joblib` is a powerful library that makes parallel computing easy and efficient. It's particularly great for:\n",
    "- CPU-bound tasks\n",
    "- Machine learning workloads\n",
    "- Data processing pipelines\n",
    "\n",
    "**Key advantages:**\n",
    "- Simple API: `Parallel(n_jobs=-1)(delayed(function)(args) for args in data)`\n",
    "- Automatic memory optimization\n",
    "- Built-in progress tracking\n",
    "- Works well with NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install joblib if not already installed\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def process_data(x):\n",
    "    \"\"\"Simulate data processing\"\"\"\n",
    "    time.sleep(1)\n",
    "    return x ** 3 + 2 * x ** 2 + x + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üêå Sequential Processing:\n"
     ]
    }
   ],
   "source": [
    "data = list(range(1, 51)) \n",
    "\n",
    "print(\"\\nüêå Sequential Processing:\")\n",
    "start_time = time.time()\n",
    "sequential_results = [process_data(x) for x in data]\n",
    "sequential_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time taken: 3.12 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Time taken: {sequential_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Joblib Parallel (all cores):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    7.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Parallel(n_jobs=-1)(delayed(process_data)(x) for x in data)\n",
    "print(\"\\n‚ö° Joblib Parallel (all cores):\") # -1 -> All\n",
    "start_time = time.time()\n",
    "parallel_results = Parallel(n_jobs=-1, verbose=1)(delayed(process_data)(x) for x in data)\n",
    "parallel_time = time.time() - start_time\n",
    "\n",
    "\n",
    "Parallel(n_jobs=-1, verbose=1)(delayed(process_data)(x) for x in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Joblib Parallel (all cores):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  50 out of  50 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  50 out of  50 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 19,\n",
       " 49,\n",
       " 101,\n",
       " 181,\n",
       " 295,\n",
       " 449,\n",
       " 649,\n",
       " 901,\n",
       " 1211,\n",
       " 1585,\n",
       " 2029,\n",
       " 2549,\n",
       " 3151,\n",
       " 3841,\n",
       " 4625,\n",
       " 5509,\n",
       " 6499,\n",
       " 7601,\n",
       " 8821,\n",
       " 10165,\n",
       " 11639,\n",
       " 13249,\n",
       " 15001,\n",
       " 16901,\n",
       " 18955,\n",
       " 21169,\n",
       " 23549,\n",
       " 26101,\n",
       " 28831,\n",
       " 31745,\n",
       " 34849,\n",
       " 38149,\n",
       " 41651,\n",
       " 45361,\n",
       " 49285,\n",
       " 53429,\n",
       " 57799,\n",
       " 62401,\n",
       " 67241,\n",
       " 72325,\n",
       " 77659,\n",
       " 83249,\n",
       " 89101,\n",
       " 95221,\n",
       " 101615,\n",
       " 108289,\n",
       " 115249,\n",
       " 122501,\n",
       " 130051]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallel(n_jobs=-1)(delayed(process_data)(x) for x in data)\n",
    "print(\"\\n‚ö° Joblib Parallel (all cores):\") # -1 -> All\n",
    "start_time = time.time()\n",
    "parallel_results = Parallel(n_jobs=3, verbose=-1)(delayed(process_data)(x) for x in data)\n",
    "parallel_time = time.time() - start_time\n",
    "\n",
    "\n",
    "Parallel(n_jobs=-1, verbose=1)(delayed(process_data)(x) for x in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time taken: 0.50 seconds\n",
      "   Speedup: 6.21x faster\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Time taken: {parallel_time:.2f} seconds\")\n",
    "print(f\"   Speedup: {sequential_time/parallel_time:.2f}x faster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Joblib with Progress Tracking:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time taken: 1.48 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä Joblib with Progress Tracking:\")\n",
    "start_time = time.time()\n",
    "parallel_results_verbose = Parallel(n_jobs=4, verbose=1)(\n",
    "    delayed(process_data)(x) for x in data\n",
    ")\n",
    "verbose_time = time.time() - start_time\n",
    "print(f\"   Time taken: {verbose_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Parallel Web Scraping Examples\n",
    "\n",
    "Now let's apply these concepts to web scraping. We'll compare sequential vs parallel approaches for scraping multiple URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è Advanced Parallel Scraping with Rate Limiting\n",
    "\n",
    "When scraping real websites, we need to be more careful about rate limiting, error handling, and respecting server resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.ysu.am/robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance Optimization & Best Practices\n",
    "\n",
    "### üéØ Choosing the Right Approach\n",
    "\n",
    "| Method | Best For | Pros | Cons |\n",
    "|--------|----------|------|------|\n",
    "| **Sequential** | Small datasets, strict rate limits | Simple, predictable | Slow for large datasets |\n",
    "| **Threading** | I/O-bound tasks, many small requests | Good for network-bound tasks | GIL limitations in Python |\n",
    "| **Multiprocessing** | CPU-intensive parsing | True parallelism | Higher memory usage |\n",
    "| **Joblib** | Balanced approach, data science tasks | Easy to use, optimized | Extra dependency |\n",
    "\n",
    "### üõ°Ô∏è Rate Limiting Strategies\n",
    "\n",
    "```python\n",
    "# 1. Fixed delay between requests\n",
    "time.sleep(1)\n",
    "\n",
    "# 2. Random delay (more human-like)\n",
    "time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "# 3. Exponential backoff on errors\n",
    "wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "\n",
    "# 4. Domain-specific rate limiting\n",
    "# Different limits for different websites\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üï∏Ô∏è Scrapy Framework - Industrial-Strength Web Scraping\n",
    "\n",
    "Scrapy is not just a library - it's a **complete framework** for building web scrapers. Think of it as the difference between a hammer (Beautiful Soup) and a complete construction toolkit (Scrapy).\n",
    "\n",
    "### ü§î When to Choose Scrapy vs Beautiful Soup?\n",
    "\n",
    "| Use Case | Beautiful Soup | Scrapy |\n",
    "|----------|----------------|---------|\n",
    "| **Simple, one-time scraping** | ‚úÖ Perfect | ‚ùå Overkill |\n",
    "| **Large-scale projects** | ‚ùå Limited | ‚úÖ Excellent |\n",
    "| **Multiple websites** | ‚ùå Manual work | ‚úÖ Built-in support |\n",
    "| **Following links automatically** | ‚ùå Manual coding | ‚úÖ Built-in |\n",
    "| **Data export (CSV, JSON)** | ‚ùå Manual coding | ‚úÖ Built-in |\n",
    "| **Handling cookies/sessions** | ‚ùå Manual coding | ‚úÖ Automatic |\n",
    "| **Concurrent requests** | ‚ùå Manual threading | ‚úÖ Built-in |\n",
    "| **Respecting robots.txt** | ‚ùå Manual checking | ‚úÖ Automatic |\n",
    "\n",
    "### üèóÔ∏è Scrapy Architecture\n",
    "\n",
    "Scrapy follows a **component-based architecture**:\n",
    "\n",
    "1. **Engine** - Controls data flow between components\n",
    "2. **Scheduler** - Manages which URLs to scrape next\n",
    "3. **Downloader** - Fetches web pages\n",
    "4. **Spiders** - Your custom logic for extracting data\n",
    "5. **Item Pipeline** - Processes extracted data\n",
    "6. **Middlewares** - Hooks for customizing requests/responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Getting Started with Scrapy\n",
    "\n",
    "#### Installation:\n",
    "```bash\n",
    "pip install scrapy\n",
    "```\n",
    "\n",
    "#### Creating a Scrapy Project:\n",
    "```bash\n",
    "# Create new project\n",
    "scrapy startproject myproject\n",
    "\n",
    "# Project structure created:\n",
    "myproject/\n",
    "    scrapy.cfg            # deploy configuration file\n",
    "    myproject/            # project's Python module\n",
    "        __init__.py\n",
    "        items.py          # project items definition file\n",
    "        middlewares.py    # project middlewares file\n",
    "        pipelines.py      # project pipelines file\n",
    "        settings.py       # project settings file\n",
    "        spiders/          # directory for spiders\n",
    "            __init__.py\n",
    "```\n",
    "\n",
    "#### Key Files Explained:\n",
    "- **spiders/** - Where you write your scraping logic\n",
    "- **items.py** - Define what data you want to extract\n",
    "- **pipelines.py** - Process the extracted data\n",
    "- **settings.py** - Configure how Scrapy behaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üï∑Ô∏è Understanding Scrapy Spiders\n",
    "\n",
    "A **Spider** is a class that defines how to scrape a website. Every spider must:\n",
    "1. **Have a unique name**\n",
    "2. **Define starting URLs**\n",
    "3. **Implement a parse method**\n",
    "\n",
    "#### Basic Spider Structure:\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'quotes'                    # Unique identifier\n",
    "    allowed_domains = ['quotes.toscrape.com']  # Optional: restrict domains\n",
    "    start_urls = ['http://quotes.toscrape.com/']  # Starting URLs\n",
    "    \n",
    "    def parse(self, response):\n",
    "        # This method is called for each start_url\n",
    "        # Extract data and/or follow links\n",
    "        pass\n",
    "```\n",
    "\n",
    "#### The `response` Object:\n",
    "- `response.css()` - Use CSS selectors\n",
    "- `response.xpath()` - Use XPath selectors  \n",
    "- `response.url` - Current URL\n",
    "- `response.status` - HTTP status code\n",
    "- `response.follow()` - Follow links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï∑Ô∏è Scrapy Spider Analysis:\n",
      "===================================\n",
      "\n",
      "1Ô∏è‚É£ Spider Attributes:\n",
      "   Name: quotes\n",
      "   Allowed domains: ['quotes.toscrape.com']\n",
      "   Starting URLs: ['http://quotes.toscrape.com/']\n",
      "\n",
      "2Ô∏è‚É£ How Scrapy Works:\n",
      "   Step 1: Scrapy sends requests to start_urls\n",
      "   Step 2: Calls parse() method with each response\n",
      "   Step 3: Spider yields data items and/or new requests\n",
      "   Step 4: Scrapy schedules new requests and processes items\n",
      "   Step 5: Repeats until no more requests\n",
      "\n",
      "3Ô∏è‚É£ Key Scrapy Concepts:\n",
      "   üì• yield items ‚Üí Data extraction\n",
      "   üì§ yield requests ‚Üí Following links\n",
      "   üîÑ response.follow() ‚Üí Automatic link following\n",
      "   üéØ CSS/XPath selectors ‚Üí Element selection\n",
      "\n",
      "4Ô∏è‚É£ Scrapy Selectors:\n",
      "   .get() ‚Üí Get first match (like select_one)\n",
      "   .getall() ‚Üí Get all matches (like select)\n",
      "   ::text ‚Üí Extract text content\n",
      "   ::attr(name) ‚Üí Extract attribute value\n",
      "\n",
      "5Ô∏è‚É£ Running the Spider:\n",
      "   Command: scrapy crawl quotes -o quotes.json\n",
      "   Output: Saves all extracted data to quotes.json\n",
      "   Automatically: Handles requests, follows links, exports data\n"
     ]
    }
   ],
   "source": [
    "# Complete Scrapy Spider Example (Simulated)\n",
    "# Note: This is how a Scrapy spider looks - normally it runs in Scrapy framework\n",
    "\n",
    "class QuotesSpider:\n",
    "    \"\"\"\n",
    "    Example Scrapy Spider for quotes.toscrape.com\n",
    "    This shows the structure and logic of a real Scrapy spider\n",
    "    \"\"\"\n",
    "    \n",
    "    name = 'quotes'\n",
    "    allowed_domains = ['quotes.toscrape.com']\n",
    "    start_urls = ['http://quotes.toscrape.com/']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \"\"\"\n",
    "        Main parsing method - called for each response\n",
    "        \n",
    "        Args:\n",
    "            response: Scrapy response object with methods:\n",
    "                - response.css('selector') - CSS selectors\n",
    "                - response.xpath('xpath') - XPath selectors  \n",
    "                - response.follow(link) - Follow links\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract all quotes on the current page\n",
    "        quotes = response.css('div.quote')\n",
    "        \n",
    "        for quote in quotes:\n",
    "            # Extract individual fields using CSS selectors\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('small.author::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall(),\n",
    "            }\n",
    "        \n",
    "        # Follow the \"Next\" page link automatically\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            # This tells Scrapy to follow the link and call parse() again\n",
    "            yield response.follow(next_page, self.parse)\n",
    "\n",
    "# Let's simulate what Scrapy does behind the scenes\n",
    "print(\"üï∑Ô∏è Scrapy Spider Analysis:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Spider Attributes:\")\n",
    "spider = QuotesSpider()\n",
    "print(f\"   Name: {spider.name}\")\n",
    "print(f\"   Allowed domains: {spider.allowed_domains}\")\n",
    "print(f\"   Starting URLs: {spider.start_urls}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ How Scrapy Works:\")\n",
    "print(\"   Step 1: Scrapy sends requests to start_urls\")\n",
    "print(\"   Step 2: Calls parse() method with each response\")\n",
    "print(\"   Step 3: Spider yields data items and/or new requests\")\n",
    "print(\"   Step 4: Scrapy schedules new requests and processes items\")\n",
    "print(\"   Step 5: Repeats until no more requests\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Key Scrapy Concepts:\")\n",
    "print(\"   üì• yield items ‚Üí Data extraction\")\n",
    "print(\"   üì§ yield requests ‚Üí Following links\")\n",
    "print(\"   üîÑ response.follow() ‚Üí Automatic link following\")\n",
    "print(\"   üéØ CSS/XPath selectors ‚Üí Element selection\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Scrapy Selectors:\")\n",
    "print(\"   .get() ‚Üí Get first match (like select_one)\")\n",
    "print(\"   .getall() ‚Üí Get all matches (like select)\")\n",
    "print(\"   ::text ‚Üí Extract text content\")\n",
    "print(\"   ::attr(name) ‚Üí Extract attribute value\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ Running the Spider:\")\n",
    "print(\"   Command: scrapy crawl quotes -o quotes.json\")\n",
    "print(\"   Output: Saves all extracted data to quotes.json\")\n",
    "print(\"   Automatically: Handles requests, follows links, exports data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Resources & Documentation - Organized by Library\n",
    "\n",
    "### ü•Ñ Beautiful Soup Resources\n",
    "\n",
    "#### Official Documentation:\n",
    "- **[Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)** - Complete official documentation\n",
    "- **[Beautiful Soup Quick Start](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start)** - Getting started guide\n",
    "- **[CSS Selectors Reference](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)** - CSS selector syntax\n",
    "\n",
    "#### Video Tutorials:\n",
    "- **[Beautiful Soup Tutorial](https://www.youtube.com/watch?v=87Gx3U0BDlo)** - Corey Schafer\n",
    "- **[Web Scraping with Beautiful Soup](https://www.youtube.com/watch?v=ng2o98k983k)** - Tech With Tim\n",
    "- **[Beautiful Soup Complete Guide](https://www.youtube.com/watch?v=XVv6mJpFOb0)** - freeCodeCamp\n",
    "\n",
    "#### Articles & Tutorials:\n",
    "- **[Real Python - Beautiful Soup Guide](https://realpython.com/beautiful-soup-web-scraper-python/)** - Comprehensive tutorial\n",
    "- **[GeeksforGeeks - Beautiful Soup](https://www.geeksforgeeks.org/implementing-web-scraping-python-beautiful-soup/)** - Step-by-step examples\n",
    "\n",
    "### üåê Requests Library Resources\n",
    "\n",
    "#### Official Documentation:\n",
    "- **[Requests Documentation](https://requests.readthedocs.io/)** - HTTP library documentation\n",
    "- **[Requests Quickstart](https://requests.readthedocs.io/en/latest/user/quickstart/)** - Basic usage examples\n",
    "- **[Advanced Usage](https://requests.readthedocs.io/en/latest/user/advanced/)** - Sessions, cookies, SSL\n",
    "\n",
    "#### Video Tutorials:\n",
    "- **[Requests Library Tutorial](https://www.youtube.com/watch?v=tb8gHvYlCFs)** - Corey Schafer\n",
    "- **[HTTP Requests in Python](https://www.youtube.com/watch?v=9N6a-VLBa2I)** - Programming with Mosh\n",
    "\n",
    "#### Articles:\n",
    "- **[Requests vs urllib](https://realpython.com/python-requests/)** - When to use what\n",
    "- **[Session Objects in Requests](https://requests.readthedocs.io/en/latest/user/advanced/#session-objects)** - Persistent sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üï∏Ô∏è Scrapy Framework Resources\n",
    "\n",
    "#### Official Documentation:\n",
    "- **[Scrapy Documentation](https://docs.scrapy.org/)** - Complete framework guide\n",
    "- **[Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html)** - Step-by-step tutorial\n",
    "- **[Scrapy Best Practices](https://docs.scrapy.org/en/latest/topics/practices.html)** - Production tips\n",
    "- **[Scrapy Shell](https://docs.scrapy.org/en/latest/topics/shell.html)** - Interactive testing\n",
    "\n",
    "#### Video Tutorials:\n",
    "- **[Scrapy Framework Tutorial](https://www.youtube.com/watch?v=s4jtkzHhLzY)** - Traversy Media\n",
    "- **[Complete Scrapy Course](https://www.youtube.com/watch?v=mBoX_JCKZTE)** - Coding Entrepreneurs\n",
    "- **[Scrapy vs Beautiful Soup](https://www.youtube.com/watch?v=52rxmBEmeKQ)** - When to use what\n",
    "\n",
    "#### Books & Courses:\n",
    "- **\"Learning Scrapy\"** by Dimitris Kouzis-Loukas - Packt\n",
    "- **\"Web Scraping with Python and Scrapy\"** - Udemy courses\n",
    "- **[Scrapy GitHub Examples](https://github.com/scrapy/scrapy/tree/master/docs/topics/examples)** - Official examples\n",
    "\n",
    "### üöó Selenium Resources\n",
    "\n",
    "#### Official Documentation:\n",
    "- **[Selenium Documentation](https://selenium-python.readthedocs.io/)** - Official Python bindings\n",
    "- **[WebDriver API](https://selenium-python.readthedocs.io/api.html)** - Complete API reference\n",
    "- **[Waits in Selenium](https://selenium-python.readthedocs.io/waits.html)** - Handling dynamic content\n",
    "- **[Selenium Grid](https://selenium.dev/documentation/grid/)** - Distributed testing\n",
    "\n",
    "#### Video Tutorials:\n",
    "- **[Selenium WebDriver with Python](https://www.youtube.com/watch?v=Xjv1sY630Uc)** - Programming with Mosh\n",
    "- **[Selenium Complete Course](https://www.youtube.com/watch?v=j7VZsCCnptM)** - Edureka\n",
    "- **[Selenium with Python Tutorial](https://www.youtube.com/watch?v=zjo9yFHoUl8)** - Telusko\n",
    "\n",
    "#### Articles & Guides:\n",
    "- **[Real Python - Selenium Guide](https://realpython.com/modern-web-automation-with-python-and-selenium/)** - Modern web automation\n",
    "- **[Selenium Best Practices](https://selenium.dev/documentation/test_practices/)** - Official best practices\n",
    "- **[Handling Dynamic Content](https://selenium-python.readthedocs.io/waits.html)** - WebDriverWait examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö° Parallel Processing & Advanced Topics\n",
    "\n",
    "#### Joblib Resources:\n",
    "- **[Joblib Documentation](https://joblib.readthedocs.io/)** - Official documentation\n",
    "- **[Parallel Computing with Joblib](https://joblib.readthedocs.io/en/latest/parallel.html)** - Parallel processing guide\n",
    "- **[Joblib vs Multiprocessing](https://stackoverflow.com/questions/20776189/joblib-vs-multiprocessing)** - When to use what\n",
    "\n",
    "#### Multiprocessing & Threading:\n",
    "- **[Python Multiprocessing](https://docs.python.org/3/library/multiprocessing.html)** - Official documentation\n",
    "- **[Concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)** - High-level interface\n",
    "- **[Threading vs Multiprocessing](https://realpython.com/python-concurrency/)** - Real Python guide\n",
    "\n",
    "#### Performance & Optimization:\n",
    "- **[Web Scraping Performance](https://blog.apify.com/web-scraping-performance-optimization/)** - Apify blog\n",
    "- **[Async Web Scraping](https://www.scrapehero.com/async-web-scraping-with-aiohttp/)** - ScrapeHero guide\n",
    "\n",
    "### üõ†Ô∏è General Web Scraping Resources\n",
    "\n",
    "#### Practice Websites:\n",
    "- **[Quotes to Scrape](http://quotes.toscrape.com/)** - Perfect for beginners\n",
    "- **[Books to Scrape](http://books.toscrape.com/)** - E-commerce practice\n",
    "- **[Scrape This Site](https://scrapethissite.com/)** - Various challenges\n",
    "- **[HTTP Bin](https://httpbin.org/)** - HTTP testing service\n",
    "\n",
    "#### Alternative Libraries:\n",
    "- **[requests-html](https://github.com/psf/requests-html)** - JavaScript support for requests\n",
    "- **[playwright-python](https://playwright.dev/python/)** - Modern browser automation\n",
    "- **[httpx](https://www.python-httpx.org/)** - Next-generation HTTP client\n",
    "- **[pyppeteer](https://github.com/pyppeteer/pyppeteer)** - Puppeteer port for Python\n",
    "\n",
    "#### Data Processing:\n",
    "- **[Pandas Documentation](https://pandas.pydata.org/docs/)** - Data manipulation and analysis\n",
    "- **[NumPy User Guide](https://numpy.org/doc/stable/user/)** - Numerical computing\n",
    "- **[Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)** - Data visualization\n",
    "\n",
    "### üìñ Books & Comprehensive Courses\n",
    "\n",
    "#### Recommended Books:\n",
    "- **\"Web Scraping with Python\"** by Ryan Mitchell - O'Reilly Media (Classic)\n",
    "- **\"Python Web Scraping Cookbook\"** by Michael Heydt - Packt\n",
    "- **\"Mastering Python Web Scraping\"** - Advanced techniques\n",
    "\n",
    "#### Online Courses:\n",
    "- **[freeCodeCamp Web Scraping](https://www.youtube.com/watch?v=XVv6mJpFOb0)** - 3+ hour complete course\n",
    "- **[Udemy Web Scraping Courses](https://www.udemy.com/topic/web-scraping/)** - Various paid courses\n",
    "- **[Coursera Web Scraping](https://www.coursera.org/search?query=web%20scraping)** - University courses\n",
    "\n",
    "### üéØ Learning Path Recommendations\n",
    "\n",
    "#### Beginner (1-2 weeks):\n",
    "1. HTML/CSS basics\n",
    "2. Beautiful Soup fundamentals\n",
    "3. Simple scraping projects\n",
    "4. Practice websites\n",
    "\n",
    "#### Intermediate (2-4 weeks):\n",
    "5. Selenium for dynamic content\n",
    "6. Error handling and robustness\n",
    "7. Data processing with pandas\n",
    "8. Multiple page scraping\n",
    "\n",
    "#### Advanced (4+ weeks):\n",
    "9. Scrapy framework\n",
    "10. Parallel processing\n",
    "11. Large-scale projects\n",
    "12. Production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≤ 00\n",
    "- ‚ñ∂Ô∏è[Video]()\n",
    "- üîó[Random link]()\n",
    "- üá¶üá≤üé∂[]()\n",
    "- üåêüé∂[]()\n",
    "- ü§å[‘ø’°÷Ä’£’´’∂]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfbUegKqXVyH"
   },
   "source": [
    "\n",
    "<a href=\"http://s01.flagcounter.com/more/1oO\"><img src=\"https://s01.flagcounter.com/count2/1oO/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_1/flags_0/percent_0/\" alt=\"Flag Counter\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOx7X+DxNeKu1zUVVCmsSHJ",
   "provenance": [
    {
     "file_id": "1_9UtYmPVVGmnWIKdBzPYkbtTlTbd0clo",
     "timestamp": 1735604987843
    },
    {
     "file_id": "15x56uwwONMo_ilzUJgt6UcX1d552xH6X",
     "timestamp": 1708441161475
    },
    {
     "file_id": "1LbG88IWtk30WlIoINzG4_vXHoJAvoDaP",
     "timestamp": 1683614319950
    }
   ]
  },
  "kernelspec": {
   "display_name": "lectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
