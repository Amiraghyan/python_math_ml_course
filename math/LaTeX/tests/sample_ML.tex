 \begin{center}\begin{large} Final Test
 \vspace{1em}
 
 \end{large}\end{center}
 % \small Each question is worth 100/15 points. Duration: 115 minutes.
 \bigskip


\begin{problem} \textbf{True/False Questions:}

\begin{enumerate}
    % \item Regularization techniques are used to prevent overfitting in machine learning models.

    % \item Hyperparameters are parameters that are set prior to the training process and are not learned from the data.

    % \item K-medoids is a supervised learning algorithm.

%     \item Missing data should always be \textit{removed} from the dataset to prevent any negative impact
% on model performance

%     \item Classification is used when the target variable is categorical, while regression is used
% when the target variable is continuous.
    
%     \item Overfitting occurs when a model performs well on both the training and testing.

% True or False: PCA can be used for feature extraction as well as dimensionality reduction.

    % \item The random forest algorithm is an example of an unsupervised learning technique.



    \item In general, having a deeper  decision tree is better than a shallower one.

    \item In hierarchical clustering, the choice of linkage method determines how clusters are formed.

    % \item The K-Nearest Neighbors algorithm requires training time but no prediction time.

    \item The purpose of regularization is to penalize large coefficients in a model.


    % \item PCA (Principal Component Analysis) can be used for dimensionality reduction in a dataset.
\end{enumerate}
    
\end{problem} 

% True or False: Ensemble methods combine multiple machine learning models to improve performance.


\begin{problem} \textbf{Multiple-Choice Question:}

\item Which criteria are used for splitting nodes in decision trees? Choose all that apply.


\begin{enumerate}
    \item [a)] Mean Squared Error (MSE)
    \item [b)] Gini impurity
    \item [c)] Variance
    \item [d)] Entropy
\end{enumerate}
% 
% a) 
% b) 
% d) 
\end{problem}


\begin{problem} \textbf{Short Answer Questions:}

\begin{enumerate}
    % \item What is feature engineering, and why is it important in machine learning?

    \item 
What is the purpose of having separate Train, Validation, Test datasets?


    \item 
 What is the learning rate in gradient descent optimization algorithms, why do we need it?


\end{enumerate}
    
\end{problem}




\begin{problem}
    \textbf{Linear Regression:}



\begin{itemize}
    \item Describe how the Ordinary Least Squares (OLS) algorithm works
    
    \item Why may large weights be unwanted?

    \item What are some techniques to prevent large weights?
\end{itemize}
\end{problem}

% Multiple-Choice Questions:

% Which evaluation metric is most appropriate for imbalanced datasets?
% a) Accuracy
% b) Precision
% c) F1-score
% d) Mean Squared Error (MSE)

% Explain the bias-variance tradeoff in machine learning.
% Describe the curse of dimensionality and its implications in machine learning.

% Explain the concept of bias in machine learning models and how it can affect model performance.
% What is the difference between batch gradient descent, stochastic gradient descent, and mini-batch gradient descent?



% True or False: PCA is a supervised learning algorithm.
% True or False: Support Vector Machines are primarily used for regression tasks.


% Short Answer Questions:

% What is the purpose of a learning rate in gradient descent optimization algorithms?

% Multiple-Choice Questions:

% Which of the following algorithms is a non-parametric method?
% a) Linear Regression
% b) Decision Trees
% c) Logistic Regression
% d) Ridge Regression


% 1. True/False Questions.
% [1.1] Supervised learning requires labeled training data, while unsupervised learning
% can work with unlabeled data.
% # True # False
% [1.2] Classification is used when the target variable is categorical, while regression is
% used when the target variable is continuous.
% # True # False
% [1.3] Overfitting occurs when a model performs well on both the training and testing
% data.
% # True # False
% [1.4] Missing data should always be removed from the dataset to prevent any negative
% impact on model performance.
% # True # False
% [1.5] Feature scaling is a preprocessing technique used to bring all features to the
% range between 0 and 1.
% # True # False

% 2. Multiple-Choice Questions.
% [2.1] Ordinary Least Squares (OLS) is used in linear regression to minimize:
% # Mean Squared Error
% # Mean Absolute Error
% [2.2] Gradient descent is an optimization algorithm used to::
% # Find the maximum of a function.
% # Minimize the loss function and find optimal parameters.
% # Randomly initialize model weights.
% 2
% [2.3] Which type(s) of gradient descent doesn’t use the entire dataset in each iteration?
% Choose all that apply.
% # Batch gradient descent
% # Stochastic gradient descent
% # Mini-batch gradient descent
% [2.4] Which of the following are possible metrics used to evaluate linear regression
% models? Choose all that apply.
% # Mean Absolute Error (MAE)
% # Precision
% # Accuracy
% # Root Mean Squared Error (RMSE)
% [2.5] Which of the following are components of the logistic regression algorithm?
% Choose all that apply.
% # Sigmoid function
% # Mean Absolute Error (MAE)
% # Cross-entropy loss function
% # Root Mean Squared Error (RMSE)
% [2.6] What does the confusion matrix provide insights into?
% # Precision and Recall
% # Feature importance
% # Mean squared error
% # Bias-variance tradeoff
% [2.7] Which criterias are used for splitting nodes in decision trees? Choose all that
% apply.
% # Mean Squared Error (MSE)
% # Gini impurity
% # Variance
% # Entropy
% [2.8] Which of the following are examples of ensemble methods? Choose all that apply.
% # Random Forest
% # Logistic Regression
% # Gradient Boosting
% # K-Means
% 3
% 3. Gradient Descent
% You are using gradient descent to find the minimum of the function
% f(x) = x
% 2
% You experiment by fixing the number of iterations and trying different learning rates
% to find the one which leads to a better (smaller) solution. There are different possible
% settings, e.g., you choose a learning rate of zero (1), the optimal learning rate (2), a
% learning rate that is too large (3) or too small (4). When initializing at point A on the
% plot below, which point of the plot are you most likely to reach with each learning rate
% setting? Match the settings 1, 2, 3, and 4 to the points on the plot indicated by letters
% A,B, C, and D.
% 4. Logistic Regression
% [4.1] Arrange the steps of the logistic regression algorithm in the correct order:
% • A. Compute the weighted sum of inputs and weights.
% • B. Calculate the loss using the binary cross-entropy function.
% • C. Update the weights using gradient descent.
% • D. Apply the sigmoid function to the weighted sum.
% [4.2] Write the formula of sigmoid function.
% 4
% 5. Bias-Variance Decomposition
% Examine the provided graph illustrating the bias-variance tradeoff based on model
% complexity. In which region of the graph does the model overfit the data? Where does
% the model underfit the data? Finally, identify the area on the graph that represents the
% optimal balance between bias and variance. Use the terms ’overfitting,’ ’underfitting,’
% and ’optimal solution’ to describe each respective region.
% 6. KNN
% Describe how the K-Nearest Neighbors (KNN) algorithm works (prediction
% stage)
% • Given a new input data point for classification or regression.
% • Identify the value of k, which represents the number of nearest neighbors to consider.
% • ....
% 5
% 7. Confusion Matrix
% You are given a set of actual labels and the probability outputs as predictions from a
% binary classification model.
% Actual Label Probability Output Prediction 1 Prediction 2
% 1 0.75
% 0 0.42
% 1 0.63
% 1 0.82
% 0 0.28
% 1 0.91
% 0 0.35
% 1 0.76
% 0 0.19
% 0 0.67
% 1. Choose two threshold values and find predictions.
% 2. For each prediction construct a confusion matrix using the provided actual labels
% and probability outputs.
% 3. Calculate the precision and recall values based on the confusion matrices.
% 6
% 7. Decision Tree
% You are provided with an image depicting a decision tree applied to 2D data. Your
% task is to construct a decision tree based on the given image that captures the same
% structure and decisions as shown in the picture.