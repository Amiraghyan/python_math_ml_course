 \begin{center}\begin{large} Final Test
 \vspace{1em}
 
 \end{large}\end{center}
 % \small Each question is worth 100/15 points. Duration: 115 minutes.
 \bigskip


\begin{problem} \textbf{True/False Questions:}

\begin{enumerate}
 
    \item A decision tree can handle both numerical and categorical data.

    \item In hierarchical clustering, the choice of linkage method determines how clusters are formed.

    \item The purpose of regularization is to penalize large coefficients in a model.

    % \item The K-Nearest Neighbors algorithm requires training time but no prediction time.

\end{enumerate}
    
\end{problem} 



\begin{problem} \textbf{Multiple-Choice Question:}

\item Which criteria are used for splitting nodes in decision trees? Choose all that apply.

\begin{enumerate}
    \item [a)] Mean Squared Error (MSE)
    \item [b)] Gini impurity
    \item [c)] Variance
    \item [d)] Entropy
\end{enumerate}

\end{problem}


\begin{problem} \textbf{Short Answer Questions:}

\begin{enumerate}
    % \item What is the purpose of the bias in a neural network?
    
    \item Write the formula of ReLU function. What is it suitable for?

    \item 
Describe the difference between K-Means and K-Medoids.

    \item 
What is the purpose of having separate Train, Validation, Test datasets?

\end{enumerate}
    
\end{problem}




\begin{problem}
    \textbf{Linear Regression:}

\begin{itemize}
    \item Describe how the Ordinary Least Squares (OLS) algorithm works.
    
    \item Why may large weights be unwanted?

    \item What are some techniques to prevent large weights?
\end{itemize}
\end{problem}

