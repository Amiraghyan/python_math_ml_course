---
title: "Practice 1: Vectors"
format: html
---

## Exercise: Finding a Perpendicular Vector

**Context:**  
In linear algebra, two vectors are perpendicular (or orthogonal) if their dot product is zero. In this exercise, you will find a vector in $\mathbb{R}^2$ that is perpendicular to a given vector.

**Given:**  
Let $\mathbf{v} = [2, 3]$.

**Tasks:**

1. **Find a Perpendicular Vector:**  
   - Find a non-zero vector $\mathbf{w} = [x, y]$ such that $\mathbf{v}$ and $\mathbf{w}$ are perpendicular.
     
2. **Verification:**  
   - Show that your chosen vector $\mathbf{w}$ indeed satisfies the condition $\mathbf{v} \cdot \mathbf{w} = 0$.

3. **Unit Perpendicular Vector:**  
   - Find a unit vector in the direction of $\mathbf{w}$ by computing $\frac{\mathbf{w}}{\|\mathbf{w}\|}$, where $\|\mathbf{w}\|$ is the Euclidean norm of $\mathbf{w}$.

4. **Bonus Discussion:**  
   - Explain why there are infinitely many vectors perpendicular to $\mathbf{v}$ and describe the general form of all such vectors.

---


## Exercise: Finding the Closest Word with 2D Embeddings

**Context:**  
In NLP, words can be represented as vectors. Here, each word is represented by a 2-dimensional vector. By comparing these vectors using Euclidean distance and cosine similarity, you can determine which word is “closer” in meaning.

**Given Word Embeddings:**

- **cheese:** `[1, 2]`
- **mushroom:** `[3, 1]`
- **tasty:** `[2, 2]`

**Tasks:**

1. **Euclidean Distance:**  
   - **a.** Compute the Euclidean distance between **tasty** and **cheese**.  
   - **b.** Compute the Euclidean distance between **tasty** and **mushroom**.  
   - **c.** Which word is closer to **tasty** based on the Euclidean distance?

2. **Cosine Similarity:**  
$$
    \cos(\theta)=\frac{\mathbf{u}\cdot\mathbf{v}}{\|\mathbf{u}\|\|\mathbf{v}\|}
$$
   - **a.** Compute the cosine similarity between **tasty** and **cheese** using the formula above.
   - **b.** Compute the cosine similarity between **tasty** and **mushroom**.  
   - **c.** Based on cosine similarity, which word is closer to **tasty**?

1. **Discussion:**  
   - Compare the outcomes from the Euclidean distance and cosine similarity calculations.  
   - Discuss why one metric might be preferred over the other in different NLP applications.

:::{.callout-note}
Cool video by 3blue1brown discussing [word vectors (embeddings)](https://youtu.be/wjZofJX0v4M?t=751)
:::

## Exercise: Linear transformation matrix power 

**Tasks:**
1. **Matrix Power:**  
   - Compute the matrix power of the following matrix $A$ to the power of $n$:
$$
A = \begin{pmatrix}
    2 & 0 \\
    0 & -1
\end{pmatrix}
$$
   - What does the result represent in terms of linear transformations?

## Exercise: Subspace 
**Tasks:**

![subspace_exercise](subspace_exercise.png)

## Exercise: Vector Space 

![Poole_vec_space](vector_space.png)

![vec_space_exercise](vec_space_ex.png)


